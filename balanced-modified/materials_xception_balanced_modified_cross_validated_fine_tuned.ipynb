{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials_xception_balanced_modified_cross_validated_fine_tuned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350525ae-47c9-494c-8e8d-4768a2c84d91"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a36caeb-66e4-4a2e-d28e-5df2933a3361"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create list containing the dataset for each class\n",
        "ds_each_class = [tf.data.Dataset.list_files(str(data_dir/f'{class_name}/*.jpg'), shuffle=False) for class_name in class_names]\n",
        "\n",
        "# shuffle the 100 images in each class with the random seed value of 123 before training\n",
        "for index, ds in enumerate(ds_each_class):\n",
        "  ds_each_class[index] = ds.shuffle(image_count//10, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_LijJpqbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8d50a5-8421-4131-cb69-0178fdd8e5a3"
      },
      "source": [
        "# display some samples from a class to verify each class dataset contains only the class images\n",
        "for f in ds_each_class[0].take(10):\n",
        "  print(f.numpy())\n",
        "\n",
        "for f in ds_each_class[1].take(10):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'FMD/image/fabric/fabric_moderate_037_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_004_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_008_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_003_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_017_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_001_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_032_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_030_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_038_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_009_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_037_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_004_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_008_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_053_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_067_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_051_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_032_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_030_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_038_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_059_new.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split first class dataset into 5 equal sized partitions\n",
        "# then for remaining classes' datasets do the same and add to corresponding partition\n",
        "# for 5-fold cross validation\n",
        "A = ds_each_class[0].shard(num_shards=5, index=0)\n",
        "B = ds_each_class[0].shard(num_shards=5, index=1)\n",
        "C = ds_each_class[0].shard(num_shards=5, index=2)\n",
        "D = ds_each_class[0].shard(num_shards=5, index=3)\n",
        "E = ds_each_class[0].shard(num_shards=5, index=4)\n",
        "for i in range(1, 10):\n",
        "  A = A.concatenate(ds_each_class[i].shard(num_shards=5, index=0))\n",
        "  B = B.concatenate(ds_each_class[i].shard(num_shards=5, index=1))\n",
        "  C = C.concatenate(ds_each_class[i].shard(num_shards=5, index=2))\n",
        "  D = D.concatenate(ds_each_class[i].shard(num_shards=5, index=3))\n",
        "  E = E.concatenate(ds_each_class[i].shard(num_shards=5, index=4))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4180ca8a-fc63-4020-aab2-02e54ca2ba26"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0717988d-3d7c-40ca-edc8-56516d4cc6c7"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.xception.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 115"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff417528-c849-47d5-84a5-731600694a3f"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.Xception(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3433 - accuracy: 0.1100\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 2.2675 - accuracy: 0.1500 - val_loss: 2.1005 - val_accuracy: 0.3550\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 1.9958 - accuracy: 0.3913 - val_loss: 1.8257 - val_accuracy: 0.5750\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 1.6899 - accuracy: 0.5725 - val_loss: 1.5059 - val_accuracy: 0.7450\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 1.4121 - accuracy: 0.6800 - val_loss: 1.2578 - val_accuracy: 0.7750\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 8s 156ms/step - loss: 1.1847 - accuracy: 0.7337 - val_loss: 1.0784 - val_accuracy: 0.8250\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 8s 158ms/step - loss: 1.0404 - accuracy: 0.7625 - val_loss: 0.9527 - val_accuracy: 0.8200\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 8s 158ms/step - loss: 0.9127 - accuracy: 0.7937 - val_loss: 0.8649 - val_accuracy: 0.8200\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 8s 159ms/step - loss: 0.8344 - accuracy: 0.8100 - val_loss: 0.8000 - val_accuracy: 0.8250\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 8s 160ms/step - loss: 0.7601 - accuracy: 0.8075 - val_loss: 0.7422 - val_accuracy: 0.8500\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 0.6814 - accuracy: 0.8175 - val_loss: 0.7100 - val_accuracy: 0.8250\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 0.6617 - accuracy: 0.8338 - val_loss: 0.6747 - val_accuracy: 0.8300\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 0.6161 - accuracy: 0.8388 - val_loss: 0.6549 - val_accuracy: 0.8400\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 0.5742 - accuracy: 0.8600 - val_loss: 0.6256 - val_accuracy: 0.8450\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.5509 - accuracy: 0.8487 - val_loss: 0.6085 - val_accuracy: 0.8300\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 0.5068 - accuracy: 0.8763 - val_loss: 0.5974 - val_accuracy: 0.8550\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 0.4965 - accuracy: 0.8712 - val_loss: 0.5880 - val_accuracy: 0.8650\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.4701 - accuracy: 0.8675 - val_loss: 0.5747 - val_accuracy: 0.8550\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 0.4332 - accuracy: 0.8800 - val_loss: 0.5725 - val_accuracy: 0.8450\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 0.4196 - accuracy: 0.8888 - val_loss: 0.5522 - val_accuracy: 0.8450\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 0.4563 - accuracy: 0.8788 - val_loss: 0.5576 - val_accuracy: 0.8350\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.4100 - accuracy: 0.8850 - val_loss: 0.5350 - val_accuracy: 0.8650\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.3766 - accuracy: 0.8938 - val_loss: 0.5286 - val_accuracy: 0.8450\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3810 - accuracy: 0.9000 - val_loss: 0.5435 - val_accuracy: 0.8600\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3673 - accuracy: 0.9100 - val_loss: 0.5250 - val_accuracy: 0.8550\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3550 - accuracy: 0.9075 - val_loss: 0.5336 - val_accuracy: 0.8600\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3268 - accuracy: 0.9087 - val_loss: 0.5106 - val_accuracy: 0.8500\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3067 - accuracy: 0.9275 - val_loss: 0.5110 - val_accuracy: 0.8450\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3320 - accuracy: 0.9175 - val_loss: 0.5126 - val_accuracy: 0.8600\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3074 - accuracy: 0.9250 - val_loss: 0.5143 - val_accuracy: 0.8450\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2879 - accuracy: 0.9262 - val_loss: 0.5043 - val_accuracy: 0.8450\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3001 - accuracy: 0.9212 - val_loss: 0.5032 - val_accuracy: 0.8500\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2876 - accuracy: 0.9250 - val_loss: 0.4974 - val_accuracy: 0.8550\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2789 - accuracy: 0.9225 - val_loss: 0.4876 - val_accuracy: 0.8600\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2710 - accuracy: 0.9287 - val_loss: 0.4902 - val_accuracy: 0.8550\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2680 - accuracy: 0.9325 - val_loss: 0.4926 - val_accuracy: 0.8600\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2691 - accuracy: 0.9262 - val_loss: 0.4907 - val_accuracy: 0.8450\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2328 - accuracy: 0.9400 - val_loss: 0.4878 - val_accuracy: 0.8550\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2295 - accuracy: 0.9388 - val_loss: 0.4828 - val_accuracy: 0.8500\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2793 - accuracy: 0.9137 - val_loss: 0.4855 - val_accuracy: 0.8500\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2231 - accuracy: 0.9488 - val_loss: 0.4794 - val_accuracy: 0.8650\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2224 - accuracy: 0.9500 - val_loss: 0.4756 - val_accuracy: 0.8600\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2000 - accuracy: 0.9563 - val_loss: 0.4899 - val_accuracy: 0.8550\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2315 - accuracy: 0.9300 - val_loss: 0.4848 - val_accuracy: 0.8600\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2427 - accuracy: 0.9438 - val_loss: 0.4829 - val_accuracy: 0.8600\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2044 - accuracy: 0.9525 - val_loss: 0.4814 - val_accuracy: 0.8700\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.1816 - accuracy: 0.9613 - val_loss: 0.4810 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1967 - accuracy: 0.9588 - val_loss: 0.4816 - val_accuracy: 0.8700\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.2071 - accuracy: 0.9513 - val_loss: 0.4830 - val_accuracy: 0.8650\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.1853 - accuracy: 0.9513 - val_loss: 0.5010 - val_accuracy: 0.8400\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.1790 - accuracy: 0.9538 - val_loss: 0.4952 - val_accuracy: 0.8650\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.4952 - accuracy: 0.8650\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 12s 235ms/step - loss: 0.1771 - accuracy: 0.9475 - val_loss: 0.4745 - val_accuracy: 0.8750\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 227ms/step - loss: 0.1458 - accuracy: 0.9575 - val_loss: 0.5006 - val_accuracy: 0.8600\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 225ms/step - loss: 0.1408 - accuracy: 0.9550 - val_loss: 0.5041 - val_accuracy: 0.8650\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 222ms/step - loss: 0.1301 - accuracy: 0.9638 - val_loss: 0.4975 - val_accuracy: 0.8750\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1135 - accuracy: 0.9675 - val_loss: 0.5139 - val_accuracy: 0.8550\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.0993 - accuracy: 0.9663 - val_loss: 0.5256 - val_accuracy: 0.8400\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1084 - accuracy: 0.9700 - val_loss: 0.5503 - val_accuracy: 0.8550\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 223ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.5550 - val_accuracy: 0.8500\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 223ms/step - loss: 0.0838 - accuracy: 0.9725 - val_loss: 0.5428 - val_accuracy: 0.8450\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 223ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.5558 - val_accuracy: 0.8450\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 222ms/step - loss: 0.0574 - accuracy: 0.9862 - val_loss: 0.5917 - val_accuracy: 0.8350\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 222ms/step - loss: 0.0821 - accuracy: 0.9712 - val_loss: 0.5621 - val_accuracy: 0.8650\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.0687 - accuracy: 0.9775 - val_loss: 0.5651 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.0770 - accuracy: 0.9737 - val_loss: 0.5663 - val_accuracy: 0.8350\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.0656 - accuracy: 0.9812 - val_loss: 0.5969 - val_accuracy: 0.8400\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.0660 - accuracy: 0.9762 - val_loss: 0.5808 - val_accuracy: 0.8500\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 0.6526 - val_accuracy: 0.8500\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.0458 - accuracy: 0.9875 - val_loss: 0.6137 - val_accuracy: 0.8600\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0746 - accuracy: 0.9750 - val_loss: 0.6211 - val_accuracy: 0.8500\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.0414 - accuracy: 0.9850 - val_loss: 0.5897 - val_accuracy: 0.8400\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.6423 - val_accuracy: 0.8650\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 2.3856 - accuracy: 0.0800\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 2.3033 - accuracy: 0.1225 - val_loss: 2.1053 - val_accuracy: 0.3050\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.9983 - accuracy: 0.3613 - val_loss: 1.8135 - val_accuracy: 0.6100\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.6929 - accuracy: 0.5800 - val_loss: 1.5015 - val_accuracy: 0.7250\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.4158 - accuracy: 0.6737 - val_loss: 1.2507 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.2150 - accuracy: 0.7163 - val_loss: 1.0628 - val_accuracy: 0.7800\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.0302 - accuracy: 0.7538 - val_loss: 0.9336 - val_accuracy: 0.8050\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.9034 - accuracy: 0.7887 - val_loss: 0.8438 - val_accuracy: 0.8100\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.8002 - accuracy: 0.8025 - val_loss: 0.7789 - val_accuracy: 0.8150\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.7397 - accuracy: 0.8175 - val_loss: 0.7247 - val_accuracy: 0.8050\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.6936 - accuracy: 0.8188 - val_loss: 0.6850 - val_accuracy: 0.8150\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.6574 - accuracy: 0.8238 - val_loss: 0.6514 - val_accuracy: 0.8250\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.6158 - accuracy: 0.8512 - val_loss: 0.6347 - val_accuracy: 0.8150\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5522 - accuracy: 0.8650 - val_loss: 0.6085 - val_accuracy: 0.8150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.5090 - accuracy: 0.8875 - val_loss: 0.5895 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.5473 - accuracy: 0.8525 - val_loss: 0.5793 - val_accuracy: 0.8150\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5324 - accuracy: 0.8537 - val_loss: 0.5594 - val_accuracy: 0.8050\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.4610 - accuracy: 0.8800 - val_loss: 0.5578 - val_accuracy: 0.8250\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.4354 - accuracy: 0.8925 - val_loss: 0.5407 - val_accuracy: 0.8050\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4369 - accuracy: 0.8800 - val_loss: 0.5345 - val_accuracy: 0.8200\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.4278 - accuracy: 0.8950 - val_loss: 0.5236 - val_accuracy: 0.8350\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3997 - accuracy: 0.8950 - val_loss: 0.5142 - val_accuracy: 0.8200\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3868 - accuracy: 0.9087 - val_loss: 0.5143 - val_accuracy: 0.8200\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.3547 - accuracy: 0.9150 - val_loss: 0.5161 - val_accuracy: 0.8200\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3410 - accuracy: 0.9137 - val_loss: 0.5031 - val_accuracy: 0.8250\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3581 - accuracy: 0.9062 - val_loss: 0.4951 - val_accuracy: 0.8250\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3277 - accuracy: 0.9150 - val_loss: 0.4931 - val_accuracy: 0.8250\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3261 - accuracy: 0.9175 - val_loss: 0.4882 - val_accuracy: 0.8350\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3292 - accuracy: 0.9137 - val_loss: 0.4971 - val_accuracy: 0.8350\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3248 - accuracy: 0.9087 - val_loss: 0.4855 - val_accuracy: 0.8250\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.3129 - accuracy: 0.9225 - val_loss: 0.4964 - val_accuracy: 0.8150\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2659 - accuracy: 0.9388 - val_loss: 0.4819 - val_accuracy: 0.8350\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2716 - accuracy: 0.9275 - val_loss: 0.4803 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2759 - accuracy: 0.9250 - val_loss: 0.4718 - val_accuracy: 0.8300\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2758 - accuracy: 0.9212 - val_loss: 0.4853 - val_accuracy: 0.8250\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2332 - accuracy: 0.9450 - val_loss: 0.4806 - val_accuracy: 0.8300\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2416 - accuracy: 0.9450 - val_loss: 0.4733 - val_accuracy: 0.8350\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2628 - accuracy: 0.9413 - val_loss: 0.4881 - val_accuracy: 0.8250\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2524 - accuracy: 0.9362 - val_loss: 0.4782 - val_accuracy: 0.8200\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2470 - accuracy: 0.9400 - val_loss: 0.4694 - val_accuracy: 0.8350\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2243 - accuracy: 0.9375 - val_loss: 0.4729 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2174 - accuracy: 0.9475 - val_loss: 0.4751 - val_accuracy: 0.8300\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.2410 - accuracy: 0.9350 - val_loss: 0.4699 - val_accuracy: 0.8450\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2199 - accuracy: 0.9438 - val_loss: 0.4726 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2079 - accuracy: 0.9450 - val_loss: 0.4593 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.1983 - accuracy: 0.9575 - val_loss: 0.4712 - val_accuracy: 0.8400\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.2084 - accuracy: 0.9475 - val_loss: 0.4656 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.1972 - accuracy: 0.9513 - val_loss: 0.4708 - val_accuracy: 0.8250\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.1921 - accuracy: 0.9575 - val_loss: 0.4735 - val_accuracy: 0.8400\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.1986 - accuracy: 0.9425 - val_loss: 0.4670 - val_accuracy: 0.8250\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.1974 - accuracy: 0.9475 - val_loss: 0.4687 - val_accuracy: 0.8300\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.4687 - accuracy: 0.8300\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 227ms/step - loss: 0.1430 - accuracy: 0.9600 - val_loss: 0.4600 - val_accuracy: 0.8350\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1386 - accuracy: 0.9650 - val_loss: 0.4793 - val_accuracy: 0.8450\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 214ms/step - loss: 0.1012 - accuracy: 0.9737 - val_loss: 0.4779 - val_accuracy: 0.8500\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1056 - accuracy: 0.9638 - val_loss: 0.5052 - val_accuracy: 0.8450\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1015 - accuracy: 0.9638 - val_loss: 0.5015 - val_accuracy: 0.8400\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1208 - accuracy: 0.9638 - val_loss: 0.5037 - val_accuracy: 0.8450\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1009 - accuracy: 0.9725 - val_loss: 0.5629 - val_accuracy: 0.8400\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0968 - accuracy: 0.9762 - val_loss: 0.5482 - val_accuracy: 0.8450\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0747 - accuracy: 0.9800 - val_loss: 0.5236 - val_accuracy: 0.8500\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.5360 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0744 - accuracy: 0.9787 - val_loss: 0.5307 - val_accuracy: 0.8550\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0636 - accuracy: 0.9725 - val_loss: 0.5510 - val_accuracy: 0.8500\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0584 - accuracy: 0.9812 - val_loss: 0.5749 - val_accuracy: 0.8500\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.5760 - val_accuracy: 0.8550\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0736 - accuracy: 0.9762 - val_loss: 0.5920 - val_accuracy: 0.8550\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0469 - accuracy: 0.9825 - val_loss: 0.5786 - val_accuracy: 0.8500\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0579 - accuracy: 0.9775 - val_loss: 0.5810 - val_accuracy: 0.8550\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.5967 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.5754 - val_accuracy: 0.8600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0518 - accuracy: 0.9862 - val_loss: 0.5828 - val_accuracy: 0.8600\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.5986 - val_accuracy: 0.8600\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 2.3901 - accuracy: 0.0950\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 2.2619 - accuracy: 0.1838 - val_loss: 2.1173 - val_accuracy: 0.3100\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.9808 - accuracy: 0.4137 - val_loss: 1.8580 - val_accuracy: 0.5850\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.7020 - accuracy: 0.5825 - val_loss: 1.5888 - val_accuracy: 0.7050\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.4324 - accuracy: 0.6650 - val_loss: 1.3530 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.2240 - accuracy: 0.7013 - val_loss: 1.1828 - val_accuracy: 0.7700\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.0809 - accuracy: 0.7525 - val_loss: 1.0491 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.9328 - accuracy: 0.7937 - val_loss: 0.9488 - val_accuracy: 0.7900\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.8383 - accuracy: 0.8112 - val_loss: 0.8632 - val_accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.7784 - accuracy: 0.8125 - val_loss: 0.8210 - val_accuracy: 0.8100\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.7123 - accuracy: 0.8213 - val_loss: 0.7756 - val_accuracy: 0.7950\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.6398 - accuracy: 0.8388 - val_loss: 0.7329 - val_accuracy: 0.8050\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.6313 - accuracy: 0.8313 - val_loss: 0.7056 - val_accuracy: 0.7850\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.5994 - accuracy: 0.8512 - val_loss: 0.6789 - val_accuracy: 0.8200\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5464 - accuracy: 0.8600 - val_loss: 0.6614 - val_accuracy: 0.7900\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.4998 - accuracy: 0.8675 - val_loss: 0.6357 - val_accuracy: 0.8200\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.4855 - accuracy: 0.8750 - val_loss: 0.6236 - val_accuracy: 0.8100\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4982 - accuracy: 0.8750 - val_loss: 0.6145 - val_accuracy: 0.8300\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4564 - accuracy: 0.8725 - val_loss: 0.6007 - val_accuracy: 0.8250\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4152 - accuracy: 0.8950 - val_loss: 0.5927 - val_accuracy: 0.8100\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4391 - accuracy: 0.8750 - val_loss: 0.5881 - val_accuracy: 0.8300\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.4077 - accuracy: 0.8838 - val_loss: 0.5836 - val_accuracy: 0.8050\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3884 - accuracy: 0.8975 - val_loss: 0.5655 - val_accuracy: 0.8200\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3836 - accuracy: 0.8900 - val_loss: 0.5563 - val_accuracy: 0.8300\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3553 - accuracy: 0.9062 - val_loss: 0.5549 - val_accuracy: 0.8300\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3608 - accuracy: 0.9125 - val_loss: 0.5588 - val_accuracy: 0.8250\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3322 - accuracy: 0.9237 - val_loss: 0.5410 - val_accuracy: 0.8300\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3284 - accuracy: 0.9150 - val_loss: 0.5469 - val_accuracy: 0.8250\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3323 - accuracy: 0.9112 - val_loss: 0.5337 - val_accuracy: 0.8200\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3138 - accuracy: 0.9250 - val_loss: 0.5453 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3042 - accuracy: 0.9262 - val_loss: 0.5343 - val_accuracy: 0.8350\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3077 - accuracy: 0.9200 - val_loss: 0.5342 - val_accuracy: 0.8150\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2983 - accuracy: 0.9162 - val_loss: 0.5313 - val_accuracy: 0.8250\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2817 - accuracy: 0.9250 - val_loss: 0.5231 - val_accuracy: 0.8150\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2940 - accuracy: 0.9112 - val_loss: 0.5260 - val_accuracy: 0.8250\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 0.5302 - val_accuracy: 0.8250\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2612 - accuracy: 0.9312 - val_loss: 0.5200 - val_accuracy: 0.8350\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2646 - accuracy: 0.9287 - val_loss: 0.5217 - val_accuracy: 0.8250\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2688 - accuracy: 0.9212 - val_loss: 0.5221 - val_accuracy: 0.8200\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2497 - accuracy: 0.9400 - val_loss: 0.5278 - val_accuracy: 0.8200\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2548 - accuracy: 0.9300 - val_loss: 0.5210 - val_accuracy: 0.8300\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2230 - accuracy: 0.9475 - val_loss: 0.5199 - val_accuracy: 0.8100\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2225 - accuracy: 0.9450 - val_loss: 0.5237 - val_accuracy: 0.8200\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2279 - accuracy: 0.9388 - val_loss: 0.5210 - val_accuracy: 0.8200\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2184 - accuracy: 0.9425 - val_loss: 0.5215 - val_accuracy: 0.8250\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2025 - accuracy: 0.9563 - val_loss: 0.5132 - val_accuracy: 0.8150\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2281 - accuracy: 0.9325 - val_loss: 0.5093 - val_accuracy: 0.8150\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2088 - accuracy: 0.9488 - val_loss: 0.5115 - val_accuracy: 0.8250\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.2187 - accuracy: 0.9413 - val_loss: 0.5203 - val_accuracy: 0.8250\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1959 - accuracy: 0.9513 - val_loss: 0.5069 - val_accuracy: 0.8200\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1879 - accuracy: 0.9525 - val_loss: 0.5084 - val_accuracy: 0.8100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.5084 - accuracy: 0.8100\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 228ms/step - loss: 0.1820 - accuracy: 0.9475 - val_loss: 0.5100 - val_accuracy: 0.8150\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1387 - accuracy: 0.9563 - val_loss: 0.4854 - val_accuracy: 0.8250\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1212 - accuracy: 0.9625 - val_loss: 0.5135 - val_accuracy: 0.8100\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1171 - accuracy: 0.9650 - val_loss: 0.5080 - val_accuracy: 0.8250\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1103 - accuracy: 0.9688 - val_loss: 0.5249 - val_accuracy: 0.8050\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0952 - accuracy: 0.9613 - val_loss: 0.5170 - val_accuracy: 0.8150\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1170 - accuracy: 0.9575 - val_loss: 0.5246 - val_accuracy: 0.8150\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0872 - accuracy: 0.9700 - val_loss: 0.5362 - val_accuracy: 0.8150\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0932 - accuracy: 0.9675 - val_loss: 0.5648 - val_accuracy: 0.8050\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0863 - accuracy: 0.9663 - val_loss: 0.5308 - val_accuracy: 0.8200\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0684 - accuracy: 0.9787 - val_loss: 0.5307 - val_accuracy: 0.8200\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 0.5941 - val_accuracy: 0.8050\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0581 - accuracy: 0.9787 - val_loss: 0.6218 - val_accuracy: 0.8050\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.5708 - val_accuracy: 0.8150\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.5725 - val_accuracy: 0.8200\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0515 - accuracy: 0.9875 - val_loss: 0.5754 - val_accuracy: 0.8200\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0731 - accuracy: 0.9750 - val_loss: 0.5945 - val_accuracy: 0.8150\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0588 - accuracy: 0.9775 - val_loss: 0.5939 - val_accuracy: 0.8100\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0537 - accuracy: 0.9825 - val_loss: 0.5924 - val_accuracy: 0.8250\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.5873 - val_accuracy: 0.8300\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0510 - accuracy: 0.9900 - val_loss: 0.5718 - val_accuracy: 0.8150\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 2.3434 - accuracy: 0.0900\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.2593 - accuracy: 0.1462 - val_loss: 2.0883 - val_accuracy: 0.4050\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.9575 - accuracy: 0.4350 - val_loss: 1.8147 - val_accuracy: 0.6150\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.6622 - accuracy: 0.5938 - val_loss: 1.5206 - val_accuracy: 0.7400\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.4360 - accuracy: 0.6475 - val_loss: 1.2847 - val_accuracy: 0.7850\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.1759 - accuracy: 0.7412 - val_loss: 1.1077 - val_accuracy: 0.7750\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.0221 - accuracy: 0.7613 - val_loss: 0.9895 - val_accuracy: 0.7850\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.8929 - accuracy: 0.7825 - val_loss: 0.8984 - val_accuracy: 0.7950\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.8068 - accuracy: 0.8100 - val_loss: 0.8348 - val_accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.7410 - accuracy: 0.8125 - val_loss: 0.7855 - val_accuracy: 0.8150\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.7123 - accuracy: 0.8075 - val_loss: 0.7414 - val_accuracy: 0.8150\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.6391 - accuracy: 0.8313 - val_loss: 0.7105 - val_accuracy: 0.8100\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.5962 - accuracy: 0.8575 - val_loss: 0.6840 - val_accuracy: 0.8200\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5567 - accuracy: 0.8587 - val_loss: 0.6636 - val_accuracy: 0.8150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5622 - accuracy: 0.8487 - val_loss: 0.6470 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.5184 - accuracy: 0.8687 - val_loss: 0.6333 - val_accuracy: 0.8300\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.4544 - accuracy: 0.8800 - val_loss: 0.6220 - val_accuracy: 0.8350\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.5037 - accuracy: 0.8587 - val_loss: 0.6108 - val_accuracy: 0.8300\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4501 - accuracy: 0.8900 - val_loss: 0.5944 - val_accuracy: 0.8350\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4447 - accuracy: 0.8763 - val_loss: 0.5810 - val_accuracy: 0.8300\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4240 - accuracy: 0.8788 - val_loss: 0.5775 - val_accuracy: 0.8450\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.4173 - accuracy: 0.8838 - val_loss: 0.5663 - val_accuracy: 0.8450\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3803 - accuracy: 0.9112 - val_loss: 0.5626 - val_accuracy: 0.8300\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3579 - accuracy: 0.8988 - val_loss: 0.5557 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3668 - accuracy: 0.9000 - val_loss: 0.5475 - val_accuracy: 0.8250\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3409 - accuracy: 0.9150 - val_loss: 0.5386 - val_accuracy: 0.8350\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3397 - accuracy: 0.9100 - val_loss: 0.5387 - val_accuracy: 0.8350\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3271 - accuracy: 0.9087 - val_loss: 0.5270 - val_accuracy: 0.8400\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2983 - accuracy: 0.9275 - val_loss: 0.5320 - val_accuracy: 0.8350\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3145 - accuracy: 0.9200 - val_loss: 0.5221 - val_accuracy: 0.8550\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3063 - accuracy: 0.9175 - val_loss: 0.5279 - val_accuracy: 0.8500\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2944 - accuracy: 0.9200 - val_loss: 0.5218 - val_accuracy: 0.8450\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2878 - accuracy: 0.9287 - val_loss: 0.5143 - val_accuracy: 0.8500\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3006 - accuracy: 0.9162 - val_loss: 0.5154 - val_accuracy: 0.8550\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2652 - accuracy: 0.9337 - val_loss: 0.5176 - val_accuracy: 0.8350\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2573 - accuracy: 0.9325 - val_loss: 0.5022 - val_accuracy: 0.8550\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2593 - accuracy: 0.9275 - val_loss: 0.5049 - val_accuracy: 0.8500\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2490 - accuracy: 0.9388 - val_loss: 0.5067 - val_accuracy: 0.8600\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2380 - accuracy: 0.9362 - val_loss: 0.4955 - val_accuracy: 0.8550\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2387 - accuracy: 0.9350 - val_loss: 0.4970 - val_accuracy: 0.8550\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2284 - accuracy: 0.9438 - val_loss: 0.4978 - val_accuracy: 0.8550\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2427 - accuracy: 0.9325 - val_loss: 0.4957 - val_accuracy: 0.8550\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2087 - accuracy: 0.9463 - val_loss: 0.4929 - val_accuracy: 0.8600\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2210 - accuracy: 0.9388 - val_loss: 0.4983 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1977 - accuracy: 0.9600 - val_loss: 0.4961 - val_accuracy: 0.8500\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2158 - accuracy: 0.9388 - val_loss: 0.4996 - val_accuracy: 0.8600\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2122 - accuracy: 0.9425 - val_loss: 0.4983 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2067 - accuracy: 0.9362 - val_loss: 0.5053 - val_accuracy: 0.8550\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1933 - accuracy: 0.9563 - val_loss: 0.5063 - val_accuracy: 0.8600\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1854 - accuracy: 0.9538 - val_loss: 0.5003 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1836 - accuracy: 0.9563 - val_loss: 0.5000 - val_accuracy: 0.8450\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.5000 - accuracy: 0.8450\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 228ms/step - loss: 0.1624 - accuracy: 0.9600 - val_loss: 0.5032 - val_accuracy: 0.8450\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1342 - accuracy: 0.9613 - val_loss: 0.5095 - val_accuracy: 0.8500\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.1342 - accuracy: 0.9625 - val_loss: 0.5251 - val_accuracy: 0.8500\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1247 - accuracy: 0.9600 - val_loss: 0.5238 - val_accuracy: 0.8550\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.1163 - accuracy: 0.9650 - val_loss: 0.5366 - val_accuracy: 0.8600\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0992 - accuracy: 0.9688 - val_loss: 0.5386 - val_accuracy: 0.8550\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0828 - accuracy: 0.9762 - val_loss: 0.5660 - val_accuracy: 0.8650\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.5537 - val_accuracy: 0.8550\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.5634 - val_accuracy: 0.8500\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.5778 - val_accuracy: 0.8700\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0591 - accuracy: 0.9787 - val_loss: 0.5820 - val_accuracy: 0.8650\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 0.5769 - val_accuracy: 0.8600\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0715 - accuracy: 0.9750 - val_loss: 0.5688 - val_accuracy: 0.8600\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0537 - accuracy: 0.9850 - val_loss: 0.6071 - val_accuracy: 0.8650\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0563 - accuracy: 0.9787 - val_loss: 0.5961 - val_accuracy: 0.8650\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0501 - accuracy: 0.9900 - val_loss: 0.5954 - val_accuracy: 0.8600\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0600 - accuracy: 0.9825 - val_loss: 0.6230 - val_accuracy: 0.8550\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0479 - accuracy: 0.9875 - val_loss: 0.6303 - val_accuracy: 0.8550\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0489 - accuracy: 0.9850 - val_loss: 0.6172 - val_accuracy: 0.8700\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.6254 - val_accuracy: 0.8550\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 0.6448 - val_accuracy: 0.8550\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 2.3546 - accuracy: 0.0900\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 2.2733 - accuracy: 0.1725 - val_loss: 2.0608 - val_accuracy: 0.3950\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.9645 - accuracy: 0.4300 - val_loss: 1.7790 - val_accuracy: 0.6300\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.6676 - accuracy: 0.5875 - val_loss: 1.4892 - val_accuracy: 0.7100\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.3963 - accuracy: 0.6787 - val_loss: 1.2509 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.1586 - accuracy: 0.7337 - val_loss: 1.0885 - val_accuracy: 0.7550\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 1.0066 - accuracy: 0.7688 - val_loss: 0.9445 - val_accuracy: 0.8000\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.8757 - accuracy: 0.7937 - val_loss: 0.8582 - val_accuracy: 0.8200\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.8145 - accuracy: 0.7925 - val_loss: 0.7995 - val_accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.7186 - accuracy: 0.8313 - val_loss: 0.7475 - val_accuracy: 0.8200\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.6796 - accuracy: 0.8138 - val_loss: 0.7113 - val_accuracy: 0.8300\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.6228 - accuracy: 0.8500 - val_loss: 0.6784 - val_accuracy: 0.8350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5956 - accuracy: 0.8562 - val_loss: 0.6581 - val_accuracy: 0.8350\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5945 - accuracy: 0.8475 - val_loss: 0.6331 - val_accuracy: 0.8350\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.5310 - accuracy: 0.8737 - val_loss: 0.6096 - val_accuracy: 0.8400\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.5131 - accuracy: 0.8750 - val_loss: 0.5981 - val_accuracy: 0.8500\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.5008 - accuracy: 0.8750 - val_loss: 0.5737 - val_accuracy: 0.8450\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.4524 - accuracy: 0.8900 - val_loss: 0.5681 - val_accuracy: 0.8600\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.4188 - accuracy: 0.8888 - val_loss: 0.5560 - val_accuracy: 0.8550\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.4407 - accuracy: 0.8800 - val_loss: 0.5361 - val_accuracy: 0.8600\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.4130 - accuracy: 0.8875 - val_loss: 0.5424 - val_accuracy: 0.8450\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3936 - accuracy: 0.8925 - val_loss: 0.5375 - val_accuracy: 0.8500\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3750 - accuracy: 0.8963 - val_loss: 0.5395 - val_accuracy: 0.8350\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.3638 - accuracy: 0.9025 - val_loss: 0.5241 - val_accuracy: 0.8500\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3501 - accuracy: 0.9150 - val_loss: 0.5137 - val_accuracy: 0.8450\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.3406 - accuracy: 0.9175 - val_loss: 0.5191 - val_accuracy: 0.8450\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.3117 - accuracy: 0.9225 - val_loss: 0.5081 - val_accuracy: 0.8500\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3435 - accuracy: 0.9187 - val_loss: 0.5027 - val_accuracy: 0.8550\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.3089 - accuracy: 0.9250 - val_loss: 0.5038 - val_accuracy: 0.8550\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 181ms/step - loss: 0.3016 - accuracy: 0.9250 - val_loss: 0.4923 - val_accuracy: 0.8550\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2920 - accuracy: 0.9175 - val_loss: 0.4906 - val_accuracy: 0.8600\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2892 - accuracy: 0.9275 - val_loss: 0.5097 - val_accuracy: 0.8400\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2765 - accuracy: 0.9287 - val_loss: 0.5046 - val_accuracy: 0.8350\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2601 - accuracy: 0.9438 - val_loss: 0.4941 - val_accuracy: 0.8550\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2693 - accuracy: 0.9375 - val_loss: 0.4862 - val_accuracy: 0.8550\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 181ms/step - loss: 0.2596 - accuracy: 0.9312 - val_loss: 0.4827 - val_accuracy: 0.8550\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2590 - accuracy: 0.9362 - val_loss: 0.4847 - val_accuracy: 0.8550\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2469 - accuracy: 0.9362 - val_loss: 0.4816 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 181ms/step - loss: 0.2286 - accuracy: 0.9475 - val_loss: 0.4877 - val_accuracy: 0.8400\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2194 - accuracy: 0.9425 - val_loss: 0.4792 - val_accuracy: 0.8600\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2299 - accuracy: 0.9413 - val_loss: 0.4930 - val_accuracy: 0.8400\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2215 - accuracy: 0.9463 - val_loss: 0.4873 - val_accuracy: 0.8600\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2045 - accuracy: 0.9538 - val_loss: 0.4845 - val_accuracy: 0.8600\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2280 - accuracy: 0.9438 - val_loss: 0.4821 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.2150 - accuracy: 0.9463 - val_loss: 0.4869 - val_accuracy: 0.8600\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.1956 - accuracy: 0.9513 - val_loss: 0.4775 - val_accuracy: 0.8550\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.2192 - accuracy: 0.9513 - val_loss: 0.4818 - val_accuracy: 0.8550\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1827 - accuracy: 0.9613 - val_loss: 0.4804 - val_accuracy: 0.8550\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 0.1928 - accuracy: 0.9463 - val_loss: 0.4796 - val_accuracy: 0.8650\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.1935 - accuracy: 0.9450 - val_loss: 0.4800 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.1936 - accuracy: 0.9438 - val_loss: 0.4812 - val_accuracy: 0.8500\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 0.4812 - accuracy: 0.8500\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 229ms/step - loss: 0.1674 - accuracy: 0.9475 - val_loss: 0.4783 - val_accuracy: 0.8500\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1425 - accuracy: 0.9575 - val_loss: 0.4896 - val_accuracy: 0.8650\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1280 - accuracy: 0.9650 - val_loss: 0.4901 - val_accuracy: 0.8550\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0839 - accuracy: 0.9762 - val_loss: 0.5157 - val_accuracy: 0.8600\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.1206 - accuracy: 0.9625 - val_loss: 0.5153 - val_accuracy: 0.8750\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0943 - accuracy: 0.9700 - val_loss: 0.5162 - val_accuracy: 0.8650\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0945 - accuracy: 0.9700 - val_loss: 0.5541 - val_accuracy: 0.8600\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.5253 - val_accuracy: 0.8700\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0864 - accuracy: 0.9700 - val_loss: 0.5255 - val_accuracy: 0.8800\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.1033 - accuracy: 0.9663 - val_loss: 0.5245 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0893 - accuracy: 0.9700 - val_loss: 0.5309 - val_accuracy: 0.8500\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0737 - accuracy: 0.9800 - val_loss: 0.5642 - val_accuracy: 0.8600\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0648 - accuracy: 0.9775 - val_loss: 0.6170 - val_accuracy: 0.8350\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.0647 - accuracy: 0.9775 - val_loss: 0.5895 - val_accuracy: 0.8700\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.0566 - accuracy: 0.9787 - val_loss: 0.6167 - val_accuracy: 0.8650\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 0.5676 - val_accuracy: 0.8600\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.6038 - val_accuracy: 0.8700\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.6248 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.5876 - val_accuracy: 0.8600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0557 - accuracy: 0.9812 - val_loss: 0.6399 - val_accuracy: 0.8650\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.5895 - val_accuracy: 0.8600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6b055a-9f92-4a6a-d577-a1faa211d295"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.09300000071525574\n",
            "Accuracy before fine-tuning: 0.8400000095367431\n",
            "Final accuracy: 0.8639999985694885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5e0b6497-6e82-4b29-db4d-759d345cafe2"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7e85d157-ca98-4137-b3d4-61435d7c00bc"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}