{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-inceptionv3-balanced-modified-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlztECYIjJlUAh4oIIuDkl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f739b59-26ff-4f23-a672-ba069667ff22"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is required for pre-trained models like Inception V3\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03c0efa-ed96-4432-d9d5-0fb1810c63ee"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create list containing the dataset for each class\n",
        "ds_each_class = [tf.data.Dataset.list_files(str(data_dir/f'{class_name}/*.jpg'), shuffle=False) for class_name in class_names]\n",
        "\n",
        "# shuffle the 100 images in each class with the random seed value of 123 before training\n",
        "for index, ds in enumerate(ds_each_class):\n",
        "  ds_each_class[index] = ds.shuffle(image_count//10, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_LijJpqbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6198451-81f7-41e1-df97-1347a3888386"
      },
      "source": [
        "# display some samples from a class to verify each class dataset contains only the class images\n",
        "for f in ds_each_class[0].take(10):\n",
        "  print(f.numpy())\n",
        "\n",
        "for f in ds_each_class[1].take(10):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'FMD/image/fabric/fabric_moderate_037_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_004_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_008_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_003_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_017_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_001_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_032_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_030_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_038_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_009_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_037_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_004_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_008_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_053_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_067_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_051_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_032_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_030_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_038_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_059_new.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split first class dataset into 5 equal sized partitions\n",
        "# then for remaining classes' datasets do the same and add to corresponding partition\n",
        "# for 5-fold cross validation\n",
        "A = ds_each_class[0].shard(num_shards=5, index=0)\n",
        "B = ds_each_class[0].shard(num_shards=5, index=1)\n",
        "C = ds_each_class[0].shard(num_shards=5, index=2)\n",
        "D = ds_each_class[0].shard(num_shards=5, index=3)\n",
        "E = ds_each_class[0].shard(num_shards=5, index=4)\n",
        "for i in range(1, 10):\n",
        "  A = A.concatenate(ds_each_class[i].shard(num_shards=5, index=0))\n",
        "  B = B.concatenate(ds_each_class[i].shard(num_shards=5, index=1))\n",
        "  C = C.concatenate(ds_each_class[i].shard(num_shards=5, index=2))\n",
        "  D = D.concatenate(ds_each_class[i].shard(num_shards=5, index=3))\n",
        "  E = E.concatenate(ds_each_class[i].shard(num_shards=5, index=4))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d548b343-cdf4-44d3-96c9-7de8d3898d43"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461afa8b-7ed4-42a7-c2e0-a8b6e4a7bfd8"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.inception_v3.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 249"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37e56b2-244e-4b1d-cfba-3fe1f02be151"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.InceptionV3(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 2.3862 - accuracy: 0.1000\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 2.2837 - accuracy: 0.1675 - val_loss: 2.0073 - val_accuracy: 0.3150\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 1.9125 - accuracy: 0.3512 - val_loss: 1.6865 - val_accuracy: 0.5350\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.6109 - accuracy: 0.5038 - val_loss: 1.4160 - val_accuracy: 0.6650\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.3677 - accuracy: 0.5838 - val_loss: 1.1906 - val_accuracy: 0.7250\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 1.2099 - accuracy: 0.6413 - val_loss: 1.0279 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.0584 - accuracy: 0.6975 - val_loss: 0.9297 - val_accuracy: 0.8000\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.9797 - accuracy: 0.7100 - val_loss: 0.8618 - val_accuracy: 0.7900\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.8718 - accuracy: 0.7400 - val_loss: 0.7923 - val_accuracy: 0.7850\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.8701 - accuracy: 0.7250 - val_loss: 0.7578 - val_accuracy: 0.8000\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.7849 - accuracy: 0.7688 - val_loss: 0.7363 - val_accuracy: 0.8000\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.7397 - accuracy: 0.7700 - val_loss: 0.7094 - val_accuracy: 0.8050\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6678 - accuracy: 0.7975 - val_loss: 0.6662 - val_accuracy: 0.8250\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6529 - accuracy: 0.8087 - val_loss: 0.6505 - val_accuracy: 0.7850\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6420 - accuracy: 0.7912 - val_loss: 0.6244 - val_accuracy: 0.7900\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5820 - accuracy: 0.8300 - val_loss: 0.6137 - val_accuracy: 0.8200\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5823 - accuracy: 0.8125 - val_loss: 0.6015 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5266 - accuracy: 0.8363 - val_loss: 0.5877 - val_accuracy: 0.7950\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5255 - accuracy: 0.8438 - val_loss: 0.5791 - val_accuracy: 0.8150\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5207 - accuracy: 0.8338 - val_loss: 0.5689 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4850 - accuracy: 0.8450 - val_loss: 0.5673 - val_accuracy: 0.8150\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4794 - accuracy: 0.8487 - val_loss: 0.5673 - val_accuracy: 0.8100\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4438 - accuracy: 0.8625 - val_loss: 0.5727 - val_accuracy: 0.8150\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4514 - accuracy: 0.8725 - val_loss: 0.5477 - val_accuracy: 0.8300\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4212 - accuracy: 0.8725 - val_loss: 0.5515 - val_accuracy: 0.8200\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4055 - accuracy: 0.8775 - val_loss: 0.5553 - val_accuracy: 0.8300\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4397 - accuracy: 0.8650 - val_loss: 0.5640 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3920 - accuracy: 0.8775 - val_loss: 0.5497 - val_accuracy: 0.8300\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3738 - accuracy: 0.8888 - val_loss: 0.5408 - val_accuracy: 0.8050\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3746 - accuracy: 0.8925 - val_loss: 0.5430 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3635 - accuracy: 0.8913 - val_loss: 0.5354 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3596 - accuracy: 0.8900 - val_loss: 0.5558 - val_accuracy: 0.8200\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3393 - accuracy: 0.8975 - val_loss: 0.5520 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3021 - accuracy: 0.9112 - val_loss: 0.5295 - val_accuracy: 0.8200\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3111 - accuracy: 0.8963 - val_loss: 0.5393 - val_accuracy: 0.8200\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2970 - accuracy: 0.9225 - val_loss: 0.5259 - val_accuracy: 0.8250\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3191 - accuracy: 0.9025 - val_loss: 0.5479 - val_accuracy: 0.8150\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3091 - accuracy: 0.9075 - val_loss: 0.5277 - val_accuracy: 0.8100\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3209 - accuracy: 0.9075 - val_loss: 0.5576 - val_accuracy: 0.8200\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2737 - accuracy: 0.9237 - val_loss: 0.5319 - val_accuracy: 0.8350\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2628 - accuracy: 0.9250 - val_loss: 0.5488 - val_accuracy: 0.8100\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2783 - accuracy: 0.9175 - val_loss: 0.5303 - val_accuracy: 0.8400\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2844 - accuracy: 0.9212 - val_loss: 0.5117 - val_accuracy: 0.8300\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2708 - accuracy: 0.9162 - val_loss: 0.5164 - val_accuracy: 0.8250\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2458 - accuracy: 0.9287 - val_loss: 0.5308 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2349 - accuracy: 0.9300 - val_loss: 0.5202 - val_accuracy: 0.8250\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2214 - accuracy: 0.9375 - val_loss: 0.5189 - val_accuracy: 0.8250\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2522 - accuracy: 0.9250 - val_loss: 0.5143 - val_accuracy: 0.8300\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2445 - accuracy: 0.9362 - val_loss: 0.5475 - val_accuracy: 0.8300\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2085 - accuracy: 0.9413 - val_loss: 0.5166 - val_accuracy: 0.8100\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2154 - accuracy: 0.9388 - val_loss: 0.5160 - val_accuracy: 0.8150\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 0.5160 - accuracy: 0.8150\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 6s 110ms/step - loss: 0.2387 - accuracy: 0.9212 - val_loss: 0.5104 - val_accuracy: 0.8200\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1710 - accuracy: 0.9488 - val_loss: 0.5188 - val_accuracy: 0.8200\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1403 - accuracy: 0.9575 - val_loss: 0.5219 - val_accuracy: 0.8250\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1208 - accuracy: 0.9638 - val_loss: 0.5500 - val_accuracy: 0.8250\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0999 - accuracy: 0.9737 - val_loss: 0.5600 - val_accuracy: 0.8300\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1253 - accuracy: 0.9613 - val_loss: 0.5613 - val_accuracy: 0.8200\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0896 - accuracy: 0.9712 - val_loss: 0.5703 - val_accuracy: 0.8350\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0724 - accuracy: 0.9762 - val_loss: 0.5875 - val_accuracy: 0.8150\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0656 - accuracy: 0.9800 - val_loss: 0.5829 - val_accuracy: 0.8400\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0476 - accuracy: 0.9862 - val_loss: 0.5403 - val_accuracy: 0.8400\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 0.5611 - val_accuracy: 0.8400\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.6332 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0362 - accuracy: 0.9937 - val_loss: 0.6254 - val_accuracy: 0.8250\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0345 - accuracy: 0.9925 - val_loss: 0.6664 - val_accuracy: 0.8100\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0329 - accuracy: 0.9925 - val_loss: 0.6363 - val_accuracy: 0.8250\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.6643 - val_accuracy: 0.8250\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0214 - accuracy: 0.9962 - val_loss: 0.6309 - val_accuracy: 0.8450\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0450 - accuracy: 0.9837 - val_loss: 0.6237 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 0.6001 - val_accuracy: 0.8600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.6593 - val_accuracy: 0.8400\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 0.7171 - val_accuracy: 0.8200\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 2.5006 - accuracy: 0.0700\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 2.3298 - accuracy: 0.1375 - val_loss: 2.0797 - val_accuracy: 0.3450\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 2.0074 - accuracy: 0.3200 - val_loss: 1.8232 - val_accuracy: 0.5150\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.7862 - accuracy: 0.4150 - val_loss: 1.5583 - val_accuracy: 0.6400\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.5046 - accuracy: 0.5525 - val_loss: 1.3246 - val_accuracy: 0.6950\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.3054 - accuracy: 0.6125 - val_loss: 1.1608 - val_accuracy: 0.7250\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.1501 - accuracy: 0.6700 - val_loss: 1.0303 - val_accuracy: 0.7200\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.0558 - accuracy: 0.6925 - val_loss: 0.9236 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.9336 - accuracy: 0.7287 - val_loss: 0.8597 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.8238 - accuracy: 0.7387 - val_loss: 0.8047 - val_accuracy: 0.7700\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.7789 - accuracy: 0.7738 - val_loss: 0.7802 - val_accuracy: 0.7800\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.7658 - accuracy: 0.7750 - val_loss: 0.7354 - val_accuracy: 0.7800\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.7190 - accuracy: 0.7837 - val_loss: 0.7142 - val_accuracy: 0.7900\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6791 - accuracy: 0.8000 - val_loss: 0.7011 - val_accuracy: 0.7950\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6174 - accuracy: 0.8163 - val_loss: 0.6677 - val_accuracy: 0.7950\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5752 - accuracy: 0.8388 - val_loss: 0.6594 - val_accuracy: 0.7950\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5661 - accuracy: 0.8250 - val_loss: 0.6468 - val_accuracy: 0.7900\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5835 - accuracy: 0.8425 - val_loss: 0.6214 - val_accuracy: 0.8100\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5507 - accuracy: 0.8450 - val_loss: 0.6186 - val_accuracy: 0.8150\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5158 - accuracy: 0.8525 - val_loss: 0.6222 - val_accuracy: 0.8000\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5049 - accuracy: 0.8438 - val_loss: 0.5950 - val_accuracy: 0.8200\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4708 - accuracy: 0.8600 - val_loss: 0.6119 - val_accuracy: 0.8200\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4415 - accuracy: 0.8725 - val_loss: 0.5865 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4537 - accuracy: 0.8675 - val_loss: 0.5662 - val_accuracy: 0.8150\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4241 - accuracy: 0.8700 - val_loss: 0.5784 - val_accuracy: 0.8100\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4165 - accuracy: 0.8788 - val_loss: 0.5922 - val_accuracy: 0.8100\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4239 - accuracy: 0.8700 - val_loss: 0.5665 - val_accuracy: 0.8200\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3822 - accuracy: 0.8988 - val_loss: 0.5491 - val_accuracy: 0.8350\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3843 - accuracy: 0.8938 - val_loss: 0.5406 - val_accuracy: 0.8350\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3871 - accuracy: 0.8800 - val_loss: 0.5420 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3733 - accuracy: 0.8975 - val_loss: 0.5664 - val_accuracy: 0.8300\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3570 - accuracy: 0.9050 - val_loss: 0.5394 - val_accuracy: 0.8250\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3307 - accuracy: 0.9087 - val_loss: 0.5388 - val_accuracy: 0.8450\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3338 - accuracy: 0.9062 - val_loss: 0.5536 - val_accuracy: 0.8300\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3325 - accuracy: 0.9062 - val_loss: 0.5486 - val_accuracy: 0.8250\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3425 - accuracy: 0.9000 - val_loss: 0.5577 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3267 - accuracy: 0.9000 - val_loss: 0.5359 - val_accuracy: 0.8450\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3093 - accuracy: 0.9187 - val_loss: 0.5525 - val_accuracy: 0.8400\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2804 - accuracy: 0.9187 - val_loss: 0.5320 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2727 - accuracy: 0.9287 - val_loss: 0.5414 - val_accuracy: 0.8500\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2567 - accuracy: 0.9362 - val_loss: 0.5592 - val_accuracy: 0.8300\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2753 - accuracy: 0.9312 - val_loss: 0.5368 - val_accuracy: 0.8450\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2789 - accuracy: 0.9225 - val_loss: 0.5206 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2541 - accuracy: 0.9212 - val_loss: 0.5263 - val_accuracy: 0.8450\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2295 - accuracy: 0.9300 - val_loss: 0.5527 - val_accuracy: 0.8100\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2682 - accuracy: 0.9225 - val_loss: 0.5240 - val_accuracy: 0.8300\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2507 - accuracy: 0.9237 - val_loss: 0.5221 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2285 - accuracy: 0.9362 - val_loss: 0.5158 - val_accuracy: 0.8550\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2291 - accuracy: 0.9325 - val_loss: 0.5227 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2621 - accuracy: 0.9275 - val_loss: 0.5193 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2450 - accuracy: 0.9262 - val_loss: 0.5287 - val_accuracy: 0.8600\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.5287 - accuracy: 0.8600\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.2422 - accuracy: 0.9287 - val_loss: 0.5022 - val_accuracy: 0.8600\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1650 - accuracy: 0.9488 - val_loss: 0.5003 - val_accuracy: 0.8600\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1442 - accuracy: 0.9600 - val_loss: 0.5085 - val_accuracy: 0.8750\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1224 - accuracy: 0.9550 - val_loss: 0.5268 - val_accuracy: 0.8600\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1162 - accuracy: 0.9650 - val_loss: 0.5564 - val_accuracy: 0.8650\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1001 - accuracy: 0.9712 - val_loss: 0.5234 - val_accuracy: 0.8650\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0967 - accuracy: 0.9737 - val_loss: 0.5698 - val_accuracy: 0.8700\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 0.5660 - val_accuracy: 0.8600\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 0.6209 - val_accuracy: 0.8450\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0579 - accuracy: 0.9800 - val_loss: 0.6028 - val_accuracy: 0.8700\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0684 - accuracy: 0.9762 - val_loss: 0.6131 - val_accuracy: 0.8650\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 0.5509 - val_accuracy: 0.8800\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0563 - accuracy: 0.9775 - val_loss: 0.6326 - val_accuracy: 0.8550\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 0.6056 - val_accuracy: 0.8700\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0403 - accuracy: 0.9837 - val_loss: 0.6222 - val_accuracy: 0.8800\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0523 - accuracy: 0.9787 - val_loss: 0.6390 - val_accuracy: 0.8750\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.6842 - val_accuracy: 0.8700\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.6657 - val_accuracy: 0.8700\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 0.7098 - val_accuracy: 0.8650\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.7309 - val_accuracy: 0.8750\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0243 - accuracy: 0.9900 - val_loss: 0.6786 - val_accuracy: 0.8650\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 2.4814 - accuracy: 0.1100\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 2.3133 - accuracy: 0.1612 - val_loss: 2.0416 - val_accuracy: 0.3350\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.9273 - accuracy: 0.3688 - val_loss: 1.7881 - val_accuracy: 0.4950\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.5993 - accuracy: 0.5038 - val_loss: 1.5519 - val_accuracy: 0.6050\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.4721 - accuracy: 0.5475 - val_loss: 1.3643 - val_accuracy: 0.6700\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.2329 - accuracy: 0.6187 - val_loss: 1.1981 - val_accuracy: 0.7200\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.0927 - accuracy: 0.6938 - val_loss: 1.1090 - val_accuracy: 0.6900\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.0009 - accuracy: 0.6975 - val_loss: 1.0242 - val_accuracy: 0.7350\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.8935 - accuracy: 0.7275 - val_loss: 0.9861 - val_accuracy: 0.7300\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.8258 - accuracy: 0.7450 - val_loss: 0.9284 - val_accuracy: 0.7550\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.7695 - accuracy: 0.7713 - val_loss: 0.8672 - val_accuracy: 0.7700\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.7177 - accuracy: 0.7725 - val_loss: 0.8509 - val_accuracy: 0.7400\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.6463 - accuracy: 0.8012 - val_loss: 0.8053 - val_accuracy: 0.7550\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.6258 - accuracy: 0.7925 - val_loss: 0.8007 - val_accuracy: 0.7450\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5925 - accuracy: 0.8188 - val_loss: 0.7838 - val_accuracy: 0.7600\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.5689 - accuracy: 0.8400 - val_loss: 0.8027 - val_accuracy: 0.7400\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5460 - accuracy: 0.8413 - val_loss: 0.7506 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5557 - accuracy: 0.8425 - val_loss: 0.7535 - val_accuracy: 0.7550\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4950 - accuracy: 0.8575 - val_loss: 0.7426 - val_accuracy: 0.7600\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4847 - accuracy: 0.8600 - val_loss: 0.7808 - val_accuracy: 0.7450\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4846 - accuracy: 0.8562 - val_loss: 0.7346 - val_accuracy: 0.7550\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4482 - accuracy: 0.8637 - val_loss: 0.7843 - val_accuracy: 0.7300\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.4568 - accuracy: 0.8675 - val_loss: 0.7282 - val_accuracy: 0.7450\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4142 - accuracy: 0.8737 - val_loss: 0.7105 - val_accuracy: 0.7500\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4153 - accuracy: 0.8712 - val_loss: 0.7039 - val_accuracy: 0.7700\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3848 - accuracy: 0.8900 - val_loss: 0.7066 - val_accuracy: 0.7600\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3839 - accuracy: 0.8850 - val_loss: 0.7038 - val_accuracy: 0.7550\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3646 - accuracy: 0.8875 - val_loss: 0.7150 - val_accuracy: 0.7700\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3730 - accuracy: 0.8875 - val_loss: 0.7269 - val_accuracy: 0.7300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3580 - accuracy: 0.8925 - val_loss: 0.6762 - val_accuracy: 0.7600\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3248 - accuracy: 0.9025 - val_loss: 0.6771 - val_accuracy: 0.7700\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3053 - accuracy: 0.9112 - val_loss: 0.6845 - val_accuracy: 0.7700\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3104 - accuracy: 0.9150 - val_loss: 0.6735 - val_accuracy: 0.7650\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3127 - accuracy: 0.9075 - val_loss: 0.6810 - val_accuracy: 0.7550\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3053 - accuracy: 0.9062 - val_loss: 0.6666 - val_accuracy: 0.7600\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3236 - accuracy: 0.9112 - val_loss: 0.6756 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3189 - accuracy: 0.9038 - val_loss: 0.6618 - val_accuracy: 0.7650\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2986 - accuracy: 0.9162 - val_loss: 0.6698 - val_accuracy: 0.7700\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2539 - accuracy: 0.9350 - val_loss: 0.6587 - val_accuracy: 0.7400\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2911 - accuracy: 0.9150 - val_loss: 0.6625 - val_accuracy: 0.7800\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2610 - accuracy: 0.9275 - val_loss: 0.6505 - val_accuracy: 0.7600\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2776 - accuracy: 0.9150 - val_loss: 0.6640 - val_accuracy: 0.7700\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2469 - accuracy: 0.9287 - val_loss: 0.6746 - val_accuracy: 0.7450\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2409 - accuracy: 0.9225 - val_loss: 0.7013 - val_accuracy: 0.7600\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2329 - accuracy: 0.9287 - val_loss: 0.6572 - val_accuracy: 0.7600\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2555 - accuracy: 0.9225 - val_loss: 0.6457 - val_accuracy: 0.7750\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.2266 - accuracy: 0.9275 - val_loss: 0.6817 - val_accuracy: 0.7450\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2165 - accuracy: 0.9413 - val_loss: 0.6493 - val_accuracy: 0.7700\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2370 - accuracy: 0.9362 - val_loss: 0.6462 - val_accuracy: 0.7700\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2091 - accuracy: 0.9463 - val_loss: 0.6525 - val_accuracy: 0.7650\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2094 - accuracy: 0.9388 - val_loss: 0.6583 - val_accuracy: 0.7600\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.6583 - accuracy: 0.7600\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 108ms/step - loss: 0.2126 - accuracy: 0.9337 - val_loss: 0.6315 - val_accuracy: 0.7800\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1563 - accuracy: 0.9525 - val_loss: 0.6741 - val_accuracy: 0.7800\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1368 - accuracy: 0.9638 - val_loss: 0.6234 - val_accuracy: 0.7900\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1167 - accuracy: 0.9650 - val_loss: 0.6713 - val_accuracy: 0.7800\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1051 - accuracy: 0.9638 - val_loss: 0.6580 - val_accuracy: 0.7850\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0910 - accuracy: 0.9775 - val_loss: 0.6710 - val_accuracy: 0.7950\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0711 - accuracy: 0.9812 - val_loss: 0.7054 - val_accuracy: 0.7800\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0599 - accuracy: 0.9837 - val_loss: 0.6766 - val_accuracy: 0.7900\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0701 - accuracy: 0.9787 - val_loss: 0.6505 - val_accuracy: 0.7750\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.6856 - val_accuracy: 0.7900\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0549 - accuracy: 0.9875 - val_loss: 0.6773 - val_accuracy: 0.8100\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 0.6941 - val_accuracy: 0.7850\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.7371 - val_accuracy: 0.7850\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.7550 - val_accuracy: 0.7850\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0388 - accuracy: 0.9912 - val_loss: 0.7754 - val_accuracy: 0.7850\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.7334 - val_accuracy: 0.7950\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 0.7244 - val_accuracy: 0.8150\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.7119 - val_accuracy: 0.7850\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.7301 - val_accuracy: 0.8000\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.8358 - val_accuracy: 0.7700\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.7479 - val_accuracy: 0.7900\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 2.5782 - accuracy: 0.0650\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 2.3242 - accuracy: 0.1550 - val_loss: 2.0113 - val_accuracy: 0.3600\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.9365 - accuracy: 0.3375 - val_loss: 1.7096 - val_accuracy: 0.5450\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 1.6544 - accuracy: 0.4863 - val_loss: 1.4248 - val_accuracy: 0.6350\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.3799 - accuracy: 0.5813 - val_loss: 1.2431 - val_accuracy: 0.6700\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.1843 - accuracy: 0.6712 - val_loss: 1.0847 - val_accuracy: 0.7200\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.0634 - accuracy: 0.7000 - val_loss: 0.9629 - val_accuracy: 0.7800\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.9713 - accuracy: 0.7175 - val_loss: 0.8828 - val_accuracy: 0.7850\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.8716 - accuracy: 0.7400 - val_loss: 0.8395 - val_accuracy: 0.7800\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.8254 - accuracy: 0.7500 - val_loss: 0.8279 - val_accuracy: 0.7600\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.7510 - accuracy: 0.7900 - val_loss: 0.7786 - val_accuracy: 0.7850\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.7138 - accuracy: 0.7850 - val_loss: 0.7389 - val_accuracy: 0.7900\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.6574 - accuracy: 0.8150 - val_loss: 0.7025 - val_accuracy: 0.8000\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.6662 - accuracy: 0.7950 - val_loss: 0.7229 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.6211 - accuracy: 0.8000 - val_loss: 0.6885 - val_accuracy: 0.7950\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.5600 - accuracy: 0.8475 - val_loss: 0.6766 - val_accuracy: 0.8050\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.5682 - accuracy: 0.8350 - val_loss: 0.6671 - val_accuracy: 0.8100\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.5141 - accuracy: 0.8512 - val_loss: 0.6633 - val_accuracy: 0.8150\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4948 - accuracy: 0.8475 - val_loss: 0.6615 - val_accuracy: 0.7900\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.4727 - accuracy: 0.8675 - val_loss: 0.6611 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.4646 - accuracy: 0.8737 - val_loss: 0.6410 - val_accuracy: 0.8000\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.4317 - accuracy: 0.8625 - val_loss: 0.6599 - val_accuracy: 0.7950\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.4114 - accuracy: 0.8800 - val_loss: 0.6326 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.4454 - accuracy: 0.8562 - val_loss: 0.6325 - val_accuracy: 0.8150\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.4019 - accuracy: 0.8700 - val_loss: 0.6289 - val_accuracy: 0.8000\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3993 - accuracy: 0.8825 - val_loss: 0.6237 - val_accuracy: 0.8100\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3949 - accuracy: 0.8863 - val_loss: 0.6194 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3673 - accuracy: 0.8888 - val_loss: 0.6083 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3521 - accuracy: 0.9025 - val_loss: 0.6179 - val_accuracy: 0.8050\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3532 - accuracy: 0.9013 - val_loss: 0.6200 - val_accuracy: 0.8100\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3459 - accuracy: 0.8875 - val_loss: 0.6048 - val_accuracy: 0.8200\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3332 - accuracy: 0.9125 - val_loss: 0.6228 - val_accuracy: 0.8050\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3644 - accuracy: 0.8850 - val_loss: 0.5950 - val_accuracy: 0.8150\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3155 - accuracy: 0.9187 - val_loss: 0.6206 - val_accuracy: 0.8150\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3335 - accuracy: 0.9100 - val_loss: 0.5956 - val_accuracy: 0.8000\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3010 - accuracy: 0.9250 - val_loss: 0.6138 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3199 - accuracy: 0.8988 - val_loss: 0.6030 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3292 - accuracy: 0.8938 - val_loss: 0.6104 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2986 - accuracy: 0.9087 - val_loss: 0.5935 - val_accuracy: 0.8150\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3033 - accuracy: 0.9112 - val_loss: 0.5991 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2557 - accuracy: 0.9337 - val_loss: 0.6229 - val_accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2808 - accuracy: 0.9225 - val_loss: 0.5998 - val_accuracy: 0.8000\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2833 - accuracy: 0.9162 - val_loss: 0.6019 - val_accuracy: 0.7950\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2511 - accuracy: 0.9162 - val_loss: 0.6060 - val_accuracy: 0.8100\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2492 - accuracy: 0.9325 - val_loss: 0.6029 - val_accuracy: 0.8050\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.2181 - accuracy: 0.9337 - val_loss: 0.5866 - val_accuracy: 0.8100\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2532 - accuracy: 0.9300 - val_loss: 0.6133 - val_accuracy: 0.7900\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.2358 - accuracy: 0.9362 - val_loss: 0.5927 - val_accuracy: 0.8100\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2644 - accuracy: 0.9275 - val_loss: 0.5993 - val_accuracy: 0.8100\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.2319 - accuracy: 0.9287 - val_loss: 0.6054 - val_accuracy: 0.8100\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2246 - accuracy: 0.9375 - val_loss: 0.5950 - val_accuracy: 0.8000\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.5950 - accuracy: 0.8000\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.2129 - accuracy: 0.9463 - val_loss: 0.5788 - val_accuracy: 0.8100\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1844 - accuracy: 0.9563 - val_loss: 0.6128 - val_accuracy: 0.8050\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1463 - accuracy: 0.9575 - val_loss: 0.6242 - val_accuracy: 0.8200\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1206 - accuracy: 0.9638 - val_loss: 0.6296 - val_accuracy: 0.8200\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1210 - accuracy: 0.9638 - val_loss: 0.5996 - val_accuracy: 0.8100\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0975 - accuracy: 0.9725 - val_loss: 0.6242 - val_accuracy: 0.8150\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.6583 - val_accuracy: 0.8100\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0629 - accuracy: 0.9837 - val_loss: 0.6929 - val_accuracy: 0.8200\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0505 - accuracy: 0.9887 - val_loss: 0.6951 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0713 - accuracy: 0.9787 - val_loss: 0.6637 - val_accuracy: 0.8300\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0560 - accuracy: 0.9837 - val_loss: 0.7817 - val_accuracy: 0.8300\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0491 - accuracy: 0.9862 - val_loss: 0.6926 - val_accuracy: 0.8450\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.6847 - val_accuracy: 0.8300\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0343 - accuracy: 0.9862 - val_loss: 0.7612 - val_accuracy: 0.8350\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.7662 - val_accuracy: 0.8500\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0312 - accuracy: 0.9975 - val_loss: 0.7326 - val_accuracy: 0.8450\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.8385 - val_accuracy: 0.8200\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.7446 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.8045 - val_accuracy: 0.8300\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 0.8134 - val_accuracy: 0.8250\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.9363 - val_accuracy: 0.8150\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 2.5049 - accuracy: 0.0900\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 2.3135 - accuracy: 0.1713 - val_loss: 2.0408 - val_accuracy: 0.3600\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.9834 - accuracy: 0.3225 - val_loss: 1.7565 - val_accuracy: 0.5700\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 1.6610 - accuracy: 0.4775 - val_loss: 1.4678 - val_accuracy: 0.6300\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 1.3987 - accuracy: 0.5950 - val_loss: 1.2463 - val_accuracy: 0.7050\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 1.2499 - accuracy: 0.6162 - val_loss: 1.1019 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 1.1139 - accuracy: 0.6750 - val_loss: 0.9940 - val_accuracy: 0.7550\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 1.0105 - accuracy: 0.7138 - val_loss: 0.8792 - val_accuracy: 0.7850\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.9087 - accuracy: 0.7300 - val_loss: 0.8380 - val_accuracy: 0.7650\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.8624 - accuracy: 0.7212 - val_loss: 0.8059 - val_accuracy: 0.7650\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.7972 - accuracy: 0.7725 - val_loss: 0.7415 - val_accuracy: 0.8050\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.7450 - accuracy: 0.7763 - val_loss: 0.7028 - val_accuracy: 0.7950\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.7111 - accuracy: 0.7962 - val_loss: 0.6928 - val_accuracy: 0.7950\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.6345 - accuracy: 0.8263 - val_loss: 0.6707 - val_accuracy: 0.8050\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.6430 - accuracy: 0.8125 - val_loss: 0.6402 - val_accuracy: 0.8150\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.5869 - accuracy: 0.8225 - val_loss: 0.6215 - val_accuracy: 0.8200\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.5476 - accuracy: 0.8450 - val_loss: 0.6068 - val_accuracy: 0.8450\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.5402 - accuracy: 0.8413 - val_loss: 0.5867 - val_accuracy: 0.8350\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.5232 - accuracy: 0.8363 - val_loss: 0.5962 - val_accuracy: 0.8450\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.5122 - accuracy: 0.8400 - val_loss: 0.5671 - val_accuracy: 0.8300\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.4808 - accuracy: 0.8537 - val_loss: 0.5636 - val_accuracy: 0.8450\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.4862 - accuracy: 0.8625 - val_loss: 0.5647 - val_accuracy: 0.8450\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.4590 - accuracy: 0.8562 - val_loss: 0.5451 - val_accuracy: 0.8350\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.4692 - accuracy: 0.8600 - val_loss: 0.5494 - val_accuracy: 0.8450\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.4304 - accuracy: 0.8788 - val_loss: 0.5356 - val_accuracy: 0.8400\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.4040 - accuracy: 0.8850 - val_loss: 0.5374 - val_accuracy: 0.8250\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.4140 - accuracy: 0.8612 - val_loss: 0.5242 - val_accuracy: 0.8350\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.3957 - accuracy: 0.8900 - val_loss: 0.5263 - val_accuracy: 0.8350\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3953 - accuracy: 0.8788 - val_loss: 0.5127 - val_accuracy: 0.8400\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3805 - accuracy: 0.8888 - val_loss: 0.5176 - val_accuracy: 0.8450\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3740 - accuracy: 0.8813 - val_loss: 0.5271 - val_accuracy: 0.8350\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.3587 - accuracy: 0.8900 - val_loss: 0.5189 - val_accuracy: 0.8400\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3545 - accuracy: 0.8950 - val_loss: 0.5243 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.3464 - accuracy: 0.9025 - val_loss: 0.5236 - val_accuracy: 0.8350\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3319 - accuracy: 0.9125 - val_loss: 0.5068 - val_accuracy: 0.8450\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.3246 - accuracy: 0.9038 - val_loss: 0.5068 - val_accuracy: 0.8450\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3234 - accuracy: 0.9038 - val_loss: 0.5218 - val_accuracy: 0.8350\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.3201 - accuracy: 0.9125 - val_loss: 0.5058 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2832 - accuracy: 0.9200 - val_loss: 0.4950 - val_accuracy: 0.8300\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 4s 72ms/step - loss: 0.2707 - accuracy: 0.9325 - val_loss: 0.4909 - val_accuracy: 0.8450\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2773 - accuracy: 0.9175 - val_loss: 0.4954 - val_accuracy: 0.8450\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2435 - accuracy: 0.9388 - val_loss: 0.4904 - val_accuracy: 0.8450\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2774 - accuracy: 0.9162 - val_loss: 0.4880 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2544 - accuracy: 0.9300 - val_loss: 0.4861 - val_accuracy: 0.8450\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2755 - accuracy: 0.9162 - val_loss: 0.4858 - val_accuracy: 0.8400\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2514 - accuracy: 0.9212 - val_loss: 0.4858 - val_accuracy: 0.8400\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.2579 - accuracy: 0.9300 - val_loss: 0.4757 - val_accuracy: 0.8550\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2740 - accuracy: 0.9137 - val_loss: 0.4743 - val_accuracy: 0.8500\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 4s 70ms/step - loss: 0.2407 - accuracy: 0.9300 - val_loss: 0.4671 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.2229 - accuracy: 0.9362 - val_loss: 0.4715 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.2236 - accuracy: 0.9375 - val_loss: 0.4689 - val_accuracy: 0.8450\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.4689 - accuracy: 0.8450\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 6s 111ms/step - loss: 0.2327 - accuracy: 0.9262 - val_loss: 0.4551 - val_accuracy: 0.8550\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1784 - accuracy: 0.9438 - val_loss: 0.4569 - val_accuracy: 0.8400\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1531 - accuracy: 0.9438 - val_loss: 0.4411 - val_accuracy: 0.8600\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.1089 - accuracy: 0.9700 - val_loss: 0.4509 - val_accuracy: 0.8600\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1082 - accuracy: 0.9688 - val_loss: 0.4473 - val_accuracy: 0.8500\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.1063 - accuracy: 0.9600 - val_loss: 0.4585 - val_accuracy: 0.8550\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0859 - accuracy: 0.9762 - val_loss: 0.4661 - val_accuracy: 0.8650\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0649 - accuracy: 0.9800 - val_loss: 0.4854 - val_accuracy: 0.8650\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0717 - accuracy: 0.9825 - val_loss: 0.4882 - val_accuracy: 0.8750\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 0.4906 - val_accuracy: 0.8650\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0560 - accuracy: 0.9762 - val_loss: 0.4914 - val_accuracy: 0.8700\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0500 - accuracy: 0.9875 - val_loss: 0.4676 - val_accuracy: 0.8700\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0362 - accuracy: 0.9925 - val_loss: 0.4800 - val_accuracy: 0.8700\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.4769 - val_accuracy: 0.8800\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 0.4721 - val_accuracy: 0.8650\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 0.4744 - val_accuracy: 0.8800\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.5010 - val_accuracy: 0.8850\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0511 - accuracy: 0.9812 - val_loss: 0.4925 - val_accuracy: 0.8850\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8850\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.5154 - val_accuracy: 0.8750\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.5218 - val_accuracy: 0.8700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbf0213-3e33-4cc7-ac40-3f70ec2220a8"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.08700000047683716\n",
            "Accuracy before fine-tuning: 0.8160000085830689\n",
            "Final accuracy: 0.8580000042915344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0847499b-cff8-4040-8575-a703e2b5d9ba"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a29e0942-5144-46ff-8144-5c3ed36025c1"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}