{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-resnet-balanced-modified-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdPDa27PN6BwqdW9SfBLJ2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60dcbd76-299a-4a7c-fcbd-5d15b626d3bc"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c5f90b-73ad-4c00-bbeb-4825fd3f47e5"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create list containing the dataset for each class\n",
        "ds_each_class = [tf.data.Dataset.list_files(str(data_dir/f'{class_name}/*.jpg'), shuffle=False) for class_name in class_names]\n",
        "\n",
        "# shuffle the 100 images in each class with the random seed value of 123 before training\n",
        "for index, ds in enumerate(ds_each_class):\n",
        "  ds_each_class[index] = ds.shuffle(image_count//10, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_LijJpqbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3975626a-873c-4568-c7e1-f839ae3fb1de"
      },
      "source": [
        "# display some samples from a class to verify each class dataset contains only the class images\n",
        "for f in ds_each_class[0].take(10):\n",
        "  print(f.numpy())\n",
        "\n",
        "for f in ds_each_class[1].take(10):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'FMD/image/fabric/fabric_moderate_037_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_004_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_008_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_003_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_017_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_001_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_032_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_030_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_038_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_009_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_037_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_004_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_008_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_053_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_067_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_051_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_032_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_030_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_038_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_059_new.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split first class dataset into 5 equal sized partitions\n",
        "# then for remaining classes' datasets do the same and add to corresponding partition\n",
        "# for 5-fold cross validation\n",
        "A = ds_each_class[0].shard(num_shards=5, index=0)\n",
        "B = ds_each_class[0].shard(num_shards=5, index=1)\n",
        "C = ds_each_class[0].shard(num_shards=5, index=2)\n",
        "D = ds_each_class[0].shard(num_shards=5, index=3)\n",
        "E = ds_each_class[0].shard(num_shards=5, index=4)\n",
        "for i in range(1, 10):\n",
        "  A = A.concatenate(ds_each_class[i].shard(num_shards=5, index=0))\n",
        "  B = B.concatenate(ds_each_class[i].shard(num_shards=5, index=1))\n",
        "  C = C.concatenate(ds_each_class[i].shard(num_shards=5, index=2))\n",
        "  D = D.concatenate(ds_each_class[i].shard(num_shards=5, index=3))\n",
        "  E = E.concatenate(ds_each_class[i].shard(num_shards=5, index=4))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01421ab-bbcf-4c32-bdf3-16db298137a4"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df641717-88cf-4687-ad3c-16cdf540aa5f"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = -27"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0319fb1-510c-4fd3-97b8-cf8a9eeac445"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.ResNet50V2(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 6s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 229ms/step - loss: 2.5586 - accuracy: 0.1200\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 240ms/step - loss: 2.3083 - accuracy: 0.1963 - val_loss: 1.9055 - val_accuracy: 0.3800\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 238ms/step - loss: 1.8356 - accuracy: 0.3638 - val_loss: 1.5184 - val_accuracy: 0.5700\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 238ms/step - loss: 1.5197 - accuracy: 0.5000 - val_loss: 1.2198 - val_accuracy: 0.6750\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 240ms/step - loss: 1.2535 - accuracy: 0.6025 - val_loss: 1.0126 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 240ms/step - loss: 1.0746 - accuracy: 0.6737 - val_loss: 0.8796 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 240ms/step - loss: 0.9523 - accuracy: 0.7088 - val_loss: 0.7840 - val_accuracy: 0.7700\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.8689 - accuracy: 0.7225 - val_loss: 0.7217 - val_accuracy: 0.7950\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.7822 - accuracy: 0.7500 - val_loss: 0.6710 - val_accuracy: 0.7900\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.7174 - accuracy: 0.7788 - val_loss: 0.6445 - val_accuracy: 0.8050\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.6747 - accuracy: 0.7887 - val_loss: 0.6148 - val_accuracy: 0.8100\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6231 - accuracy: 0.8062 - val_loss: 0.6041 - val_accuracy: 0.8150\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.5833 - accuracy: 0.8163 - val_loss: 0.5810 - val_accuracy: 0.8250\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 242ms/step - loss: 0.5399 - accuracy: 0.8300 - val_loss: 0.5735 - val_accuracy: 0.8150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4904 - accuracy: 0.8550 - val_loss: 0.5707 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.5168 - accuracy: 0.8388 - val_loss: 0.5555 - val_accuracy: 0.8150\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4551 - accuracy: 0.8562 - val_loss: 0.5525 - val_accuracy: 0.8300\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4537 - accuracy: 0.8525 - val_loss: 0.5437 - val_accuracy: 0.8300\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4357 - accuracy: 0.8438 - val_loss: 0.5425 - val_accuracy: 0.8250\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 242ms/step - loss: 0.4305 - accuracy: 0.8625 - val_loss: 0.5397 - val_accuracy: 0.8350\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4186 - accuracy: 0.8737 - val_loss: 0.5393 - val_accuracy: 0.8100\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3751 - accuracy: 0.8875 - val_loss: 0.5379 - val_accuracy: 0.8250\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3732 - accuracy: 0.8925 - val_loss: 0.5231 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3439 - accuracy: 0.8888 - val_loss: 0.5397 - val_accuracy: 0.8100\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3386 - accuracy: 0.8925 - val_loss: 0.5395 - val_accuracy: 0.8200\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3244 - accuracy: 0.9038 - val_loss: 0.5350 - val_accuracy: 0.8150\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2877 - accuracy: 0.9075 - val_loss: 0.5221 - val_accuracy: 0.8300\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3040 - accuracy: 0.9112 - val_loss: 0.5286 - val_accuracy: 0.8250\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2840 - accuracy: 0.9175 - val_loss: 0.5344 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2467 - accuracy: 0.9300 - val_loss: 0.5376 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2892 - accuracy: 0.9050 - val_loss: 0.5373 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2557 - accuracy: 0.9250 - val_loss: 0.5589 - val_accuracy: 0.8150\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2866 - accuracy: 0.9150 - val_loss: 0.5325 - val_accuracy: 0.8150\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2392 - accuracy: 0.9300 - val_loss: 0.5246 - val_accuracy: 0.8200\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2617 - accuracy: 0.9225 - val_loss: 0.5377 - val_accuracy: 0.8300\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2330 - accuracy: 0.9400 - val_loss: 0.5351 - val_accuracy: 0.8100\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2127 - accuracy: 0.9413 - val_loss: 0.5322 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2049 - accuracy: 0.9463 - val_loss: 0.5455 - val_accuracy: 0.7950\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2177 - accuracy: 0.9362 - val_loss: 0.5457 - val_accuracy: 0.8000\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1819 - accuracy: 0.9500 - val_loss: 0.5467 - val_accuracy: 0.8050\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1985 - accuracy: 0.9425 - val_loss: 0.5447 - val_accuracy: 0.7950\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1957 - accuracy: 0.9475 - val_loss: 0.5315 - val_accuracy: 0.8250\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1661 - accuracy: 0.9563 - val_loss: 0.5359 - val_accuracy: 0.8200\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1784 - accuracy: 0.9525 - val_loss: 0.5450 - val_accuracy: 0.8150\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1600 - accuracy: 0.9563 - val_loss: 0.5473 - val_accuracy: 0.8250\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1657 - accuracy: 0.9500 - val_loss: 0.5544 - val_accuracy: 0.8050\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1815 - accuracy: 0.9488 - val_loss: 0.5577 - val_accuracy: 0.8150\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1640 - accuracy: 0.9588 - val_loss: 0.5486 - val_accuracy: 0.8100\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1704 - accuracy: 0.9413 - val_loss: 0.5538 - val_accuracy: 0.8150\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1565 - accuracy: 0.9625 - val_loss: 0.5386 - val_accuracy: 0.8250\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1573 - accuracy: 0.9563 - val_loss: 0.5415 - val_accuracy: 0.8300\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 0.5415 - accuracy: 0.8300\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 0.1353 - accuracy: 0.9550 - val_loss: 0.6350 - val_accuracy: 0.8250\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.1339 - accuracy: 0.9538 - val_loss: 0.5970 - val_accuracy: 0.8400\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.1327 - accuracy: 0.9625 - val_loss: 0.6177 - val_accuracy: 0.8450\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0665 - accuracy: 0.9775 - val_loss: 0.6210 - val_accuracy: 0.8250\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0754 - accuracy: 0.9725 - val_loss: 0.7159 - val_accuracy: 0.8300\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0792 - accuracy: 0.9750 - val_loss: 0.6862 - val_accuracy: 0.8200\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0741 - accuracy: 0.9812 - val_loss: 0.6582 - val_accuracy: 0.8100\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0905 - accuracy: 0.9638 - val_loss: 0.7744 - val_accuracy: 0.8200\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.7253 - val_accuracy: 0.8150\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0414 - accuracy: 0.9912 - val_loss: 0.7529 - val_accuracy: 0.8300\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0486 - accuracy: 0.9862 - val_loss: 0.7663 - val_accuracy: 0.8100\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.7249 - val_accuracy: 0.8250\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 0.7336 - val_accuracy: 0.8300\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.8175 - val_accuracy: 0.8300\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 0.7612 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 0.7387 - val_accuracy: 0.8250\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.7466 - val_accuracy: 0.8250\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.7783 - val_accuracy: 0.8350\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.8808 - val_accuracy: 0.8400\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.9354 - val_accuracy: 0.8250\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0323 - accuracy: 0.9825 - val_loss: 0.8501 - val_accuracy: 0.8200\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 175ms/step - loss: 2.5281 - accuracy: 0.1000\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 2.3891 - accuracy: 0.1813 - val_loss: 1.9128 - val_accuracy: 0.3700\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.8299 - accuracy: 0.3638 - val_loss: 1.5360 - val_accuracy: 0.5800\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.5060 - accuracy: 0.5163 - val_loss: 1.2626 - val_accuracy: 0.6750\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 1.2493 - accuracy: 0.6075 - val_loss: 1.0711 - val_accuracy: 0.7100\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 1.0584 - accuracy: 0.6900 - val_loss: 0.9348 - val_accuracy: 0.7300\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.9109 - accuracy: 0.7362 - val_loss: 0.8407 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.8608 - accuracy: 0.7300 - val_loss: 0.7741 - val_accuracy: 0.7800\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.7795 - accuracy: 0.7525 - val_loss: 0.7163 - val_accuracy: 0.8050\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.6947 - accuracy: 0.7850 - val_loss: 0.6880 - val_accuracy: 0.8000\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6294 - accuracy: 0.8050 - val_loss: 0.6559 - val_accuracy: 0.8100\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.6046 - accuracy: 0.8138 - val_loss: 0.6328 - val_accuracy: 0.8050\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.5966 - accuracy: 0.7987 - val_loss: 0.6130 - val_accuracy: 0.8100\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.5601 - accuracy: 0.8050 - val_loss: 0.6034 - val_accuracy: 0.8150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4990 - accuracy: 0.8525 - val_loss: 0.5872 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4949 - accuracy: 0.8475 - val_loss: 0.5763 - val_accuracy: 0.7950\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4604 - accuracy: 0.8413 - val_loss: 0.5630 - val_accuracy: 0.8250\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4344 - accuracy: 0.8625 - val_loss: 0.5505 - val_accuracy: 0.8250\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3847 - accuracy: 0.8725 - val_loss: 0.5328 - val_accuracy: 0.8200\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4005 - accuracy: 0.8675 - val_loss: 0.5293 - val_accuracy: 0.8150\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4053 - accuracy: 0.8637 - val_loss: 0.5271 - val_accuracy: 0.8150\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3573 - accuracy: 0.8813 - val_loss: 0.5195 - val_accuracy: 0.8350\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3655 - accuracy: 0.8825 - val_loss: 0.5149 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3424 - accuracy: 0.8950 - val_loss: 0.5164 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3324 - accuracy: 0.9087 - val_loss: 0.5147 - val_accuracy: 0.8300\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3179 - accuracy: 0.8963 - val_loss: 0.5152 - val_accuracy: 0.8350\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2948 - accuracy: 0.9050 - val_loss: 0.5158 - val_accuracy: 0.8300\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2669 - accuracy: 0.9237 - val_loss: 0.5126 - val_accuracy: 0.8350\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2955 - accuracy: 0.9087 - val_loss: 0.5079 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2827 - accuracy: 0.9100 - val_loss: 0.5061 - val_accuracy: 0.8350\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2669 - accuracy: 0.9237 - val_loss: 0.5052 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2545 - accuracy: 0.9175 - val_loss: 0.5030 - val_accuracy: 0.8050\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2096 - accuracy: 0.9362 - val_loss: 0.5035 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2592 - accuracy: 0.9175 - val_loss: 0.5109 - val_accuracy: 0.8250\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2746 - accuracy: 0.9137 - val_loss: 0.5191 - val_accuracy: 0.8200\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2471 - accuracy: 0.9200 - val_loss: 0.5175 - val_accuracy: 0.8250\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2253 - accuracy: 0.9325 - val_loss: 0.5088 - val_accuracy: 0.8350\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2080 - accuracy: 0.9337 - val_loss: 0.5078 - val_accuracy: 0.8100\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2149 - accuracy: 0.9400 - val_loss: 0.4965 - val_accuracy: 0.8150\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2030 - accuracy: 0.9475 - val_loss: 0.5035 - val_accuracy: 0.8100\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1814 - accuracy: 0.9488 - val_loss: 0.5110 - val_accuracy: 0.8300\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1805 - accuracy: 0.9525 - val_loss: 0.5086 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2007 - accuracy: 0.9350 - val_loss: 0.5141 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1709 - accuracy: 0.9513 - val_loss: 0.5204 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1887 - accuracy: 0.9450 - val_loss: 0.5248 - val_accuracy: 0.8300\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1527 - accuracy: 0.9575 - val_loss: 0.5212 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1494 - accuracy: 0.9638 - val_loss: 0.5125 - val_accuracy: 0.8350\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1787 - accuracy: 0.9538 - val_loss: 0.5149 - val_accuracy: 0.8400\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1623 - accuracy: 0.9500 - val_loss: 0.5070 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1496 - accuracy: 0.9600 - val_loss: 0.5088 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1613 - accuracy: 0.9513 - val_loss: 0.5014 - val_accuracy: 0.8500\n",
            "13/13 [==============================] - 2s 168ms/step - loss: 0.5014 - accuracy: 0.8500\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.1502 - accuracy: 0.9538 - val_loss: 0.5376 - val_accuracy: 0.8350\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.1234 - accuracy: 0.9538 - val_loss: 0.5871 - val_accuracy: 0.8400\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.1014 - accuracy: 0.9663 - val_loss: 0.5616 - val_accuracy: 0.8400\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0885 - accuracy: 0.9750 - val_loss: 0.5934 - val_accuracy: 0.8350\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0775 - accuracy: 0.9712 - val_loss: 0.6348 - val_accuracy: 0.8400\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0981 - accuracy: 0.9700 - val_loss: 0.6186 - val_accuracy: 0.8350\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0778 - accuracy: 0.9725 - val_loss: 0.5965 - val_accuracy: 0.8300\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0655 - accuracy: 0.9825 - val_loss: 0.5761 - val_accuracy: 0.8500\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0551 - accuracy: 0.9812 - val_loss: 0.6214 - val_accuracy: 0.8450\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 0.7012 - val_accuracy: 0.8300\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 299ms/step - loss: 0.0371 - accuracy: 0.9850 - val_loss: 0.6969 - val_accuracy: 0.8350\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0437 - accuracy: 0.9850 - val_loss: 0.6899 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.6904 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.7053 - val_accuracy: 0.8350\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.7534 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0474 - accuracy: 0.9862 - val_loss: 0.7130 - val_accuracy: 0.8450\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.7337 - val_accuracy: 0.8500\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.7230 - val_accuracy: 0.8400\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.7641 - val_accuracy: 0.8400\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.7688 - val_accuracy: 0.8350\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.8340 - val_accuracy: 0.8500\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 176ms/step - loss: 2.8860 - accuracy: 0.0850\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 2.4641 - accuracy: 0.1663 - val_loss: 2.0897 - val_accuracy: 0.3100\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 1.8832 - accuracy: 0.3425 - val_loss: 1.7028 - val_accuracy: 0.4900\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 1.5427 - accuracy: 0.4975 - val_loss: 1.3993 - val_accuracy: 0.6200\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 1.2777 - accuracy: 0.5950 - val_loss: 1.2082 - val_accuracy: 0.6750\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.0972 - accuracy: 0.6600 - val_loss: 1.0689 - val_accuracy: 0.7100\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.9846 - accuracy: 0.6975 - val_loss: 0.9785 - val_accuracy: 0.7150\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.7919 - accuracy: 0.7425 - val_loss: 0.9048 - val_accuracy: 0.7350\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.7588 - accuracy: 0.7788 - val_loss: 0.8642 - val_accuracy: 0.7300\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.6945 - accuracy: 0.7937 - val_loss: 0.8281 - val_accuracy: 0.7350\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.6081 - accuracy: 0.8087 - val_loss: 0.8056 - val_accuracy: 0.7400\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.6204 - accuracy: 0.8200 - val_loss: 0.7791 - val_accuracy: 0.7400\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5260 - accuracy: 0.8375 - val_loss: 0.7609 - val_accuracy: 0.7450\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.5517 - accuracy: 0.8275 - val_loss: 0.7455 - val_accuracy: 0.7600\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4643 - accuracy: 0.8575 - val_loss: 0.7410 - val_accuracy: 0.7550\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.5061 - accuracy: 0.8388 - val_loss: 0.7359 - val_accuracy: 0.7550\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4449 - accuracy: 0.8587 - val_loss: 0.7259 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4105 - accuracy: 0.8687 - val_loss: 0.7340 - val_accuracy: 0.7450\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4361 - accuracy: 0.8600 - val_loss: 0.7196 - val_accuracy: 0.7550\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 242ms/step - loss: 0.3838 - accuracy: 0.8800 - val_loss: 0.7248 - val_accuracy: 0.7600\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3669 - accuracy: 0.8825 - val_loss: 0.7217 - val_accuracy: 0.7600\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3707 - accuracy: 0.8750 - val_loss: 0.7178 - val_accuracy: 0.7600\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3520 - accuracy: 0.8950 - val_loss: 0.7220 - val_accuracy: 0.7700\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3217 - accuracy: 0.9025 - val_loss: 0.7218 - val_accuracy: 0.7650\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2971 - accuracy: 0.9212 - val_loss: 0.7024 - val_accuracy: 0.7600\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.3087 - accuracy: 0.9038 - val_loss: 0.7065 - val_accuracy: 0.7650\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3024 - accuracy: 0.9150 - val_loss: 0.7156 - val_accuracy: 0.7500\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2817 - accuracy: 0.9062 - val_loss: 0.7094 - val_accuracy: 0.7650\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2794 - accuracy: 0.9137 - val_loss: 0.7185 - val_accuracy: 0.7550\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2877 - accuracy: 0.9237 - val_loss: 0.7107 - val_accuracy: 0.7750\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2736 - accuracy: 0.9212 - val_loss: 0.7166 - val_accuracy: 0.7550\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2710 - accuracy: 0.9100 - val_loss: 0.7143 - val_accuracy: 0.7600\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2493 - accuracy: 0.9312 - val_loss: 0.7053 - val_accuracy: 0.7650\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2339 - accuracy: 0.9362 - val_loss: 0.7105 - val_accuracy: 0.7600\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2138 - accuracy: 0.9375 - val_loss: 0.6955 - val_accuracy: 0.7550\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2148 - accuracy: 0.9350 - val_loss: 0.7118 - val_accuracy: 0.7550\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1966 - accuracy: 0.9388 - val_loss: 0.7126 - val_accuracy: 0.7800\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2290 - accuracy: 0.9212 - val_loss: 0.7059 - val_accuracy: 0.7850\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2252 - accuracy: 0.9262 - val_loss: 0.6987 - val_accuracy: 0.7850\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1989 - accuracy: 0.9425 - val_loss: 0.6990 - val_accuracy: 0.7800\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2084 - accuracy: 0.9400 - val_loss: 0.6976 - val_accuracy: 0.7700\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1734 - accuracy: 0.9525 - val_loss: 0.7124 - val_accuracy: 0.7550\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1743 - accuracy: 0.9563 - val_loss: 0.7141 - val_accuracy: 0.7550\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1674 - accuracy: 0.9563 - val_loss: 0.6964 - val_accuracy: 0.7750\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1700 - accuracy: 0.9538 - val_loss: 0.6972 - val_accuracy: 0.7700\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1829 - accuracy: 0.9438 - val_loss: 0.7031 - val_accuracy: 0.7700\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1604 - accuracy: 0.9550 - val_loss: 0.6973 - val_accuracy: 0.7700\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 242ms/step - loss: 0.1780 - accuracy: 0.9425 - val_loss: 0.6983 - val_accuracy: 0.7750\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1601 - accuracy: 0.9538 - val_loss: 0.7128 - val_accuracy: 0.7650\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1761 - accuracy: 0.9450 - val_loss: 0.6925 - val_accuracy: 0.7700\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1501 - accuracy: 0.9625 - val_loss: 0.7004 - val_accuracy: 0.7750\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.7004 - accuracy: 0.7750\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.1588 - accuracy: 0.9425 - val_loss: 0.7547 - val_accuracy: 0.7950\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.1059 - accuracy: 0.9675 - val_loss: 0.7835 - val_accuracy: 0.7900\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.1055 - accuracy: 0.9700 - val_loss: 0.7960 - val_accuracy: 0.8050\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0944 - accuracy: 0.9688 - val_loss: 0.7882 - val_accuracy: 0.7750\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0790 - accuracy: 0.9712 - val_loss: 0.8734 - val_accuracy: 0.8000\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0734 - accuracy: 0.9750 - val_loss: 0.8561 - val_accuracy: 0.8100\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.8509 - val_accuracy: 0.8100\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.9269 - val_accuracy: 0.7950\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0634 - accuracy: 0.9750 - val_loss: 0.9276 - val_accuracy: 0.8000\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0638 - accuracy: 0.9737 - val_loss: 0.8936 - val_accuracy: 0.8150\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.8593 - val_accuracy: 0.8100\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0487 - accuracy: 0.9800 - val_loss: 0.8852 - val_accuracy: 0.8150\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.8735 - val_accuracy: 0.8200\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.9783 - val_accuracy: 0.8100\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 1.0001 - val_accuracy: 0.8150\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0347 - accuracy: 0.9825 - val_loss: 1.0255 - val_accuracy: 0.7950\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0256 - accuracy: 0.9962 - val_loss: 0.9790 - val_accuracy: 0.8100\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0241 - accuracy: 0.9887 - val_loss: 1.0367 - val_accuracy: 0.8050\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 1.0098 - val_accuracy: 0.8100\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 0.9884 - val_accuracy: 0.8100\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 300ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.9739 - val_accuracy: 0.8100\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 2.5506 - accuracy: 0.0500\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 2.3347 - accuracy: 0.1762 - val_loss: 1.9170 - val_accuracy: 0.3800\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.8385 - accuracy: 0.3587 - val_loss: 1.5345 - val_accuracy: 0.5600\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 1.4988 - accuracy: 0.5063 - val_loss: 1.2537 - val_accuracy: 0.6650\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.2594 - accuracy: 0.6125 - val_loss: 1.0581 - val_accuracy: 0.7150\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.1041 - accuracy: 0.6700 - val_loss: 0.9300 - val_accuracy: 0.7350\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.9429 - accuracy: 0.7100 - val_loss: 0.8449 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.8236 - accuracy: 0.7575 - val_loss: 0.7771 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.7370 - accuracy: 0.7675 - val_loss: 0.7383 - val_accuracy: 0.7350\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.7255 - accuracy: 0.7825 - val_loss: 0.7042 - val_accuracy: 0.7850\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6278 - accuracy: 0.7900 - val_loss: 0.6762 - val_accuracy: 0.7700\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.6269 - accuracy: 0.7937 - val_loss: 0.6307 - val_accuracy: 0.8050\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.5777 - accuracy: 0.8163 - val_loss: 0.6152 - val_accuracy: 0.8050\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.5394 - accuracy: 0.8112 - val_loss: 0.5999 - val_accuracy: 0.8150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.5165 - accuracy: 0.8250 - val_loss: 0.6034 - val_accuracy: 0.8100\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5070 - accuracy: 0.8438 - val_loss: 0.5844 - val_accuracy: 0.8200\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4648 - accuracy: 0.8587 - val_loss: 0.5629 - val_accuracy: 0.8300\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4222 - accuracy: 0.8712 - val_loss: 0.5415 - val_accuracy: 0.8350\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4062 - accuracy: 0.8737 - val_loss: 0.5436 - val_accuracy: 0.8450\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4207 - accuracy: 0.8650 - val_loss: 0.5379 - val_accuracy: 0.8350\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3989 - accuracy: 0.8750 - val_loss: 0.5293 - val_accuracy: 0.8350\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3667 - accuracy: 0.8988 - val_loss: 0.5170 - val_accuracy: 0.8450\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3408 - accuracy: 0.8975 - val_loss: 0.5066 - val_accuracy: 0.8500\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.3324 - accuracy: 0.9087 - val_loss: 0.5114 - val_accuracy: 0.8550\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3164 - accuracy: 0.8988 - val_loss: 0.5072 - val_accuracy: 0.8450\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2979 - accuracy: 0.9087 - val_loss: 0.4949 - val_accuracy: 0.8600\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2992 - accuracy: 0.9087 - val_loss: 0.4944 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3006 - accuracy: 0.9062 - val_loss: 0.4949 - val_accuracy: 0.8500\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2628 - accuracy: 0.9175 - val_loss: 0.4866 - val_accuracy: 0.8500\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2942 - accuracy: 0.9100 - val_loss: 0.4847 - val_accuracy: 0.8600\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2771 - accuracy: 0.9038 - val_loss: 0.4879 - val_accuracy: 0.8650\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2599 - accuracy: 0.9212 - val_loss: 0.4741 - val_accuracy: 0.8650\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2393 - accuracy: 0.9237 - val_loss: 0.4910 - val_accuracy: 0.8500\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2440 - accuracy: 0.9262 - val_loss: 0.4901 - val_accuracy: 0.8500\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2693 - accuracy: 0.9150 - val_loss: 0.4710 - val_accuracy: 0.8700\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2310 - accuracy: 0.9300 - val_loss: 0.4723 - val_accuracy: 0.8650\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2143 - accuracy: 0.9438 - val_loss: 0.4670 - val_accuracy: 0.8600\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2212 - accuracy: 0.9375 - val_loss: 0.4851 - val_accuracy: 0.8600\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2245 - accuracy: 0.9275 - val_loss: 0.4766 - val_accuracy: 0.8600\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.2028 - accuracy: 0.9425 - val_loss: 0.4717 - val_accuracy: 0.8600\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1764 - accuracy: 0.9488 - val_loss: 0.4795 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1974 - accuracy: 0.9488 - val_loss: 0.4852 - val_accuracy: 0.8500\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1849 - accuracy: 0.9413 - val_loss: 0.4715 - val_accuracy: 0.8650\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1980 - accuracy: 0.9500 - val_loss: 0.4846 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1607 - accuracy: 0.9625 - val_loss: 0.4853 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1691 - accuracy: 0.9538 - val_loss: 0.4713 - val_accuracy: 0.8600\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1816 - accuracy: 0.9450 - val_loss: 0.4698 - val_accuracy: 0.8700\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1546 - accuracy: 0.9525 - val_loss: 0.4816 - val_accuracy: 0.8600\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.4859 - val_accuracy: 0.8500\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1563 - accuracy: 0.9600 - val_loss: 0.4700 - val_accuracy: 0.8600\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1465 - accuracy: 0.9688 - val_loss: 0.4656 - val_accuracy: 0.8600\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.4656 - accuracy: 0.8600\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.1352 - accuracy: 0.9500 - val_loss: 0.5189 - val_accuracy: 0.8650\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0947 - accuracy: 0.9762 - val_loss: 0.5910 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0855 - accuracy: 0.9688 - val_loss: 0.5746 - val_accuracy: 0.8550\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0965 - accuracy: 0.9750 - val_loss: 0.6152 - val_accuracy: 0.8400\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.1072 - accuracy: 0.9688 - val_loss: 0.5635 - val_accuracy: 0.8650\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0935 - accuracy: 0.9650 - val_loss: 0.5758 - val_accuracy: 0.8500\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0550 - accuracy: 0.9850 - val_loss: 0.6841 - val_accuracy: 0.8450\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0688 - accuracy: 0.9775 - val_loss: 0.6022 - val_accuracy: 0.8700\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0638 - accuracy: 0.9750 - val_loss: 0.6668 - val_accuracy: 0.8300\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0429 - accuracy: 0.9812 - val_loss: 0.6326 - val_accuracy: 0.8450\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.6940 - val_accuracy: 0.8500\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.6883 - val_accuracy: 0.8400\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0473 - accuracy: 0.9812 - val_loss: 0.7480 - val_accuracy: 0.8350\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.7674 - val_accuracy: 0.8450\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.7258 - val_accuracy: 0.8450\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.7459 - val_accuracy: 0.8600\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.7420 - val_accuracy: 0.8550\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0297 - accuracy: 0.9925 - val_loss: 0.7212 - val_accuracy: 0.8550\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.7162 - val_accuracy: 0.8600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0092 - accuracy: 0.9962 - val_loss: 0.7897 - val_accuracy: 0.8400\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 0.8186 - val_accuracy: 0.8450\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 180ms/step - loss: 2.5448 - accuracy: 0.1000\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 2.3631 - accuracy: 0.1600 - val_loss: 1.8818 - val_accuracy: 0.3750\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 1.8097 - accuracy: 0.3738 - val_loss: 1.4967 - val_accuracy: 0.5650\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 1.4605 - accuracy: 0.5350 - val_loss: 1.2015 - val_accuracy: 0.6700\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.2128 - accuracy: 0.6250 - val_loss: 0.9974 - val_accuracy: 0.7400\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 1.0419 - accuracy: 0.6812 - val_loss: 0.8575 - val_accuracy: 0.7800\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.9108 - accuracy: 0.7212 - val_loss: 0.7733 - val_accuracy: 0.8050\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.7899 - accuracy: 0.7600 - val_loss: 0.7077 - val_accuracy: 0.8000\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.7484 - accuracy: 0.7663 - val_loss: 0.6565 - val_accuracy: 0.8050\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.6979 - accuracy: 0.7950 - val_loss: 0.6139 - val_accuracy: 0.8050\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.6632 - accuracy: 0.7725 - val_loss: 0.5841 - val_accuracy: 0.8300\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.6152 - accuracy: 0.7950 - val_loss: 0.5516 - val_accuracy: 0.8450\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.5358 - accuracy: 0.8300 - val_loss: 0.5464 - val_accuracy: 0.8300\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.5428 - accuracy: 0.8288 - val_loss: 0.5241 - val_accuracy: 0.8400\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4975 - accuracy: 0.8375 - val_loss: 0.5228 - val_accuracy: 0.8400\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4860 - accuracy: 0.8575 - val_loss: 0.5173 - val_accuracy: 0.8350\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4657 - accuracy: 0.8475 - val_loss: 0.5001 - val_accuracy: 0.8550\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4370 - accuracy: 0.8562 - val_loss: 0.4916 - val_accuracy: 0.8250\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4275 - accuracy: 0.8712 - val_loss: 0.4864 - val_accuracy: 0.8400\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4006 - accuracy: 0.8838 - val_loss: 0.4817 - val_accuracy: 0.8400\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3775 - accuracy: 0.8750 - val_loss: 0.4678 - val_accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.3937 - accuracy: 0.8625 - val_loss: 0.4621 - val_accuracy: 0.8400\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3687 - accuracy: 0.8875 - val_loss: 0.4601 - val_accuracy: 0.8600\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3342 - accuracy: 0.8825 - val_loss: 0.4585 - val_accuracy: 0.8500\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3204 - accuracy: 0.9125 - val_loss: 0.4619 - val_accuracy: 0.8500\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.3144 - accuracy: 0.8988 - val_loss: 0.4580 - val_accuracy: 0.8450\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3095 - accuracy: 0.9038 - val_loss: 0.4604 - val_accuracy: 0.8500\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2845 - accuracy: 0.9100 - val_loss: 0.4567 - val_accuracy: 0.8450\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2835 - accuracy: 0.9150 - val_loss: 0.4555 - val_accuracy: 0.8650\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2907 - accuracy: 0.9162 - val_loss: 0.4571 - val_accuracy: 0.8600\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2866 - accuracy: 0.9025 - val_loss: 0.4602 - val_accuracy: 0.8450\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2468 - accuracy: 0.9225 - val_loss: 0.4574 - val_accuracy: 0.8600\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2660 - accuracy: 0.9087 - val_loss: 0.4516 - val_accuracy: 0.8550\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2398 - accuracy: 0.9300 - val_loss: 0.4534 - val_accuracy: 0.8450\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2341 - accuracy: 0.9325 - val_loss: 0.4389 - val_accuracy: 0.8550\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2075 - accuracy: 0.9362 - val_loss: 0.4473 - val_accuracy: 0.8500\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1982 - accuracy: 0.9425 - val_loss: 0.4417 - val_accuracy: 0.8450\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.2305 - accuracy: 0.9400 - val_loss: 0.4494 - val_accuracy: 0.8350\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2172 - accuracy: 0.9312 - val_loss: 0.4510 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2013 - accuracy: 0.9425 - val_loss: 0.4458 - val_accuracy: 0.8600\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2218 - accuracy: 0.9337 - val_loss: 0.4512 - val_accuracy: 0.8400\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1876 - accuracy: 0.9525 - val_loss: 0.4444 - val_accuracy: 0.8400\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1929 - accuracy: 0.9425 - val_loss: 0.4519 - val_accuracy: 0.8500\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1727 - accuracy: 0.9475 - val_loss: 0.4587 - val_accuracy: 0.8450\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1819 - accuracy: 0.9438 - val_loss: 0.4480 - val_accuracy: 0.8500\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1838 - accuracy: 0.9513 - val_loss: 0.4491 - val_accuracy: 0.8450\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1791 - accuracy: 0.9450 - val_loss: 0.4460 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1652 - accuracy: 0.9563 - val_loss: 0.4526 - val_accuracy: 0.8500\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1835 - accuracy: 0.9475 - val_loss: 0.4589 - val_accuracy: 0.8550\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1616 - accuracy: 0.9588 - val_loss: 0.4575 - val_accuracy: 0.8400\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1530 - accuracy: 0.9600 - val_loss: 0.4488 - val_accuracy: 0.8350\n",
            "13/13 [==============================] - 2s 168ms/step - loss: 0.4488 - accuracy: 0.8350\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.1612 - accuracy: 0.9525 - val_loss: 0.5011 - val_accuracy: 0.8300\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.1055 - accuracy: 0.9575 - val_loss: 0.5288 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.0906 - accuracy: 0.9725 - val_loss: 0.5193 - val_accuracy: 0.8400\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.1093 - accuracy: 0.9688 - val_loss: 0.5573 - val_accuracy: 0.8300\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0577 - accuracy: 0.9837 - val_loss: 0.5077 - val_accuracy: 0.8300\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 0.5399 - val_accuracy: 0.8250\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0695 - accuracy: 0.9862 - val_loss: 0.5127 - val_accuracy: 0.8350\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0620 - accuracy: 0.9775 - val_loss: 0.5529 - val_accuracy: 0.8400\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.6054 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0531 - accuracy: 0.9800 - val_loss: 0.5379 - val_accuracy: 0.8500\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.5907 - val_accuracy: 0.8450\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0459 - accuracy: 0.9850 - val_loss: 0.6095 - val_accuracy: 0.8250\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0268 - accuracy: 0.9937 - val_loss: 0.6325 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 0.5892 - val_accuracy: 0.8500\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.6248 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.6763 - val_accuracy: 0.8250\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.6641 - val_accuracy: 0.8400\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.7296 - val_accuracy: 0.8400\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.6843 - val_accuracy: 0.8500\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.7561 - val_accuracy: 0.8300\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.7131 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e457f367-7c36-4a21-be63-748e9ffc60d6"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.0910000003874302\n",
            "Accuracy before fine-tuning: 0.8299999952316284\n",
            "Final accuracy: 0.850000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "030af84f-89f2-410c-9ef5-bec2376cb9f7"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "29437802-5ac9-48bc-df23-b2fcd4ae1b14"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}