{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-xception-balanced-modified-cross-validated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVwsmF8U925SL7v45DomLn"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b8fb83-2707-4bb0-b30d-706db0e7f828"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9bcf3c-b2ca-46f9-e422-f149c07629b9"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create list containing the dataset for each class\n",
        "ds_each_class = [tf.data.Dataset.list_files(str(data_dir/f'{class_name}/*.jpg'), shuffle=False) for class_name in class_names]\n",
        "\n",
        "# shuffle the 100 images in each class with the random seed value of 123 before training\n",
        "for index, ds in enumerate(ds_each_class):\n",
        "  ds_each_class[index] = ds.shuffle(image_count//10, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_LijJpqbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f41b202-2f16-4fff-9432-ef36d444a392"
      },
      "source": [
        "# display some samples from a class to verify each class dataset contains only the class images\n",
        "for f in ds_each_class[0].take(10):\n",
        "  print(f.numpy())\n",
        "\n",
        "for f in ds_each_class[1].take(10):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'FMD/image/fabric/fabric_moderate_037_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_004_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_008_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_003_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_017_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_001_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_032_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_030_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_038_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_009_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_037_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_004_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_008_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_053_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_067_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_051_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_032_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_030_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_038_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_059_new.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split first class dataset into 5 equal sized partitions\n",
        "# then for remaining classes' datasets do the same and add to corresponding partition\n",
        "# for 5-fold cross validation\n",
        "A = ds_each_class[0].shard(num_shards=5, index=0)\n",
        "B = ds_each_class[0].shard(num_shards=5, index=1)\n",
        "C = ds_each_class[0].shard(num_shards=5, index=2)\n",
        "D = ds_each_class[0].shard(num_shards=5, index=3)\n",
        "E = ds_each_class[0].shard(num_shards=5, index=4)\n",
        "for i in range(1, 10):\n",
        "  A = A.concatenate(ds_each_class[i].shard(num_shards=5, index=0))\n",
        "  B = B.concatenate(ds_each_class[i].shard(num_shards=5, index=1))\n",
        "  C = C.concatenate(ds_each_class[i].shard(num_shards=5, index=2))\n",
        "  D = D.concatenate(ds_each_class[i].shard(num_shards=5, index=3))\n",
        "  E = E.concatenate(ds_each_class[i].shard(num_shards=5, index=4))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb95289d-d574-4d9c-9c42-55caee25e7f1"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66c8a36-4848-4595-f3a5-4b7f5dcf11a4"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.xception.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVOP5fIPwEx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528f9770-5405-4aa1-9e14-42f14b33d864"
      },
      "source": [
        "# get pre-trained model\n",
        "base_model = keras.applications.Xception(include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2kAceGVW0e"
      },
      "source": [
        "# don't train base model weights\n",
        "base_model.trainable = False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGkReMX60ScJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e46b4e-c5a1-414d-e497-d0fafbf0551b"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,861,480\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model():\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 100"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97aa1b89-23eb-463b-cee1-c95e6a5a62f2"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model()\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy']))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3537 - accuracy: 0.1100\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 2.2156 - accuracy: 0.2037 - val_loss: 2.0694 - val_accuracy: 0.3850\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 1.9280 - accuracy: 0.4212 - val_loss: 1.7821 - val_accuracy: 0.6150\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 1.6437 - accuracy: 0.5925 - val_loss: 1.5037 - val_accuracy: 0.7100\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 8s 158ms/step - loss: 1.3655 - accuracy: 0.6938 - val_loss: 1.2770 - val_accuracy: 0.7350\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 8s 159ms/step - loss: 1.1726 - accuracy: 0.7200 - val_loss: 1.0985 - val_accuracy: 0.7850\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 8s 160ms/step - loss: 1.0106 - accuracy: 0.7625 - val_loss: 0.9803 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 0.8959 - accuracy: 0.7862 - val_loss: 0.8934 - val_accuracy: 0.8100\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.8296 - accuracy: 0.7950 - val_loss: 0.8240 - val_accuracy: 0.8100\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 0.7370 - accuracy: 0.8188 - val_loss: 0.7718 - val_accuracy: 0.8150\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 0.6876 - accuracy: 0.8238 - val_loss: 0.7330 - val_accuracy: 0.8200\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.6501 - accuracy: 0.8300 - val_loss: 0.7034 - val_accuracy: 0.8200\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5992 - accuracy: 0.8512 - val_loss: 0.6841 - val_accuracy: 0.8200\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5845 - accuracy: 0.8562 - val_loss: 0.6491 - val_accuracy: 0.8300\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.5236 - accuracy: 0.8625 - val_loss: 0.6265 - val_accuracy: 0.8400\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.5162 - accuracy: 0.8750 - val_loss: 0.6174 - val_accuracy: 0.8300\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4842 - accuracy: 0.8737 - val_loss: 0.6014 - val_accuracy: 0.8600\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4680 - accuracy: 0.8800 - val_loss: 0.5855 - val_accuracy: 0.8450\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4541 - accuracy: 0.8725 - val_loss: 0.5848 - val_accuracy: 0.8600\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4248 - accuracy: 0.8900 - val_loss: 0.5663 - val_accuracy: 0.8600\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4251 - accuracy: 0.9000 - val_loss: 0.5577 - val_accuracy: 0.8500\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4016 - accuracy: 0.9038 - val_loss: 0.5726 - val_accuracy: 0.8750\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3850 - accuracy: 0.9013 - val_loss: 0.5376 - val_accuracy: 0.8600\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3858 - accuracy: 0.8925 - val_loss: 0.5436 - val_accuracy: 0.8750\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3999 - accuracy: 0.8950 - val_loss: 0.5308 - val_accuracy: 0.8650\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3638 - accuracy: 0.9100 - val_loss: 0.5326 - val_accuracy: 0.8700\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3287 - accuracy: 0.9150 - val_loss: 0.5325 - val_accuracy: 0.8650\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3284 - accuracy: 0.9100 - val_loss: 0.5237 - val_accuracy: 0.8650\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3300 - accuracy: 0.9087 - val_loss: 0.5191 - val_accuracy: 0.8800\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2897 - accuracy: 0.9375 - val_loss: 0.5234 - val_accuracy: 0.8700\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3107 - accuracy: 0.9062 - val_loss: 0.5050 - val_accuracy: 0.8700\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2952 - accuracy: 0.9325 - val_loss: 0.5195 - val_accuracy: 0.8500\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2749 - accuracy: 0.9450 - val_loss: 0.5166 - val_accuracy: 0.8750\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2754 - accuracy: 0.9350 - val_loss: 0.5027 - val_accuracy: 0.8550\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2972 - accuracy: 0.9162 - val_loss: 0.5157 - val_accuracy: 0.8550\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2667 - accuracy: 0.9275 - val_loss: 0.5089 - val_accuracy: 0.8650\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2728 - accuracy: 0.9275 - val_loss: 0.5098 - val_accuracy: 0.8550\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2474 - accuracy: 0.9325 - val_loss: 0.5051 - val_accuracy: 0.8550\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2687 - accuracy: 0.9250 - val_loss: 0.5179 - val_accuracy: 0.8550\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2404 - accuracy: 0.9438 - val_loss: 0.5151 - val_accuracy: 0.8500\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2482 - accuracy: 0.9375 - val_loss: 0.5067 - val_accuracy: 0.8500\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2232 - accuracy: 0.9438 - val_loss: 0.5002 - val_accuracy: 0.8350\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2484 - accuracy: 0.9237 - val_loss: 0.4940 - val_accuracy: 0.8500\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2058 - accuracy: 0.9525 - val_loss: 0.5006 - val_accuracy: 0.8450\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2042 - accuracy: 0.9538 - val_loss: 0.4912 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2052 - accuracy: 0.9375 - val_loss: 0.4867 - val_accuracy: 0.8400\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2045 - accuracy: 0.9488 - val_loss: 0.5001 - val_accuracy: 0.8650\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2124 - accuracy: 0.9463 - val_loss: 0.4857 - val_accuracy: 0.8350\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1990 - accuracy: 0.9413 - val_loss: 0.4992 - val_accuracy: 0.8400\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1926 - accuracy: 0.9575 - val_loss: 0.4949 - val_accuracy: 0.8550\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1811 - accuracy: 0.9525 - val_loss: 0.5110 - val_accuracy: 0.8650\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1939 - accuracy: 0.9488 - val_loss: 0.4858 - val_accuracy: 0.8350\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1709 - accuracy: 0.9663 - val_loss: 0.5028 - val_accuracy: 0.8550\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1841 - accuracy: 0.9575 - val_loss: 0.4916 - val_accuracy: 0.8550\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1743 - accuracy: 0.9488 - val_loss: 0.5033 - val_accuracy: 0.8550\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1824 - accuracy: 0.9525 - val_loss: 0.4916 - val_accuracy: 0.8450\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1672 - accuracy: 0.9538 - val_loss: 0.5071 - val_accuracy: 0.8600\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1561 - accuracy: 0.9650 - val_loss: 0.4874 - val_accuracy: 0.8500\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1646 - accuracy: 0.9700 - val_loss: 0.4876 - val_accuracy: 0.8550\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1526 - accuracy: 0.9588 - val_loss: 0.4906 - val_accuracy: 0.8550\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1583 - accuracy: 0.9638 - val_loss: 0.5054 - val_accuracy: 0.8550\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1537 - accuracy: 0.9650 - val_loss: 0.5113 - val_accuracy: 0.8550\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1448 - accuracy: 0.9675 - val_loss: 0.4892 - val_accuracy: 0.8500\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1590 - accuracy: 0.9500 - val_loss: 0.4970 - val_accuracy: 0.8650\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1354 - accuracy: 0.9737 - val_loss: 0.5071 - val_accuracy: 0.8600\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1461 - accuracy: 0.9725 - val_loss: 0.4885 - val_accuracy: 0.8550\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1331 - accuracy: 0.9663 - val_loss: 0.5033 - val_accuracy: 0.8550\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1426 - accuracy: 0.9625 - val_loss: 0.4928 - val_accuracy: 0.8550\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1353 - accuracy: 0.9725 - val_loss: 0.4916 - val_accuracy: 0.8600\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1482 - accuracy: 0.9650 - val_loss: 0.4946 - val_accuracy: 0.8600\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1192 - accuracy: 0.9762 - val_loss: 0.4992 - val_accuracy: 0.8600\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1163 - accuracy: 0.9725 - val_loss: 0.4908 - val_accuracy: 0.8600\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1267 - accuracy: 0.9688 - val_loss: 0.4840 - val_accuracy: 0.8450\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1397 - accuracy: 0.9600 - val_loss: 0.4908 - val_accuracy: 0.8550\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1182 - accuracy: 0.9737 - val_loss: 0.4934 - val_accuracy: 0.8500\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1196 - accuracy: 0.9750 - val_loss: 0.4910 - val_accuracy: 0.8650\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1102 - accuracy: 0.9762 - val_loss: 0.5030 - val_accuracy: 0.8600\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1071 - accuracy: 0.9812 - val_loss: 0.4955 - val_accuracy: 0.8500\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1362 - accuracy: 0.9675 - val_loss: 0.4974 - val_accuracy: 0.8500\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1159 - accuracy: 0.9762 - val_loss: 0.4972 - val_accuracy: 0.8550\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1074 - accuracy: 0.9762 - val_loss: 0.5026 - val_accuracy: 0.8450\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1074 - accuracy: 0.9712 - val_loss: 0.5062 - val_accuracy: 0.8600\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1146 - accuracy: 0.9750 - val_loss: 0.5095 - val_accuracy: 0.8400\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1275 - accuracy: 0.9663 - val_loss: 0.4905 - val_accuracy: 0.8550\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1136 - accuracy: 0.9775 - val_loss: 0.5029 - val_accuracy: 0.8500\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1100 - accuracy: 0.9737 - val_loss: 0.4955 - val_accuracy: 0.8500\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1061 - accuracy: 0.9737 - val_loss: 0.5084 - val_accuracy: 0.8550\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0944 - accuracy: 0.9775 - val_loss: 0.5181 - val_accuracy: 0.8650\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1119 - accuracy: 0.9688 - val_loss: 0.5024 - val_accuracy: 0.8550\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1059 - accuracy: 0.9675 - val_loss: 0.4961 - val_accuracy: 0.8550\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1003 - accuracy: 0.9737 - val_loss: 0.5022 - val_accuracy: 0.8650\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1101 - accuracy: 0.9675 - val_loss: 0.5144 - val_accuracy: 0.8600\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1151 - accuracy: 0.9650 - val_loss: 0.5252 - val_accuracy: 0.8550\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.0915 - accuracy: 0.9762 - val_loss: 0.5179 - val_accuracy: 0.8350\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0956 - accuracy: 0.9775 - val_loss: 0.5169 - val_accuracy: 0.8650\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1087 - accuracy: 0.9737 - val_loss: 0.5345 - val_accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0930 - accuracy: 0.9787 - val_loss: 0.5203 - val_accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0878 - accuracy: 0.9825 - val_loss: 0.5123 - val_accuracy: 0.8450\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0828 - accuracy: 0.9812 - val_loss: 0.5241 - val_accuracy: 0.8600\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1001 - accuracy: 0.9775 - val_loss: 0.5286 - val_accuracy: 0.8400\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.0846 - accuracy: 0.9825 - val_loss: 0.5171 - val_accuracy: 0.8650\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 2.3419 - accuracy: 0.1050\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 2.2573 - accuracy: 0.1838 - val_loss: 2.0499 - val_accuracy: 0.3850\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.9627 - accuracy: 0.4125 - val_loss: 1.7684 - val_accuracy: 0.5950\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.6811 - accuracy: 0.5763 - val_loss: 1.4856 - val_accuracy: 0.7200\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.4357 - accuracy: 0.6338 - val_loss: 1.2491 - val_accuracy: 0.7650\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.2140 - accuracy: 0.7050 - val_loss: 1.0710 - val_accuracy: 0.7800\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0462 - accuracy: 0.7325 - val_loss: 0.9419 - val_accuracy: 0.7900\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8980 - accuracy: 0.7812 - val_loss: 0.8491 - val_accuracy: 0.7800\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8303 - accuracy: 0.7950 - val_loss: 0.7754 - val_accuracy: 0.8050\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7261 - accuracy: 0.8300 - val_loss: 0.7174 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6990 - accuracy: 0.8112 - val_loss: 0.6869 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6321 - accuracy: 0.8462 - val_loss: 0.6454 - val_accuracy: 0.8100\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6057 - accuracy: 0.8400 - val_loss: 0.6255 - val_accuracy: 0.8150\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5621 - accuracy: 0.8500 - val_loss: 0.5946 - val_accuracy: 0.8300\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5407 - accuracy: 0.8687 - val_loss: 0.5782 - val_accuracy: 0.8450\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4952 - accuracy: 0.8838 - val_loss: 0.5631 - val_accuracy: 0.8300\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5051 - accuracy: 0.8625 - val_loss: 0.5493 - val_accuracy: 0.8300\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4569 - accuracy: 0.8950 - val_loss: 0.5346 - val_accuracy: 0.8450\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4671 - accuracy: 0.8763 - val_loss: 0.5273 - val_accuracy: 0.8450\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4384 - accuracy: 0.8950 - val_loss: 0.5159 - val_accuracy: 0.8400\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4061 - accuracy: 0.8950 - val_loss: 0.5093 - val_accuracy: 0.8450\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4131 - accuracy: 0.8950 - val_loss: 0.4990 - val_accuracy: 0.8450\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3667 - accuracy: 0.9125 - val_loss: 0.4992 - val_accuracy: 0.8350\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3719 - accuracy: 0.8988 - val_loss: 0.4944 - val_accuracy: 0.8450\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3637 - accuracy: 0.9075 - val_loss: 0.4844 - val_accuracy: 0.8400\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3617 - accuracy: 0.9112 - val_loss: 0.4849 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3102 - accuracy: 0.9262 - val_loss: 0.4759 - val_accuracy: 0.8350\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3471 - accuracy: 0.9112 - val_loss: 0.4736 - val_accuracy: 0.8450\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3115 - accuracy: 0.9125 - val_loss: 0.4682 - val_accuracy: 0.8450\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2973 - accuracy: 0.9225 - val_loss: 0.4707 - val_accuracy: 0.8450\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3000 - accuracy: 0.9162 - val_loss: 0.4652 - val_accuracy: 0.8500\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3162 - accuracy: 0.9112 - val_loss: 0.4698 - val_accuracy: 0.8450\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2924 - accuracy: 0.9275 - val_loss: 0.4663 - val_accuracy: 0.8450\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2852 - accuracy: 0.9250 - val_loss: 0.4588 - val_accuracy: 0.8550\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2705 - accuracy: 0.9262 - val_loss: 0.4644 - val_accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2534 - accuracy: 0.9325 - val_loss: 0.4561 - val_accuracy: 0.8500\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2666 - accuracy: 0.9275 - val_loss: 0.4757 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2393 - accuracy: 0.9450 - val_loss: 0.4683 - val_accuracy: 0.8500\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2641 - accuracy: 0.9300 - val_loss: 0.4653 - val_accuracy: 0.8400\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2428 - accuracy: 0.9400 - val_loss: 0.4570 - val_accuracy: 0.8500\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2229 - accuracy: 0.9413 - val_loss: 0.4519 - val_accuracy: 0.8550\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2176 - accuracy: 0.9400 - val_loss: 0.4509 - val_accuracy: 0.8550\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2077 - accuracy: 0.9513 - val_loss: 0.4444 - val_accuracy: 0.8500\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2269 - accuracy: 0.9413 - val_loss: 0.4471 - val_accuracy: 0.8400\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2142 - accuracy: 0.9463 - val_loss: 0.4442 - val_accuracy: 0.8550\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2072 - accuracy: 0.9513 - val_loss: 0.4638 - val_accuracy: 0.8450\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2032 - accuracy: 0.9513 - val_loss: 0.4441 - val_accuracy: 0.8450\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1764 - accuracy: 0.9538 - val_loss: 0.4556 - val_accuracy: 0.8450\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1950 - accuracy: 0.9550 - val_loss: 0.4534 - val_accuracy: 0.8450\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1813 - accuracy: 0.9525 - val_loss: 0.4411 - val_accuracy: 0.8500\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1746 - accuracy: 0.9488 - val_loss: 0.4466 - val_accuracy: 0.8450\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1749 - accuracy: 0.9525 - val_loss: 0.4424 - val_accuracy: 0.8450\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1857 - accuracy: 0.9563 - val_loss: 0.4513 - val_accuracy: 0.8450\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1697 - accuracy: 0.9563 - val_loss: 0.4505 - val_accuracy: 0.8300\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1570 - accuracy: 0.9638 - val_loss: 0.4425 - val_accuracy: 0.8500\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1614 - accuracy: 0.9638 - val_loss: 0.4492 - val_accuracy: 0.8450\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1640 - accuracy: 0.9638 - val_loss: 0.4380 - val_accuracy: 0.8450\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1712 - accuracy: 0.9575 - val_loss: 0.4557 - val_accuracy: 0.8350\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1439 - accuracy: 0.9700 - val_loss: 0.4451 - val_accuracy: 0.8500\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1700 - accuracy: 0.9625 - val_loss: 0.4428 - val_accuracy: 0.8550\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1419 - accuracy: 0.9725 - val_loss: 0.4304 - val_accuracy: 0.8450\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1532 - accuracy: 0.9625 - val_loss: 0.4469 - val_accuracy: 0.8450\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1426 - accuracy: 0.9762 - val_loss: 0.4423 - val_accuracy: 0.8450\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1533 - accuracy: 0.9613 - val_loss: 0.4441 - val_accuracy: 0.8450\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1537 - accuracy: 0.9650 - val_loss: 0.4315 - val_accuracy: 0.8550\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1293 - accuracy: 0.9750 - val_loss: 0.4443 - val_accuracy: 0.8450\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1225 - accuracy: 0.9700 - val_loss: 0.4353 - val_accuracy: 0.8500\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1397 - accuracy: 0.9700 - val_loss: 0.4397 - val_accuracy: 0.8450\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1320 - accuracy: 0.9725 - val_loss: 0.4399 - val_accuracy: 0.8550\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1464 - accuracy: 0.9688 - val_loss: 0.4486 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1183 - accuracy: 0.9812 - val_loss: 0.4505 - val_accuracy: 0.8450\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1243 - accuracy: 0.9737 - val_loss: 0.4446 - val_accuracy: 0.8450\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1232 - accuracy: 0.9762 - val_loss: 0.4482 - val_accuracy: 0.8400\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1145 - accuracy: 0.9712 - val_loss: 0.4501 - val_accuracy: 0.8450\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1337 - accuracy: 0.9688 - val_loss: 0.4509 - val_accuracy: 0.8450\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1278 - accuracy: 0.9688 - val_loss: 0.4634 - val_accuracy: 0.8300\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1128 - accuracy: 0.9737 - val_loss: 0.4463 - val_accuracy: 0.8400\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1135 - accuracy: 0.9712 - val_loss: 0.4590 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1159 - accuracy: 0.9737 - val_loss: 0.4585 - val_accuracy: 0.8350\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1108 - accuracy: 0.9737 - val_loss: 0.4513 - val_accuracy: 0.8400\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1365 - accuracy: 0.9712 - val_loss: 0.4664 - val_accuracy: 0.8350\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1132 - accuracy: 0.9762 - val_loss: 0.4578 - val_accuracy: 0.8450\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0943 - accuracy: 0.9812 - val_loss: 0.4679 - val_accuracy: 0.8500\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1266 - accuracy: 0.9700 - val_loss: 0.4611 - val_accuracy: 0.8400\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1098 - accuracy: 0.9787 - val_loss: 0.4674 - val_accuracy: 0.8450\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1121 - accuracy: 0.9688 - val_loss: 0.4692 - val_accuracy: 0.8350\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0839 - accuracy: 0.9900 - val_loss: 0.4667 - val_accuracy: 0.8350\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0935 - accuracy: 0.9787 - val_loss: 0.4671 - val_accuracy: 0.8450\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0930 - accuracy: 0.9837 - val_loss: 0.4695 - val_accuracy: 0.8400\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0915 - accuracy: 0.9825 - val_loss: 0.4793 - val_accuracy: 0.8300\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1239 - accuracy: 0.9650 - val_loss: 0.4729 - val_accuracy: 0.8400\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0995 - accuracy: 0.9787 - val_loss: 0.4806 - val_accuracy: 0.8400\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1041 - accuracy: 0.9725 - val_loss: 0.4592 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1044 - accuracy: 0.9800 - val_loss: 0.4603 - val_accuracy: 0.8450\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0840 - accuracy: 0.9837 - val_loss: 0.4648 - val_accuracy: 0.8450\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0735 - accuracy: 0.9875 - val_loss: 0.4678 - val_accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1006 - accuracy: 0.9725 - val_loss: 0.4730 - val_accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0856 - accuracy: 0.9837 - val_loss: 0.4681 - val_accuracy: 0.8500\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.0863 - accuracy: 0.9812 - val_loss: 0.4633 - val_accuracy: 0.8400\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.0714 - accuracy: 0.9862 - val_loss: 0.4680 - val_accuracy: 0.8450\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0884 - accuracy: 0.9825 - val_loss: 0.4738 - val_accuracy: 0.8350\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3471 - accuracy: 0.1050\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.2473 - accuracy: 0.1688 - val_loss: 2.0724 - val_accuracy: 0.4950\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.9245 - accuracy: 0.4437 - val_loss: 1.7868 - val_accuracy: 0.6650\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.6435 - accuracy: 0.5925 - val_loss: 1.5117 - val_accuracy: 0.7100\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.3800 - accuracy: 0.6963 - val_loss: 1.2777 - val_accuracy: 0.7550\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.1620 - accuracy: 0.7362 - val_loss: 1.1007 - val_accuracy: 0.7850\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.0071 - accuracy: 0.7613 - val_loss: 0.9864 - val_accuracy: 0.7800\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9100 - accuracy: 0.8000 - val_loss: 0.8907 - val_accuracy: 0.8050\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8087 - accuracy: 0.8112 - val_loss: 0.8173 - val_accuracy: 0.8200\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7645 - accuracy: 0.8037 - val_loss: 0.7809 - val_accuracy: 0.8050\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6819 - accuracy: 0.8375 - val_loss: 0.7366 - val_accuracy: 0.7950\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6262 - accuracy: 0.8487 - val_loss: 0.7038 - val_accuracy: 0.7950\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5944 - accuracy: 0.8350 - val_loss: 0.6920 - val_accuracy: 0.8250\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5611 - accuracy: 0.8512 - val_loss: 0.6618 - val_accuracy: 0.8250\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5340 - accuracy: 0.8587 - val_loss: 0.6468 - val_accuracy: 0.8100\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5125 - accuracy: 0.8725 - val_loss: 0.6278 - val_accuracy: 0.8050\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5038 - accuracy: 0.8587 - val_loss: 0.6146 - val_accuracy: 0.8150\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4621 - accuracy: 0.8838 - val_loss: 0.6093 - val_accuracy: 0.8100\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4468 - accuracy: 0.8813 - val_loss: 0.5883 - val_accuracy: 0.8050\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4336 - accuracy: 0.8850 - val_loss: 0.5763 - val_accuracy: 0.8250\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4182 - accuracy: 0.8788 - val_loss: 0.5657 - val_accuracy: 0.8150\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4014 - accuracy: 0.8825 - val_loss: 0.5644 - val_accuracy: 0.8250\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4116 - accuracy: 0.8888 - val_loss: 0.5721 - val_accuracy: 0.7950\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3849 - accuracy: 0.9100 - val_loss: 0.5547 - val_accuracy: 0.8100\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3639 - accuracy: 0.9013 - val_loss: 0.5555 - val_accuracy: 0.8150\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3507 - accuracy: 0.9100 - val_loss: 0.5452 - val_accuracy: 0.8000\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3278 - accuracy: 0.9200 - val_loss: 0.5505 - val_accuracy: 0.8150\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3212 - accuracy: 0.9150 - val_loss: 0.5498 - val_accuracy: 0.8050\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3241 - accuracy: 0.9187 - val_loss: 0.5330 - val_accuracy: 0.8200\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2937 - accuracy: 0.9287 - val_loss: 0.5323 - val_accuracy: 0.8100\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3026 - accuracy: 0.9262 - val_loss: 0.5217 - val_accuracy: 0.8150\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2837 - accuracy: 0.9262 - val_loss: 0.5353 - val_accuracy: 0.8050\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2809 - accuracy: 0.9287 - val_loss: 0.5370 - val_accuracy: 0.8150\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2753 - accuracy: 0.9287 - val_loss: 0.5234 - val_accuracy: 0.8100\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2618 - accuracy: 0.9362 - val_loss: 0.5331 - val_accuracy: 0.8150\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2543 - accuracy: 0.9350 - val_loss: 0.5199 - val_accuracy: 0.8100\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2504 - accuracy: 0.9400 - val_loss: 0.5252 - val_accuracy: 0.8100\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2569 - accuracy: 0.9262 - val_loss: 0.5224 - val_accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2445 - accuracy: 0.9425 - val_loss: 0.5263 - val_accuracy: 0.8100\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2345 - accuracy: 0.9475 - val_loss: 0.5160 - val_accuracy: 0.8150\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2436 - accuracy: 0.9362 - val_loss: 0.5146 - val_accuracy: 0.8100\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2191 - accuracy: 0.9463 - val_loss: 0.5206 - val_accuracy: 0.8100\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1986 - accuracy: 0.9513 - val_loss: 0.5032 - val_accuracy: 0.8200\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2054 - accuracy: 0.9500 - val_loss: 0.5067 - val_accuracy: 0.8150\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1997 - accuracy: 0.9525 - val_loss: 0.5191 - val_accuracy: 0.8200\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2240 - accuracy: 0.9400 - val_loss: 0.5141 - val_accuracy: 0.8050\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1856 - accuracy: 0.9575 - val_loss: 0.5060 - val_accuracy: 0.8100\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1921 - accuracy: 0.9575 - val_loss: 0.5088 - val_accuracy: 0.8100\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2000 - accuracy: 0.9488 - val_loss: 0.5082 - val_accuracy: 0.8050\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1856 - accuracy: 0.9600 - val_loss: 0.5148 - val_accuracy: 0.8100\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1920 - accuracy: 0.9488 - val_loss: 0.5046 - val_accuracy: 0.8100\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1716 - accuracy: 0.9563 - val_loss: 0.5060 - val_accuracy: 0.8200\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1678 - accuracy: 0.9575 - val_loss: 0.5043 - val_accuracy: 0.8100\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1800 - accuracy: 0.9500 - val_loss: 0.5218 - val_accuracy: 0.8200\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1752 - accuracy: 0.9575 - val_loss: 0.5175 - val_accuracy: 0.8100\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1712 - accuracy: 0.9500 - val_loss: 0.5168 - val_accuracy: 0.8250\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1614 - accuracy: 0.9613 - val_loss: 0.5094 - val_accuracy: 0.8100\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1573 - accuracy: 0.9650 - val_loss: 0.5112 - val_accuracy: 0.8050\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1823 - accuracy: 0.9488 - val_loss: 0.5160 - val_accuracy: 0.8150\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1599 - accuracy: 0.9600 - val_loss: 0.5207 - val_accuracy: 0.8100\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1717 - accuracy: 0.9425 - val_loss: 0.5123 - val_accuracy: 0.8150\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1413 - accuracy: 0.9663 - val_loss: 0.5148 - val_accuracy: 0.8050\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1325 - accuracy: 0.9688 - val_loss: 0.5146 - val_accuracy: 0.8200\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1459 - accuracy: 0.9625 - val_loss: 0.5221 - val_accuracy: 0.8050\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1340 - accuracy: 0.9762 - val_loss: 0.5084 - val_accuracy: 0.8100\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1335 - accuracy: 0.9688 - val_loss: 0.5157 - val_accuracy: 0.8150\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1349 - accuracy: 0.9638 - val_loss: 0.5131 - val_accuracy: 0.8150\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1416 - accuracy: 0.9663 - val_loss: 0.5080 - val_accuracy: 0.8150\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1339 - accuracy: 0.9737 - val_loss: 0.5269 - val_accuracy: 0.8100\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1355 - accuracy: 0.9663 - val_loss: 0.5104 - val_accuracy: 0.8100\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1278 - accuracy: 0.9700 - val_loss: 0.5141 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1190 - accuracy: 0.9750 - val_loss: 0.5112 - val_accuracy: 0.8050\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1151 - accuracy: 0.9725 - val_loss: 0.5113 - val_accuracy: 0.8200\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1253 - accuracy: 0.9663 - val_loss: 0.5263 - val_accuracy: 0.8200\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1249 - accuracy: 0.9700 - val_loss: 0.5179 - val_accuracy: 0.8150\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1279 - accuracy: 0.9762 - val_loss: 0.5154 - val_accuracy: 0.8200\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1111 - accuracy: 0.9725 - val_loss: 0.5137 - val_accuracy: 0.8100\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1045 - accuracy: 0.9750 - val_loss: 0.5241 - val_accuracy: 0.8000\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1196 - accuracy: 0.9750 - val_loss: 0.5378 - val_accuracy: 0.8100\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1160 - accuracy: 0.9737 - val_loss: 0.5285 - val_accuracy: 0.8050\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1047 - accuracy: 0.9775 - val_loss: 0.5357 - val_accuracy: 0.8150\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1148 - accuracy: 0.9688 - val_loss: 0.5263 - val_accuracy: 0.8150\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1203 - accuracy: 0.9737 - val_loss: 0.5201 - val_accuracy: 0.8150\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0948 - accuracy: 0.9862 - val_loss: 0.5434 - val_accuracy: 0.8100\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1115 - accuracy: 0.9725 - val_loss: 0.5323 - val_accuracy: 0.8100\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1011 - accuracy: 0.9812 - val_loss: 0.5485 - val_accuracy: 0.8200\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1080 - accuracy: 0.9712 - val_loss: 0.5237 - val_accuracy: 0.8100\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1110 - accuracy: 0.9800 - val_loss: 0.5433 - val_accuracy: 0.8200\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1086 - accuracy: 0.9712 - val_loss: 0.5506 - val_accuracy: 0.8100\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0953 - accuracy: 0.9787 - val_loss: 0.5339 - val_accuracy: 0.8250\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0991 - accuracy: 0.9725 - val_loss: 0.5374 - val_accuracy: 0.8150\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0941 - accuracy: 0.9762 - val_loss: 0.5427 - val_accuracy: 0.8200\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1001 - accuracy: 0.9725 - val_loss: 0.5482 - val_accuracy: 0.8100\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0942 - accuracy: 0.9775 - val_loss: 0.5549 - val_accuracy: 0.8150\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0950 - accuracy: 0.9775 - val_loss: 0.5515 - val_accuracy: 0.8050\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0890 - accuracy: 0.9775 - val_loss: 0.5624 - val_accuracy: 0.8050\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0859 - accuracy: 0.9800 - val_loss: 0.5438 - val_accuracy: 0.8050\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0871 - accuracy: 0.9812 - val_loss: 0.5600 - val_accuracy: 0.8200\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0913 - accuracy: 0.9762 - val_loss: 0.5489 - val_accuracy: 0.8100\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0867 - accuracy: 0.9837 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1030 - accuracy: 0.9725 - val_loss: 0.5419 - val_accuracy: 0.8100\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 2.3692 - accuracy: 0.0500\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.2819 - accuracy: 0.1287 - val_loss: 2.1465 - val_accuracy: 0.3450\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 2.0435 - accuracy: 0.3862 - val_loss: 1.9165 - val_accuracy: 0.5900\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.7562 - accuracy: 0.5500 - val_loss: 1.6263 - val_accuracy: 0.6850\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.4791 - accuracy: 0.6612 - val_loss: 1.3656 - val_accuracy: 0.7300\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.2218 - accuracy: 0.7138 - val_loss: 1.1729 - val_accuracy: 0.7400\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.0468 - accuracy: 0.7487 - val_loss: 1.0369 - val_accuracy: 0.7750\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.9195 - accuracy: 0.7887 - val_loss: 0.9272 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.8386 - accuracy: 0.7925 - val_loss: 0.8624 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.7699 - accuracy: 0.8125 - val_loss: 0.8074 - val_accuracy: 0.7950\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.7230 - accuracy: 0.8125 - val_loss: 0.7789 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6367 - accuracy: 0.8462 - val_loss: 0.7365 - val_accuracy: 0.8050\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6227 - accuracy: 0.8438 - val_loss: 0.7161 - val_accuracy: 0.8150\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5939 - accuracy: 0.8350 - val_loss: 0.6827 - val_accuracy: 0.8200\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5457 - accuracy: 0.8612 - val_loss: 0.6627 - val_accuracy: 0.8150\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5177 - accuracy: 0.8525 - val_loss: 0.6395 - val_accuracy: 0.8250\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4723 - accuracy: 0.8963 - val_loss: 0.6305 - val_accuracy: 0.8200\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4804 - accuracy: 0.8687 - val_loss: 0.6182 - val_accuracy: 0.8300\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4647 - accuracy: 0.8712 - val_loss: 0.6031 - val_accuracy: 0.8300\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4178 - accuracy: 0.8950 - val_loss: 0.6015 - val_accuracy: 0.8250\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4225 - accuracy: 0.8775 - val_loss: 0.5942 - val_accuracy: 0.8400\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3935 - accuracy: 0.9050 - val_loss: 0.5904 - val_accuracy: 0.8300\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3829 - accuracy: 0.8988 - val_loss: 0.5751 - val_accuracy: 0.8350\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3589 - accuracy: 0.9062 - val_loss: 0.5641 - val_accuracy: 0.8550\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3628 - accuracy: 0.9013 - val_loss: 0.5597 - val_accuracy: 0.8350\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3550 - accuracy: 0.9075 - val_loss: 0.5532 - val_accuracy: 0.8450\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3135 - accuracy: 0.9225 - val_loss: 0.5555 - val_accuracy: 0.8400\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3081 - accuracy: 0.9225 - val_loss: 0.5407 - val_accuracy: 0.8350\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3047 - accuracy: 0.9212 - val_loss: 0.5386 - val_accuracy: 0.8450\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3101 - accuracy: 0.9212 - val_loss: 0.5381 - val_accuracy: 0.8450\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2822 - accuracy: 0.9375 - val_loss: 0.5347 - val_accuracy: 0.8400\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2846 - accuracy: 0.9262 - val_loss: 0.5264 - val_accuracy: 0.8350\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2774 - accuracy: 0.9287 - val_loss: 0.5221 - val_accuracy: 0.8350\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2590 - accuracy: 0.9312 - val_loss: 0.5242 - val_accuracy: 0.8450\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2715 - accuracy: 0.9250 - val_loss: 0.5233 - val_accuracy: 0.8400\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2665 - accuracy: 0.9200 - val_loss: 0.5218 - val_accuracy: 0.8400\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2399 - accuracy: 0.9513 - val_loss: 0.5152 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2249 - accuracy: 0.9425 - val_loss: 0.5161 - val_accuracy: 0.8550\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2377 - accuracy: 0.9438 - val_loss: 0.5183 - val_accuracy: 0.8400\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2378 - accuracy: 0.9325 - val_loss: 0.5289 - val_accuracy: 0.8350\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2270 - accuracy: 0.9475 - val_loss: 0.5129 - val_accuracy: 0.8400\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2074 - accuracy: 0.9563 - val_loss: 0.5037 - val_accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2284 - accuracy: 0.9438 - val_loss: 0.5191 - val_accuracy: 0.8450\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2230 - accuracy: 0.9463 - val_loss: 0.5126 - val_accuracy: 0.8500\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2035 - accuracy: 0.9588 - val_loss: 0.5048 - val_accuracy: 0.8450\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2136 - accuracy: 0.9400 - val_loss: 0.5147 - val_accuracy: 0.8500\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1917 - accuracy: 0.9525 - val_loss: 0.5029 - val_accuracy: 0.8450\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2049 - accuracy: 0.9400 - val_loss: 0.5098 - val_accuracy: 0.8500\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1725 - accuracy: 0.9600 - val_loss: 0.5145 - val_accuracy: 0.8450\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1896 - accuracy: 0.9600 - val_loss: 0.5107 - val_accuracy: 0.8450\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1819 - accuracy: 0.9525 - val_loss: 0.5252 - val_accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1941 - accuracy: 0.9600 - val_loss: 0.5208 - val_accuracy: 0.8450\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1492 - accuracy: 0.9725 - val_loss: 0.5219 - val_accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1851 - accuracy: 0.9588 - val_loss: 0.5180 - val_accuracy: 0.8450\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1733 - accuracy: 0.9575 - val_loss: 0.5179 - val_accuracy: 0.8350\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1550 - accuracy: 0.9688 - val_loss: 0.5193 - val_accuracy: 0.8350\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1437 - accuracy: 0.9675 - val_loss: 0.5201 - val_accuracy: 0.8450\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1668 - accuracy: 0.9525 - val_loss: 0.5132 - val_accuracy: 0.8400\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1603 - accuracy: 0.9575 - val_loss: 0.5210 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1455 - accuracy: 0.9638 - val_loss: 0.5164 - val_accuracy: 0.8350\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1625 - accuracy: 0.9550 - val_loss: 0.5178 - val_accuracy: 0.8350\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1663 - accuracy: 0.9463 - val_loss: 0.5128 - val_accuracy: 0.8350\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1330 - accuracy: 0.9700 - val_loss: 0.5076 - val_accuracy: 0.8450\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1337 - accuracy: 0.9737 - val_loss: 0.5138 - val_accuracy: 0.8450\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1497 - accuracy: 0.9663 - val_loss: 0.5221 - val_accuracy: 0.8400\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1325 - accuracy: 0.9737 - val_loss: 0.5280 - val_accuracy: 0.8500\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1547 - accuracy: 0.9588 - val_loss: 0.5259 - val_accuracy: 0.8400\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1260 - accuracy: 0.9750 - val_loss: 0.5223 - val_accuracy: 0.8450\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1426 - accuracy: 0.9650 - val_loss: 0.5244 - val_accuracy: 0.8450\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1305 - accuracy: 0.9688 - val_loss: 0.5188 - val_accuracy: 0.8550\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1371 - accuracy: 0.9663 - val_loss: 0.5289 - val_accuracy: 0.8450\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1190 - accuracy: 0.9762 - val_loss: 0.5189 - val_accuracy: 0.8400\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1218 - accuracy: 0.9663 - val_loss: 0.5123 - val_accuracy: 0.8500\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1095 - accuracy: 0.9725 - val_loss: 0.5227 - val_accuracy: 0.8450\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1281 - accuracy: 0.9675 - val_loss: 0.5470 - val_accuracy: 0.8350\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1311 - accuracy: 0.9688 - val_loss: 0.5250 - val_accuracy: 0.8450\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1226 - accuracy: 0.9725 - val_loss: 0.5184 - val_accuracy: 0.8550\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1246 - accuracy: 0.9750 - val_loss: 0.5271 - val_accuracy: 0.8450\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 0.5343 - val_accuracy: 0.8450\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1361 - accuracy: 0.9675 - val_loss: 0.5229 - val_accuracy: 0.8450\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1056 - accuracy: 0.9750 - val_loss: 0.5344 - val_accuracy: 0.8450\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1041 - accuracy: 0.9800 - val_loss: 0.5308 - val_accuracy: 0.8550\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1172 - accuracy: 0.9688 - val_loss: 0.5311 - val_accuracy: 0.8450\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1125 - accuracy: 0.9712 - val_loss: 0.5399 - val_accuracy: 0.8500\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1175 - accuracy: 0.9625 - val_loss: 0.5329 - val_accuracy: 0.8550\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0949 - accuracy: 0.9850 - val_loss: 0.5444 - val_accuracy: 0.8400\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1079 - accuracy: 0.9750 - val_loss: 0.5298 - val_accuracy: 0.8450\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1081 - accuracy: 0.9725 - val_loss: 0.5367 - val_accuracy: 0.8350\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0892 - accuracy: 0.9825 - val_loss: 0.5386 - val_accuracy: 0.8450\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0862 - accuracy: 0.9850 - val_loss: 0.5439 - val_accuracy: 0.8450\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1044 - accuracy: 0.9675 - val_loss: 0.5381 - val_accuracy: 0.8500\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0866 - accuracy: 0.9837 - val_loss: 0.5456 - val_accuracy: 0.8450\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0979 - accuracy: 0.9812 - val_loss: 0.5347 - val_accuracy: 0.8400\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0931 - accuracy: 0.9812 - val_loss: 0.5303 - val_accuracy: 0.8500\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1042 - accuracy: 0.9700 - val_loss: 0.5194 - val_accuracy: 0.8500\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0891 - accuracy: 0.9775 - val_loss: 0.5435 - val_accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1014 - accuracy: 0.9775 - val_loss: 0.5317 - val_accuracy: 0.8500\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1083 - accuracy: 0.9762 - val_loss: 0.5301 - val_accuracy: 0.8550\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0914 - accuracy: 0.9812 - val_loss: 0.5304 - val_accuracy: 0.8500\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0907 - accuracy: 0.9800 - val_loss: 0.5279 - val_accuracy: 0.8550\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.0806 - accuracy: 0.9850 - val_loss: 0.5362 - val_accuracy: 0.8500\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3171 - accuracy: 0.1050\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.2514 - accuracy: 0.1838 - val_loss: 2.0630 - val_accuracy: 0.3750\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.9703 - accuracy: 0.4150 - val_loss: 1.7841 - val_accuracy: 0.6800\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 1.6929 - accuracy: 0.5750 - val_loss: 1.4913 - val_accuracy: 0.7800\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 1.4186 - accuracy: 0.6775 - val_loss: 1.2508 - val_accuracy: 0.7950\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.2191 - accuracy: 0.7125 - val_loss: 1.0822 - val_accuracy: 0.8050\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0589 - accuracy: 0.7188 - val_loss: 0.9442 - val_accuracy: 0.8400\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.9438 - accuracy: 0.7775 - val_loss: 0.8519 - val_accuracy: 0.8550\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.8547 - accuracy: 0.7937 - val_loss: 0.8047 - val_accuracy: 0.8300\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7768 - accuracy: 0.8075 - val_loss: 0.7310 - val_accuracy: 0.8450\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.7226 - accuracy: 0.8075 - val_loss: 0.7015 - val_accuracy: 0.8450\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6839 - accuracy: 0.8263 - val_loss: 0.6668 - val_accuracy: 0.8600\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.6196 - accuracy: 0.8525 - val_loss: 0.6539 - val_accuracy: 0.8500\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.5978 - accuracy: 0.8363 - val_loss: 0.6096 - val_accuracy: 0.8650\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.5398 - accuracy: 0.8650 - val_loss: 0.5997 - val_accuracy: 0.8550\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5341 - accuracy: 0.8562 - val_loss: 0.5700 - val_accuracy: 0.8600\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4980 - accuracy: 0.8725 - val_loss: 0.5724 - val_accuracy: 0.8500\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4890 - accuracy: 0.8600 - val_loss: 0.5546 - val_accuracy: 0.8650\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4443 - accuracy: 0.8763 - val_loss: 0.5390 - val_accuracy: 0.8750\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4381 - accuracy: 0.8950 - val_loss: 0.5451 - val_accuracy: 0.8600\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4188 - accuracy: 0.8950 - val_loss: 0.5347 - val_accuracy: 0.8550\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4059 - accuracy: 0.8963 - val_loss: 0.5161 - val_accuracy: 0.8700\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3852 - accuracy: 0.9000 - val_loss: 0.5168 - val_accuracy: 0.8650\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3678 - accuracy: 0.9062 - val_loss: 0.5115 - val_accuracy: 0.8600\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.3531 - accuracy: 0.9125 - val_loss: 0.5044 - val_accuracy: 0.8650\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3599 - accuracy: 0.8963 - val_loss: 0.5145 - val_accuracy: 0.8500\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3531 - accuracy: 0.9175 - val_loss: 0.4962 - val_accuracy: 0.8650\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3441 - accuracy: 0.9100 - val_loss: 0.4938 - val_accuracy: 0.8550\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.3279 - accuracy: 0.9137 - val_loss: 0.4939 - val_accuracy: 0.8550\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3023 - accuracy: 0.9075 - val_loss: 0.4978 - val_accuracy: 0.8500\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3069 - accuracy: 0.9100 - val_loss: 0.4987 - val_accuracy: 0.8550\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2921 - accuracy: 0.9275 - val_loss: 0.4961 - val_accuracy: 0.8450\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2782 - accuracy: 0.9337 - val_loss: 0.4911 - val_accuracy: 0.8500\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2754 - accuracy: 0.9350 - val_loss: 0.5020 - val_accuracy: 0.8450\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2899 - accuracy: 0.9187 - val_loss: 0.4887 - val_accuracy: 0.8450\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2822 - accuracy: 0.9250 - val_loss: 0.4867 - val_accuracy: 0.8450\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2687 - accuracy: 0.9300 - val_loss: 0.4819 - val_accuracy: 0.8550\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2323 - accuracy: 0.9400 - val_loss: 0.4870 - val_accuracy: 0.8500\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2426 - accuracy: 0.9400 - val_loss: 0.4827 - val_accuracy: 0.8600\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.2232 - accuracy: 0.9463 - val_loss: 0.4834 - val_accuracy: 0.8600\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2316 - accuracy: 0.9287 - val_loss: 0.4808 - val_accuracy: 0.8600\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2482 - accuracy: 0.9325 - val_loss: 0.5012 - val_accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2223 - accuracy: 0.9388 - val_loss: 0.4845 - val_accuracy: 0.8600\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2241 - accuracy: 0.9463 - val_loss: 0.4888 - val_accuracy: 0.8600\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2067 - accuracy: 0.9525 - val_loss: 0.4911 - val_accuracy: 0.8600\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2075 - accuracy: 0.9463 - val_loss: 0.4894 - val_accuracy: 0.8550\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1965 - accuracy: 0.9550 - val_loss: 0.4824 - val_accuracy: 0.8550\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2147 - accuracy: 0.9388 - val_loss: 0.5033 - val_accuracy: 0.8450\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2217 - accuracy: 0.9413 - val_loss: 0.4781 - val_accuracy: 0.8550\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1859 - accuracy: 0.9600 - val_loss: 0.4817 - val_accuracy: 0.8600\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1808 - accuracy: 0.9613 - val_loss: 0.4822 - val_accuracy: 0.8500\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1973 - accuracy: 0.9438 - val_loss: 0.4941 - val_accuracy: 0.8550\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1674 - accuracy: 0.9600 - val_loss: 0.4803 - val_accuracy: 0.8500\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1521 - accuracy: 0.9737 - val_loss: 0.4952 - val_accuracy: 0.8500\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1911 - accuracy: 0.9438 - val_loss: 0.4964 - val_accuracy: 0.8400\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1655 - accuracy: 0.9588 - val_loss: 0.4949 - val_accuracy: 0.8350\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1612 - accuracy: 0.9575 - val_loss: 0.4864 - val_accuracy: 0.8650\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1854 - accuracy: 0.9525 - val_loss: 0.5010 - val_accuracy: 0.8350\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1453 - accuracy: 0.9675 - val_loss: 0.4848 - val_accuracy: 0.8500\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1503 - accuracy: 0.9588 - val_loss: 0.4908 - val_accuracy: 0.8500\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1448 - accuracy: 0.9650 - val_loss: 0.4988 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1593 - accuracy: 0.9600 - val_loss: 0.4880 - val_accuracy: 0.8550\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1425 - accuracy: 0.9650 - val_loss: 0.4887 - val_accuracy: 0.8350\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1665 - accuracy: 0.9575 - val_loss: 0.4934 - val_accuracy: 0.8450\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1348 - accuracy: 0.9675 - val_loss: 0.4953 - val_accuracy: 0.8550\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1497 - accuracy: 0.9625 - val_loss: 0.4897 - val_accuracy: 0.8400\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1425 - accuracy: 0.9625 - val_loss: 0.4885 - val_accuracy: 0.8400\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1283 - accuracy: 0.9737 - val_loss: 0.4887 - val_accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1374 - accuracy: 0.9688 - val_loss: 0.5033 - val_accuracy: 0.8300\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1347 - accuracy: 0.9675 - val_loss: 0.4924 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1286 - accuracy: 0.9700 - val_loss: 0.4964 - val_accuracy: 0.8450\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1244 - accuracy: 0.9663 - val_loss: 0.5068 - val_accuracy: 0.8250\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1076 - accuracy: 0.9787 - val_loss: 0.5195 - val_accuracy: 0.8250\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1281 - accuracy: 0.9675 - val_loss: 0.5063 - val_accuracy: 0.8550\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1368 - accuracy: 0.9638 - val_loss: 0.5066 - val_accuracy: 0.8450\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1272 - accuracy: 0.9650 - val_loss: 0.5095 - val_accuracy: 0.8450\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1143 - accuracy: 0.9675 - val_loss: 0.5140 - val_accuracy: 0.8350\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1152 - accuracy: 0.9688 - val_loss: 0.5004 - val_accuracy: 0.8450\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1236 - accuracy: 0.9638 - val_loss: 0.4968 - val_accuracy: 0.8450\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1227 - accuracy: 0.9725 - val_loss: 0.5087 - val_accuracy: 0.8500\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1140 - accuracy: 0.9750 - val_loss: 0.5234 - val_accuracy: 0.8350\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1245 - accuracy: 0.9650 - val_loss: 0.5157 - val_accuracy: 0.8500\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1223 - accuracy: 0.9663 - val_loss: 0.5261 - val_accuracy: 0.8350\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1090 - accuracy: 0.9750 - val_loss: 0.5204 - val_accuracy: 0.8550\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1096 - accuracy: 0.9737 - val_loss: 0.5235 - val_accuracy: 0.8400\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1112 - accuracy: 0.9650 - val_loss: 0.5136 - val_accuracy: 0.8350\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1035 - accuracy: 0.9750 - val_loss: 0.5097 - val_accuracy: 0.8450\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1066 - accuracy: 0.9700 - val_loss: 0.5139 - val_accuracy: 0.8450\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1155 - accuracy: 0.9688 - val_loss: 0.5022 - val_accuracy: 0.8450\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1010 - accuracy: 0.9750 - val_loss: 0.5158 - val_accuracy: 0.8400\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1085 - accuracy: 0.9750 - val_loss: 0.5070 - val_accuracy: 0.8450\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1166 - accuracy: 0.9737 - val_loss: 0.5326 - val_accuracy: 0.8400\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0877 - accuracy: 0.9812 - val_loss: 0.5282 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.0885 - accuracy: 0.9875 - val_loss: 0.5112 - val_accuracy: 0.8350\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1057 - accuracy: 0.9750 - val_loss: 0.5262 - val_accuracy: 0.8300\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0882 - accuracy: 0.9825 - val_loss: 0.5343 - val_accuracy: 0.8250\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0943 - accuracy: 0.9787 - val_loss: 0.5345 - val_accuracy: 0.8400\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0980 - accuracy: 0.9787 - val_loss: 0.5272 - val_accuracy: 0.8400\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.0949 - accuracy: 0.9750 - val_loss: 0.5238 - val_accuracy: 0.8450\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0839 - accuracy: 0.9875 - val_loss: 0.5276 - val_accuracy: 0.8200\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.0785 - accuracy: 0.9850 - val_loss: 0.5251 - val_accuracy: 0.8550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d868d7b3-2a17-4a7c-ccff-55ae7ffc6dd1"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy after training\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.09499999806284905\n",
            "Final accuracy: 0.8590000033378601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "70f0df8c-308b-4c83-bbd3-de24b1470ab3"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4042b9ed-a72d-424c-c8c8-8aefb9f3b6cf"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}