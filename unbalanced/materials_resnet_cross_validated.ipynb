{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-resnet-cross-validated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODyOSiV/N8/9iTwE3n9ZNt"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "outputId": "5be9fe4e-9516-4a37-a15d-607bbad15a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "outputId": "64946634-14ba-45eb-ee2f-fa597392bf47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "outputId": "9b3ac979-833c-4acc-efdc-a19279d1fd1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "outputId": "a9d162d2-69f3-4898-a64d-be073bc77ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVOP5fIPwEx8",
        "outputId": "3d1f026f-3c0e-41b4-8a1f-56153c66082b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get pre-trained model\n",
        "base_model = keras.applications.ResNet50V2(include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2kAceGVW0e"
      },
      "source": [
        "# don't train base model weights\n",
        "base_model.trainable = False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGkReMX60ScJ",
        "outputId": "6f65d4d7-cbc6-4c34-c616-18b6db3f8459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 305, 305, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 150, 150, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 152, 152, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 75, 75, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 75, 75, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 75, 75, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 75, 75, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 75, 75, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 75, 75, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 75, 75, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 75, 75, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 75, 75, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 75, 75, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 75, 75, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 75, 75, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 75, 75, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 75, 75, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 75, 75, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 75, 75, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 75, 75, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 75, 75, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 75, 75, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 38, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 38, 38, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 38, 38, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 38, 38, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 38, 38, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 38, 38, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 38, 38, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 38, 38, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 38, 38, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 38, 38, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 38, 38, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 38, 38, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 38, 38, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 38, 38, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 38, 38, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 38, 38, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 19, 19, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 19, 19, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 19, 19, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 19, 19, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 19, 19, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 19, 19, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 19, 19, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 19, 19, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 19, 19, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 19, 19, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 19, 19, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 19, 19, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 19, 19, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 19, 19, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 19, 19, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 19, 19, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 19, 19, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 19, 19, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 19, 19, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 19, 19, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 10, 10, 1024) 0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 10, 10, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 10, 10, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 10, 10, 512)  0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 10, 10, 512)  0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 10, 10, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 10, 10, 2048) 0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 10, 10, 2048) 8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 10, 10, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 10, 10, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 10, 10, 512)  0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 10, 10, 512)  0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 10, 10, 2048) 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 10, 10, 2048) 8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 10, 10, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 10, 10, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 10, 10, 512)  0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 10, 10, 512)  0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 10, 10, 2048) 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 10, 10, 2048) 8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 10, 10, 2048) 0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model():\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 100"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "outputId": "e4dfb1b9-b2d2-4047-d6b9-d570047bbdf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model()\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy']))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 2.5452 - accuracy: 0.1000\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 115ms/step - loss: 2.4803 - accuracy: 0.1475 - val_loss: 2.2137 - val_accuracy: 0.1850\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 2.1083 - accuracy: 0.2625 - val_loss: 1.9756 - val_accuracy: 0.3050\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.9236 - accuracy: 0.3275 - val_loss: 1.7778 - val_accuracy: 0.4100\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.6937 - accuracy: 0.4087 - val_loss: 1.6130 - val_accuracy: 0.5300\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.5342 - accuracy: 0.4875 - val_loss: 1.4757 - val_accuracy: 0.5750\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.4461 - accuracy: 0.5475 - val_loss: 1.3621 - val_accuracy: 0.6050\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 123ms/step - loss: 1.2972 - accuracy: 0.6050 - val_loss: 1.2715 - val_accuracy: 0.6350\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 123ms/step - loss: 1.1970 - accuracy: 0.6463 - val_loss: 1.1949 - val_accuracy: 0.6850\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 1.1503 - accuracy: 0.6400 - val_loss: 1.1241 - val_accuracy: 0.6950\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0610 - accuracy: 0.6825 - val_loss: 1.0756 - val_accuracy: 0.6950\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.9856 - accuracy: 0.7113 - val_loss: 1.0271 - val_accuracy: 0.6950\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.9377 - accuracy: 0.7350 - val_loss: 0.9836 - val_accuracy: 0.7150\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8836 - accuracy: 0.7525 - val_loss: 0.9482 - val_accuracy: 0.7200\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8509 - accuracy: 0.7575 - val_loss: 0.9158 - val_accuracy: 0.7350\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8181 - accuracy: 0.7812 - val_loss: 0.8857 - val_accuracy: 0.7300\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7760 - accuracy: 0.7887 - val_loss: 0.8616 - val_accuracy: 0.7300\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.7393 - accuracy: 0.8025 - val_loss: 0.8389 - val_accuracy: 0.7350\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7295 - accuracy: 0.8100 - val_loss: 0.8156 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6769 - accuracy: 0.8175 - val_loss: 0.7967 - val_accuracy: 0.7450\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6753 - accuracy: 0.8000 - val_loss: 0.7807 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6471 - accuracy: 0.8025 - val_loss: 0.7638 - val_accuracy: 0.7600\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6060 - accuracy: 0.8363 - val_loss: 0.7552 - val_accuracy: 0.7600\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6026 - accuracy: 0.8338 - val_loss: 0.7350 - val_accuracy: 0.7700\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6096 - accuracy: 0.8325 - val_loss: 0.7235 - val_accuracy: 0.7700\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5818 - accuracy: 0.8425 - val_loss: 0.7168 - val_accuracy: 0.7800\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5608 - accuracy: 0.8587 - val_loss: 0.7030 - val_accuracy: 0.7750\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5293 - accuracy: 0.8550 - val_loss: 0.6927 - val_accuracy: 0.7750\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5140 - accuracy: 0.8550 - val_loss: 0.6869 - val_accuracy: 0.7800\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5094 - accuracy: 0.8637 - val_loss: 0.6731 - val_accuracy: 0.7900\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5297 - accuracy: 0.8550 - val_loss: 0.6654 - val_accuracy: 0.7800\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5014 - accuracy: 0.8712 - val_loss: 0.6560 - val_accuracy: 0.7850\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4750 - accuracy: 0.8788 - val_loss: 0.6501 - val_accuracy: 0.7850\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4794 - accuracy: 0.8637 - val_loss: 0.6437 - val_accuracy: 0.7900\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4381 - accuracy: 0.8875 - val_loss: 0.6411 - val_accuracy: 0.7950\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4431 - accuracy: 0.8925 - val_loss: 0.6342 - val_accuracy: 0.7900\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4515 - accuracy: 0.8788 - val_loss: 0.6268 - val_accuracy: 0.8000\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4455 - accuracy: 0.8775 - val_loss: 0.6218 - val_accuracy: 0.7900\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4179 - accuracy: 0.8938 - val_loss: 0.6175 - val_accuracy: 0.7950\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4293 - accuracy: 0.8763 - val_loss: 0.6170 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4253 - accuracy: 0.8750 - val_loss: 0.6081 - val_accuracy: 0.8000\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3959 - accuracy: 0.9000 - val_loss: 0.5998 - val_accuracy: 0.7900\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3823 - accuracy: 0.9075 - val_loss: 0.5956 - val_accuracy: 0.7950\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3840 - accuracy: 0.8975 - val_loss: 0.5907 - val_accuracy: 0.8050\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3574 - accuracy: 0.9162 - val_loss: 0.5905 - val_accuracy: 0.8000\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3797 - accuracy: 0.8950 - val_loss: 0.5856 - val_accuracy: 0.8050\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3547 - accuracy: 0.9025 - val_loss: 0.5853 - val_accuracy: 0.8000\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3628 - accuracy: 0.9013 - val_loss: 0.5840 - val_accuracy: 0.7950\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3601 - accuracy: 0.9075 - val_loss: 0.5791 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3494 - accuracy: 0.9062 - val_loss: 0.5753 - val_accuracy: 0.7950\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3354 - accuracy: 0.9125 - val_loss: 0.5710 - val_accuracy: 0.7950\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3434 - accuracy: 0.9062 - val_loss: 0.5714 - val_accuracy: 0.8100\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3265 - accuracy: 0.9125 - val_loss: 0.5666 - val_accuracy: 0.8050\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3154 - accuracy: 0.9200 - val_loss: 0.5693 - val_accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3055 - accuracy: 0.9287 - val_loss: 0.5646 - val_accuracy: 0.8050\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2975 - accuracy: 0.9187 - val_loss: 0.5581 - val_accuracy: 0.8150\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3143 - accuracy: 0.9175 - val_loss: 0.5537 - val_accuracy: 0.8150\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3010 - accuracy: 0.9200 - val_loss: 0.5613 - val_accuracy: 0.8150\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2883 - accuracy: 0.9175 - val_loss: 0.5597 - val_accuracy: 0.8100\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2986 - accuracy: 0.9250 - val_loss: 0.5494 - val_accuracy: 0.8250\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.2870 - accuracy: 0.9225 - val_loss: 0.5463 - val_accuracy: 0.8200\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.2791 - accuracy: 0.9287 - val_loss: 0.5508 - val_accuracy: 0.8150\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2731 - accuracy: 0.9362 - val_loss: 0.5497 - val_accuracy: 0.8000\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2720 - accuracy: 0.9350 - val_loss: 0.5462 - val_accuracy: 0.8200\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2908 - accuracy: 0.9237 - val_loss: 0.5452 - val_accuracy: 0.8200\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2709 - accuracy: 0.9312 - val_loss: 0.5469 - val_accuracy: 0.8200\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2440 - accuracy: 0.9450 - val_loss: 0.5441 - val_accuracy: 0.8050\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2716 - accuracy: 0.9325 - val_loss: 0.5460 - val_accuracy: 0.8100\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2583 - accuracy: 0.9312 - val_loss: 0.5531 - val_accuracy: 0.8050\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2566 - accuracy: 0.9337 - val_loss: 0.5470 - val_accuracy: 0.8100\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2369 - accuracy: 0.9450 - val_loss: 0.5413 - val_accuracy: 0.8100\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2507 - accuracy: 0.9425 - val_loss: 0.5427 - val_accuracy: 0.8150\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2468 - accuracy: 0.9400 - val_loss: 0.5353 - val_accuracy: 0.8100\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2606 - accuracy: 0.9375 - val_loss: 0.5315 - val_accuracy: 0.8100\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2552 - accuracy: 0.9350 - val_loss: 0.5305 - val_accuracy: 0.8050\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2256 - accuracy: 0.9438 - val_loss: 0.5309 - val_accuracy: 0.8100\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2234 - accuracy: 0.9550 - val_loss: 0.5312 - val_accuracy: 0.8100\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2118 - accuracy: 0.9600 - val_loss: 0.5329 - val_accuracy: 0.8100\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2250 - accuracy: 0.9438 - val_loss: 0.5321 - val_accuracy: 0.8100\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.2198 - accuracy: 0.9575 - val_loss: 0.5277 - val_accuracy: 0.8100\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2168 - accuracy: 0.9488 - val_loss: 0.5277 - val_accuracy: 0.8150\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2064 - accuracy: 0.9525 - val_loss: 0.5255 - val_accuracy: 0.8100\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.2138 - accuracy: 0.9550 - val_loss: 0.5294 - val_accuracy: 0.8150\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1939 - accuracy: 0.9650 - val_loss: 0.5293 - val_accuracy: 0.8100\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2110 - accuracy: 0.9488 - val_loss: 0.5273 - val_accuracy: 0.8100\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1825 - accuracy: 0.9737 - val_loss: 0.5259 - val_accuracy: 0.8100\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1977 - accuracy: 0.9575 - val_loss: 0.5228 - val_accuracy: 0.8200\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2191 - accuracy: 0.9438 - val_loss: 0.5279 - val_accuracy: 0.8100\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1917 - accuracy: 0.9588 - val_loss: 0.5255 - val_accuracy: 0.8200\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1884 - accuracy: 0.9588 - val_loss: 0.5250 - val_accuracy: 0.8100\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.1938 - accuracy: 0.9575 - val_loss: 0.5226 - val_accuracy: 0.8200\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1890 - accuracy: 0.9588 - val_loss: 0.5235 - val_accuracy: 0.8150\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1788 - accuracy: 0.9675 - val_loss: 0.5213 - val_accuracy: 0.8150\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1952 - accuracy: 0.9475 - val_loss: 0.5217 - val_accuracy: 0.8200\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1948 - accuracy: 0.9488 - val_loss: 0.5236 - val_accuracy: 0.8250\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1904 - accuracy: 0.9563 - val_loss: 0.5214 - val_accuracy: 0.8250\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1674 - accuracy: 0.9663 - val_loss: 0.5279 - val_accuracy: 0.8100\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1741 - accuracy: 0.9600 - val_loss: 0.5223 - val_accuracy: 0.8300\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1669 - accuracy: 0.9712 - val_loss: 0.5210 - val_accuracy: 0.8350\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1620 - accuracy: 0.9688 - val_loss: 0.5235 - val_accuracy: 0.8300\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1842 - accuracy: 0.9500 - val_loss: 0.5233 - val_accuracy: 0.8250\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 2.6594 - accuracy: 0.1050\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.6370 - accuracy: 0.1325 - val_loss: 2.2946 - val_accuracy: 0.1550\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.2906 - accuracy: 0.1963 - val_loss: 2.0309 - val_accuracy: 0.2700\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 2.0169 - accuracy: 0.2975 - val_loss: 1.8059 - val_accuracy: 0.3800\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.8193 - accuracy: 0.3688 - val_loss: 1.6218 - val_accuracy: 0.4850\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.6392 - accuracy: 0.4263 - val_loss: 1.4687 - val_accuracy: 0.5700\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.4654 - accuracy: 0.5325 - val_loss: 1.3436 - val_accuracy: 0.6300\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.3954 - accuracy: 0.5600 - val_loss: 1.2436 - val_accuracy: 0.6700\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.2500 - accuracy: 0.6212 - val_loss: 1.1590 - val_accuracy: 0.6900\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.1855 - accuracy: 0.6275 - val_loss: 1.0845 - val_accuracy: 0.7150\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.0962 - accuracy: 0.6875 - val_loss: 1.0258 - val_accuracy: 0.7300\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0453 - accuracy: 0.7075 - val_loss: 0.9785 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.9584 - accuracy: 0.7225 - val_loss: 0.9307 - val_accuracy: 0.7550\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.9127 - accuracy: 0.7287 - val_loss: 0.8932 - val_accuracy: 0.7700\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8799 - accuracy: 0.7462 - val_loss: 0.8665 - val_accuracy: 0.7800\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8101 - accuracy: 0.7663 - val_loss: 0.8348 - val_accuracy: 0.7850\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8010 - accuracy: 0.7650 - val_loss: 0.8100 - val_accuracy: 0.7800\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7873 - accuracy: 0.7837 - val_loss: 0.7880 - val_accuracy: 0.7850\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7188 - accuracy: 0.8050 - val_loss: 0.7684 - val_accuracy: 0.7800\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.7229 - accuracy: 0.8037 - val_loss: 0.7558 - val_accuracy: 0.7800\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6737 - accuracy: 0.8100 - val_loss: 0.7379 - val_accuracy: 0.7750\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6639 - accuracy: 0.8188 - val_loss: 0.7240 - val_accuracy: 0.7800\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6522 - accuracy: 0.8150 - val_loss: 0.7130 - val_accuracy: 0.8050\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6060 - accuracy: 0.8438 - val_loss: 0.7020 - val_accuracy: 0.7950\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6027 - accuracy: 0.8288 - val_loss: 0.6883 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5518 - accuracy: 0.8637 - val_loss: 0.6787 - val_accuracy: 0.8100\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5810 - accuracy: 0.8325 - val_loss: 0.6691 - val_accuracy: 0.8050\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5620 - accuracy: 0.8475 - val_loss: 0.6540 - val_accuracy: 0.8100\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5542 - accuracy: 0.8400 - val_loss: 0.6500 - val_accuracy: 0.8050\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5325 - accuracy: 0.8537 - val_loss: 0.6453 - val_accuracy: 0.8100\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5246 - accuracy: 0.8587 - val_loss: 0.6359 - val_accuracy: 0.8150\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4978 - accuracy: 0.8700 - val_loss: 0.6295 - val_accuracy: 0.8050\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4881 - accuracy: 0.8700 - val_loss: 0.6198 - val_accuracy: 0.8150\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4774 - accuracy: 0.8700 - val_loss: 0.6148 - val_accuracy: 0.8200\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4895 - accuracy: 0.8438 - val_loss: 0.6128 - val_accuracy: 0.8200\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4666 - accuracy: 0.8737 - val_loss: 0.6084 - val_accuracy: 0.8200\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4436 - accuracy: 0.8850 - val_loss: 0.6038 - val_accuracy: 0.8200\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4491 - accuracy: 0.8575 - val_loss: 0.5976 - val_accuracy: 0.8150\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4431 - accuracy: 0.8838 - val_loss: 0.5910 - val_accuracy: 0.8200\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4313 - accuracy: 0.8838 - val_loss: 0.5858 - val_accuracy: 0.8200\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4089 - accuracy: 0.8913 - val_loss: 0.5829 - val_accuracy: 0.8250\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3717 - accuracy: 0.9137 - val_loss: 0.5807 - val_accuracy: 0.8150\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3708 - accuracy: 0.9062 - val_loss: 0.5765 - val_accuracy: 0.8200\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4008 - accuracy: 0.9075 - val_loss: 0.5730 - val_accuracy: 0.8150\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3639 - accuracy: 0.8963 - val_loss: 0.5711 - val_accuracy: 0.8150\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3782 - accuracy: 0.8975 - val_loss: 0.5711 - val_accuracy: 0.8150\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3940 - accuracy: 0.8988 - val_loss: 0.5675 - val_accuracy: 0.8200\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3530 - accuracy: 0.9087 - val_loss: 0.5646 - val_accuracy: 0.8250\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3518 - accuracy: 0.9062 - val_loss: 0.5633 - val_accuracy: 0.8200\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3479 - accuracy: 0.9087 - val_loss: 0.5633 - val_accuracy: 0.8200\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3461 - accuracy: 0.9100 - val_loss: 0.5636 - val_accuracy: 0.8300\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3180 - accuracy: 0.9112 - val_loss: 0.5576 - val_accuracy: 0.8250\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3317 - accuracy: 0.9175 - val_loss: 0.5592 - val_accuracy: 0.8250\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3337 - accuracy: 0.9087 - val_loss: 0.5566 - val_accuracy: 0.8250\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3285 - accuracy: 0.9175 - val_loss: 0.5449 - val_accuracy: 0.8250\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3116 - accuracy: 0.9275 - val_loss: 0.5446 - val_accuracy: 0.8300\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3125 - accuracy: 0.9250 - val_loss: 0.5413 - val_accuracy: 0.8250\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3060 - accuracy: 0.9125 - val_loss: 0.5388 - val_accuracy: 0.8300\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3191 - accuracy: 0.9187 - val_loss: 0.5418 - val_accuracy: 0.8300\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3027 - accuracy: 0.9150 - val_loss: 0.5400 - val_accuracy: 0.8300\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2886 - accuracy: 0.9350 - val_loss: 0.5361 - val_accuracy: 0.8250\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2814 - accuracy: 0.9312 - val_loss: 0.5321 - val_accuracy: 0.8350\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2728 - accuracy: 0.9250 - val_loss: 0.5359 - val_accuracy: 0.8350\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2906 - accuracy: 0.9300 - val_loss: 0.5367 - val_accuracy: 0.8300\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2743 - accuracy: 0.9262 - val_loss: 0.5346 - val_accuracy: 0.8300\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2719 - accuracy: 0.9225 - val_loss: 0.5324 - val_accuracy: 0.8400\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2660 - accuracy: 0.9287 - val_loss: 0.5330 - val_accuracy: 0.8250\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.2619 - accuracy: 0.9438 - val_loss: 0.5312 - val_accuracy: 0.8200\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2515 - accuracy: 0.9362 - val_loss: 0.5358 - val_accuracy: 0.8350\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2658 - accuracy: 0.9388 - val_loss: 0.5307 - val_accuracy: 0.8300\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2458 - accuracy: 0.9438 - val_loss: 0.5293 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2388 - accuracy: 0.9463 - val_loss: 0.5277 - val_accuracy: 0.8250\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2448 - accuracy: 0.9312 - val_loss: 0.5241 - val_accuracy: 0.8350\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2339 - accuracy: 0.9413 - val_loss: 0.5248 - val_accuracy: 0.8350\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2460 - accuracy: 0.9362 - val_loss: 0.5256 - val_accuracy: 0.8250\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2461 - accuracy: 0.9413 - val_loss: 0.5239 - val_accuracy: 0.8250\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2306 - accuracy: 0.9438 - val_loss: 0.5243 - val_accuracy: 0.8300\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2137 - accuracy: 0.9550 - val_loss: 0.5199 - val_accuracy: 0.8300\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2118 - accuracy: 0.9600 - val_loss: 0.5160 - val_accuracy: 0.8200\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2267 - accuracy: 0.9525 - val_loss: 0.5199 - val_accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2358 - accuracy: 0.9438 - val_loss: 0.5192 - val_accuracy: 0.8200\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2002 - accuracy: 0.9550 - val_loss: 0.5221 - val_accuracy: 0.8250\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2175 - accuracy: 0.9525 - val_loss: 0.5169 - val_accuracy: 0.8250\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2015 - accuracy: 0.9575 - val_loss: 0.5196 - val_accuracy: 0.8250\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.1995 - accuracy: 0.9550 - val_loss: 0.5106 - val_accuracy: 0.8250\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1990 - accuracy: 0.9550 - val_loss: 0.5120 - val_accuracy: 0.8300\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1975 - accuracy: 0.9538 - val_loss: 0.5170 - val_accuracy: 0.8200\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2020 - accuracy: 0.9600 - val_loss: 0.5205 - val_accuracy: 0.8150\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2237 - accuracy: 0.9513 - val_loss: 0.5157 - val_accuracy: 0.8250\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2114 - accuracy: 0.9500 - val_loss: 0.5122 - val_accuracy: 0.8350\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1768 - accuracy: 0.9712 - val_loss: 0.5103 - val_accuracy: 0.8350\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1972 - accuracy: 0.9588 - val_loss: 0.5139 - val_accuracy: 0.8300\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1824 - accuracy: 0.9625 - val_loss: 0.5159 - val_accuracy: 0.8300\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1934 - accuracy: 0.9538 - val_loss: 0.5212 - val_accuracy: 0.8300\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1909 - accuracy: 0.9600 - val_loss: 0.5110 - val_accuracy: 0.8250\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2025 - accuracy: 0.9563 - val_loss: 0.5055 - val_accuracy: 0.8400\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1864 - accuracy: 0.9588 - val_loss: 0.5039 - val_accuracy: 0.8350\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1764 - accuracy: 0.9675 - val_loss: 0.5122 - val_accuracy: 0.8300\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1847 - accuracy: 0.9613 - val_loss: 0.5118 - val_accuracy: 0.8250\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1716 - accuracy: 0.9600 - val_loss: 0.5148 - val_accuracy: 0.8250\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1800 - accuracy: 0.9588 - val_loss: 0.5047 - val_accuracy: 0.8250\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 2.7314 - accuracy: 0.1000\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.6197 - accuracy: 0.1213 - val_loss: 2.4051 - val_accuracy: 0.1600\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.2931 - accuracy: 0.2062 - val_loss: 2.1441 - val_accuracy: 0.2450\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.0582 - accuracy: 0.2525 - val_loss: 1.9213 - val_accuracy: 0.3350\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.8200 - accuracy: 0.3787 - val_loss: 1.7357 - val_accuracy: 0.4400\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.6360 - accuracy: 0.4250 - val_loss: 1.5801 - val_accuracy: 0.5150\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.4840 - accuracy: 0.5088 - val_loss: 1.4460 - val_accuracy: 0.5700\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.3683 - accuracy: 0.5688 - val_loss: 1.3352 - val_accuracy: 0.6100\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.2658 - accuracy: 0.6012 - val_loss: 1.2469 - val_accuracy: 0.6450\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.1602 - accuracy: 0.6587 - val_loss: 1.1634 - val_accuracy: 0.6950\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0813 - accuracy: 0.6850 - val_loss: 1.0991 - val_accuracy: 0.7100\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0179 - accuracy: 0.7100 - val_loss: 1.0423 - val_accuracy: 0.7250\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.9504 - accuracy: 0.7225 - val_loss: 0.9946 - val_accuracy: 0.7500\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.9295 - accuracy: 0.7362 - val_loss: 0.9456 - val_accuracy: 0.7650\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8899 - accuracy: 0.7425 - val_loss: 0.9128 - val_accuracy: 0.7650\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8246 - accuracy: 0.7613 - val_loss: 0.8789 - val_accuracy: 0.7700\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7652 - accuracy: 0.7812 - val_loss: 0.8452 - val_accuracy: 0.7750\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7772 - accuracy: 0.7563 - val_loss: 0.8184 - val_accuracy: 0.7750\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7441 - accuracy: 0.7763 - val_loss: 0.7978 - val_accuracy: 0.7850\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7227 - accuracy: 0.8025 - val_loss: 0.7788 - val_accuracy: 0.7850\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6709 - accuracy: 0.8100 - val_loss: 0.7600 - val_accuracy: 0.7900\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6740 - accuracy: 0.8062 - val_loss: 0.7403 - val_accuracy: 0.7950\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6173 - accuracy: 0.8238 - val_loss: 0.7241 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6258 - accuracy: 0.8263 - val_loss: 0.7059 - val_accuracy: 0.8100\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5826 - accuracy: 0.8338 - val_loss: 0.6929 - val_accuracy: 0.8050\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5778 - accuracy: 0.8363 - val_loss: 0.6860 - val_accuracy: 0.8100\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5925 - accuracy: 0.8288 - val_loss: 0.6735 - val_accuracy: 0.8100\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5624 - accuracy: 0.8400 - val_loss: 0.6611 - val_accuracy: 0.8250\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5534 - accuracy: 0.8450 - val_loss: 0.6529 - val_accuracy: 0.8250\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5245 - accuracy: 0.8500 - val_loss: 0.6426 - val_accuracy: 0.8250\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5147 - accuracy: 0.8525 - val_loss: 0.6341 - val_accuracy: 0.8250\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5160 - accuracy: 0.8512 - val_loss: 0.6235 - val_accuracy: 0.8250\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4825 - accuracy: 0.8675 - val_loss: 0.6165 - val_accuracy: 0.8250\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4760 - accuracy: 0.8637 - val_loss: 0.6083 - val_accuracy: 0.8250\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4780 - accuracy: 0.8650 - val_loss: 0.6003 - val_accuracy: 0.8300\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4576 - accuracy: 0.8763 - val_loss: 0.5962 - val_accuracy: 0.8250\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4524 - accuracy: 0.8737 - val_loss: 0.5866 - val_accuracy: 0.8350\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4515 - accuracy: 0.8662 - val_loss: 0.5809 - val_accuracy: 0.8350\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4285 - accuracy: 0.8838 - val_loss: 0.5764 - val_accuracy: 0.8400\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4249 - accuracy: 0.8813 - val_loss: 0.5694 - val_accuracy: 0.8400\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4271 - accuracy: 0.8737 - val_loss: 0.5647 - val_accuracy: 0.8400\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4083 - accuracy: 0.8800 - val_loss: 0.5617 - val_accuracy: 0.8350\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4050 - accuracy: 0.8925 - val_loss: 0.5560 - val_accuracy: 0.8350\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3744 - accuracy: 0.8913 - val_loss: 0.5527 - val_accuracy: 0.8400\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3745 - accuracy: 0.9038 - val_loss: 0.5494 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3857 - accuracy: 0.8913 - val_loss: 0.5485 - val_accuracy: 0.8450\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3786 - accuracy: 0.8938 - val_loss: 0.5428 - val_accuracy: 0.8400\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3673 - accuracy: 0.8938 - val_loss: 0.5383 - val_accuracy: 0.8450\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3668 - accuracy: 0.9000 - val_loss: 0.5377 - val_accuracy: 0.8450\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3597 - accuracy: 0.9050 - val_loss: 0.5308 - val_accuracy: 0.8450\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3678 - accuracy: 0.9050 - val_loss: 0.5240 - val_accuracy: 0.8450\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3252 - accuracy: 0.9275 - val_loss: 0.5218 - val_accuracy: 0.8450\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3478 - accuracy: 0.9175 - val_loss: 0.5170 - val_accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3516 - accuracy: 0.9062 - val_loss: 0.5156 - val_accuracy: 0.8450\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3254 - accuracy: 0.9100 - val_loss: 0.5128 - val_accuracy: 0.8450\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3181 - accuracy: 0.9187 - val_loss: 0.5106 - val_accuracy: 0.8450\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3295 - accuracy: 0.9087 - val_loss: 0.5098 - val_accuracy: 0.8400\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2958 - accuracy: 0.9087 - val_loss: 0.5064 - val_accuracy: 0.8450\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3132 - accuracy: 0.9262 - val_loss: 0.5034 - val_accuracy: 0.8450\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2963 - accuracy: 0.9275 - val_loss: 0.5051 - val_accuracy: 0.8500\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2952 - accuracy: 0.9212 - val_loss: 0.4997 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2987 - accuracy: 0.9225 - val_loss: 0.4984 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2983 - accuracy: 0.9125 - val_loss: 0.4952 - val_accuracy: 0.8400\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2884 - accuracy: 0.9262 - val_loss: 0.4920 - val_accuracy: 0.8450\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2949 - accuracy: 0.9275 - val_loss: 0.4870 - val_accuracy: 0.8450\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2956 - accuracy: 0.9187 - val_loss: 0.4847 - val_accuracy: 0.8500\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2873 - accuracy: 0.9262 - val_loss: 0.4840 - val_accuracy: 0.8450\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2755 - accuracy: 0.9337 - val_loss: 0.4835 - val_accuracy: 0.8500\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2634 - accuracy: 0.9300 - val_loss: 0.4842 - val_accuracy: 0.8550\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2728 - accuracy: 0.9325 - val_loss: 0.4823 - val_accuracy: 0.8450\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2747 - accuracy: 0.9300 - val_loss: 0.4811 - val_accuracy: 0.8450\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2658 - accuracy: 0.9275 - val_loss: 0.4824 - val_accuracy: 0.8450\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2506 - accuracy: 0.9400 - val_loss: 0.4745 - val_accuracy: 0.8500\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2406 - accuracy: 0.9463 - val_loss: 0.4754 - val_accuracy: 0.8500\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2570 - accuracy: 0.9250 - val_loss: 0.4702 - val_accuracy: 0.8500\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2340 - accuracy: 0.9463 - val_loss: 0.4695 - val_accuracy: 0.8600\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2506 - accuracy: 0.9312 - val_loss: 0.4675 - val_accuracy: 0.8550\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2469 - accuracy: 0.9287 - val_loss: 0.4658 - val_accuracy: 0.8600\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2417 - accuracy: 0.9337 - val_loss: 0.4644 - val_accuracy: 0.8600\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2365 - accuracy: 0.9438 - val_loss: 0.4631 - val_accuracy: 0.8500\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2413 - accuracy: 0.9475 - val_loss: 0.4663 - val_accuracy: 0.8550\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2226 - accuracy: 0.9475 - val_loss: 0.4642 - val_accuracy: 0.8600\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2300 - accuracy: 0.9488 - val_loss: 0.4604 - val_accuracy: 0.8550\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2323 - accuracy: 0.9450 - val_loss: 0.4640 - val_accuracy: 0.8550\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2124 - accuracy: 0.9450 - val_loss: 0.4586 - val_accuracy: 0.8600\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2243 - accuracy: 0.9450 - val_loss: 0.4574 - val_accuracy: 0.8550\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2127 - accuracy: 0.9450 - val_loss: 0.4631 - val_accuracy: 0.8550\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2102 - accuracy: 0.9463 - val_loss: 0.4589 - val_accuracy: 0.8600\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1958 - accuracy: 0.9525 - val_loss: 0.4607 - val_accuracy: 0.8600\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1938 - accuracy: 0.9663 - val_loss: 0.4608 - val_accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1859 - accuracy: 0.9650 - val_loss: 0.4585 - val_accuracy: 0.8600\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1855 - accuracy: 0.9650 - val_loss: 0.4567 - val_accuracy: 0.8550\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2099 - accuracy: 0.9500 - val_loss: 0.4595 - val_accuracy: 0.8600\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1890 - accuracy: 0.9538 - val_loss: 0.4555 - val_accuracy: 0.8600\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1877 - accuracy: 0.9737 - val_loss: 0.4573 - val_accuracy: 0.8600\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1908 - accuracy: 0.9563 - val_loss: 0.4552 - val_accuracy: 0.8550\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1847 - accuracy: 0.9550 - val_loss: 0.4548 - val_accuracy: 0.8550\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1972 - accuracy: 0.9463 - val_loss: 0.4538 - val_accuracy: 0.8600\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1831 - accuracy: 0.9625 - val_loss: 0.4498 - val_accuracy: 0.8600\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1657 - accuracy: 0.9675 - val_loss: 0.4487 - val_accuracy: 0.8600\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1878 - accuracy: 0.9550 - val_loss: 0.4476 - val_accuracy: 0.8550\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 2.5234 - accuracy: 0.1600\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.4232 - accuracy: 0.1762 - val_loss: 2.2295 - val_accuracy: 0.2450\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 2.1171 - accuracy: 0.2700 - val_loss: 2.0009 - val_accuracy: 0.3150\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.8620 - accuracy: 0.3700 - val_loss: 1.8023 - val_accuracy: 0.3800\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.6644 - accuracy: 0.4563 - val_loss: 1.6355 - val_accuracy: 0.4300\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.5417 - accuracy: 0.4825 - val_loss: 1.4969 - val_accuracy: 0.4950\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.3678 - accuracy: 0.5575 - val_loss: 1.3756 - val_accuracy: 0.5400\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.2694 - accuracy: 0.6062 - val_loss: 1.2756 - val_accuracy: 0.5850\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.1609 - accuracy: 0.6488 - val_loss: 1.2014 - val_accuracy: 0.6100\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.1192 - accuracy: 0.6575 - val_loss: 1.1246 - val_accuracy: 0.6450\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0245 - accuracy: 0.7050 - val_loss: 1.0724 - val_accuracy: 0.6800\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.9683 - accuracy: 0.7138 - val_loss: 1.0145 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.9018 - accuracy: 0.7300 - val_loss: 0.9693 - val_accuracy: 0.7200\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8402 - accuracy: 0.7725 - val_loss: 0.9369 - val_accuracy: 0.7300\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8340 - accuracy: 0.7600 - val_loss: 0.9022 - val_accuracy: 0.7400\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8026 - accuracy: 0.7638 - val_loss: 0.8783 - val_accuracy: 0.7350\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7724 - accuracy: 0.7638 - val_loss: 0.8494 - val_accuracy: 0.7700\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.7303 - accuracy: 0.7975 - val_loss: 0.8264 - val_accuracy: 0.7750\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6843 - accuracy: 0.8087 - val_loss: 0.8065 - val_accuracy: 0.7800\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6720 - accuracy: 0.8200 - val_loss: 0.7879 - val_accuracy: 0.7650\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6381 - accuracy: 0.8338 - val_loss: 0.7745 - val_accuracy: 0.7800\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.6404 - accuracy: 0.8075 - val_loss: 0.7647 - val_accuracy: 0.7800\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6258 - accuracy: 0.8313 - val_loss: 0.7542 - val_accuracy: 0.7850\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6076 - accuracy: 0.8288 - val_loss: 0.7372 - val_accuracy: 0.7800\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5802 - accuracy: 0.8425 - val_loss: 0.7255 - val_accuracy: 0.7850\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5650 - accuracy: 0.8438 - val_loss: 0.7203 - val_accuracy: 0.7900\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5509 - accuracy: 0.8487 - val_loss: 0.7060 - val_accuracy: 0.7950\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5226 - accuracy: 0.8725 - val_loss: 0.6975 - val_accuracy: 0.7900\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5168 - accuracy: 0.8537 - val_loss: 0.6876 - val_accuracy: 0.7950\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5033 - accuracy: 0.8562 - val_loss: 0.6826 - val_accuracy: 0.7900\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4971 - accuracy: 0.8537 - val_loss: 0.6741 - val_accuracy: 0.7950\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4929 - accuracy: 0.8562 - val_loss: 0.6662 - val_accuracy: 0.7950\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4773 - accuracy: 0.8650 - val_loss: 0.6588 - val_accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4558 - accuracy: 0.8712 - val_loss: 0.6556 - val_accuracy: 0.7950\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4646 - accuracy: 0.8687 - val_loss: 0.6516 - val_accuracy: 0.7950\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4477 - accuracy: 0.8775 - val_loss: 0.6501 - val_accuracy: 0.7950\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4280 - accuracy: 0.8913 - val_loss: 0.6504 - val_accuracy: 0.8000\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4025 - accuracy: 0.8900 - val_loss: 0.6385 - val_accuracy: 0.8050\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4180 - accuracy: 0.8913 - val_loss: 0.6353 - val_accuracy: 0.8100\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4195 - accuracy: 0.8838 - val_loss: 0.6286 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3916 - accuracy: 0.8913 - val_loss: 0.6309 - val_accuracy: 0.8000\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3884 - accuracy: 0.8750 - val_loss: 0.6304 - val_accuracy: 0.8050\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3979 - accuracy: 0.8888 - val_loss: 0.6250 - val_accuracy: 0.8100\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3746 - accuracy: 0.9013 - val_loss: 0.6171 - val_accuracy: 0.8100\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3722 - accuracy: 0.9000 - val_loss: 0.6192 - val_accuracy: 0.8050\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3684 - accuracy: 0.9013 - val_loss: 0.6104 - val_accuracy: 0.8100\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3475 - accuracy: 0.9112 - val_loss: 0.6145 - val_accuracy: 0.8100\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3422 - accuracy: 0.9100 - val_loss: 0.6115 - val_accuracy: 0.8100\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3524 - accuracy: 0.9162 - val_loss: 0.6087 - val_accuracy: 0.8100\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3182 - accuracy: 0.9212 - val_loss: 0.6038 - val_accuracy: 0.8100\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3364 - accuracy: 0.9050 - val_loss: 0.6047 - val_accuracy: 0.8050\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3162 - accuracy: 0.9225 - val_loss: 0.6002 - val_accuracy: 0.8150\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3210 - accuracy: 0.9125 - val_loss: 0.6000 - val_accuracy: 0.8100\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3162 - accuracy: 0.9212 - val_loss: 0.5996 - val_accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2995 - accuracy: 0.9137 - val_loss: 0.5996 - val_accuracy: 0.8150\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3157 - accuracy: 0.9125 - val_loss: 0.6025 - val_accuracy: 0.8050\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2957 - accuracy: 0.9237 - val_loss: 0.5969 - val_accuracy: 0.8150\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3030 - accuracy: 0.9237 - val_loss: 0.5852 - val_accuracy: 0.8150\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2894 - accuracy: 0.9337 - val_loss: 0.5876 - val_accuracy: 0.8150\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2892 - accuracy: 0.9200 - val_loss: 0.5907 - val_accuracy: 0.8100\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2712 - accuracy: 0.9400 - val_loss: 0.5818 - val_accuracy: 0.8100\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2849 - accuracy: 0.9262 - val_loss: 0.5868 - val_accuracy: 0.8100\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3004 - accuracy: 0.9262 - val_loss: 0.5888 - val_accuracy: 0.8050\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2633 - accuracy: 0.9450 - val_loss: 0.5862 - val_accuracy: 0.8150\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2721 - accuracy: 0.9237 - val_loss: 0.5810 - val_accuracy: 0.8150\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2728 - accuracy: 0.9262 - val_loss: 0.5791 - val_accuracy: 0.8350\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2593 - accuracy: 0.9312 - val_loss: 0.5807 - val_accuracy: 0.8200\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2532 - accuracy: 0.9413 - val_loss: 0.5836 - val_accuracy: 0.8250\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2586 - accuracy: 0.9425 - val_loss: 0.5834 - val_accuracy: 0.8250\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2397 - accuracy: 0.9362 - val_loss: 0.5835 - val_accuracy: 0.8200\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2493 - accuracy: 0.9375 - val_loss: 0.5887 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2563 - accuracy: 0.9362 - val_loss: 0.5793 - val_accuracy: 0.8250\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2527 - accuracy: 0.9325 - val_loss: 0.5848 - val_accuracy: 0.8250\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2320 - accuracy: 0.9588 - val_loss: 0.5753 - val_accuracy: 0.8300\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2365 - accuracy: 0.9563 - val_loss: 0.5820 - val_accuracy: 0.8250\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2253 - accuracy: 0.9488 - val_loss: 0.5812 - val_accuracy: 0.8250\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2340 - accuracy: 0.9413 - val_loss: 0.5855 - val_accuracy: 0.8250\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2378 - accuracy: 0.9488 - val_loss: 0.5868 - val_accuracy: 0.8200\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1940 - accuracy: 0.9638 - val_loss: 0.5870 - val_accuracy: 0.8100\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2079 - accuracy: 0.9525 - val_loss: 0.5805 - val_accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2198 - accuracy: 0.9425 - val_loss: 0.5843 - val_accuracy: 0.8200\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2161 - accuracy: 0.9538 - val_loss: 0.5880 - val_accuracy: 0.8150\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2123 - accuracy: 0.9575 - val_loss: 0.5837 - val_accuracy: 0.8250\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2054 - accuracy: 0.9563 - val_loss: 0.5842 - val_accuracy: 0.8250\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1927 - accuracy: 0.9700 - val_loss: 0.5840 - val_accuracy: 0.8250\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2087 - accuracy: 0.9550 - val_loss: 0.5825 - val_accuracy: 0.8250\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2001 - accuracy: 0.9500 - val_loss: 0.5822 - val_accuracy: 0.8250\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1776 - accuracy: 0.9737 - val_loss: 0.5861 - val_accuracy: 0.8200\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1956 - accuracy: 0.9500 - val_loss: 0.5827 - val_accuracy: 0.8300\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1907 - accuracy: 0.9525 - val_loss: 0.5916 - val_accuracy: 0.8200\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1907 - accuracy: 0.9563 - val_loss: 0.5828 - val_accuracy: 0.8250\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1829 - accuracy: 0.9688 - val_loss: 0.5888 - val_accuracy: 0.8250\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1823 - accuracy: 0.9600 - val_loss: 0.5806 - val_accuracy: 0.8250\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1633 - accuracy: 0.9725 - val_loss: 0.5797 - val_accuracy: 0.8300\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1803 - accuracy: 0.9650 - val_loss: 0.5842 - val_accuracy: 0.8250\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1801 - accuracy: 0.9600 - val_loss: 0.5815 - val_accuracy: 0.8300\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1874 - accuracy: 0.9513 - val_loss: 0.5765 - val_accuracy: 0.8300\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1881 - accuracy: 0.9525 - val_loss: 0.5803 - val_accuracy: 0.8300\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1770 - accuracy: 0.9600 - val_loss: 0.5794 - val_accuracy: 0.8250\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1716 - accuracy: 0.9600 - val_loss: 0.5787 - val_accuracy: 0.8250\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1690 - accuracy: 0.9663 - val_loss: 0.5780 - val_accuracy: 0.8250\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 2.7076 - accuracy: 0.1050\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 2.6054 - accuracy: 0.1325 - val_loss: 2.3059 - val_accuracy: 0.1950\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 2.2249 - accuracy: 0.2013 - val_loss: 2.0442 - val_accuracy: 0.3050\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 2.0188 - accuracy: 0.2788 - val_loss: 1.8222 - val_accuracy: 0.3500\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.7942 - accuracy: 0.3787 - val_loss: 1.6350 - val_accuracy: 0.4500\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.6043 - accuracy: 0.4375 - val_loss: 1.4944 - val_accuracy: 0.5200\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.4540 - accuracy: 0.5263 - val_loss: 1.3711 - val_accuracy: 0.5600\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.3165 - accuracy: 0.5562 - val_loss: 1.2646 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.2109 - accuracy: 0.6363 - val_loss: 1.1839 - val_accuracy: 0.6350\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.1729 - accuracy: 0.6525 - val_loss: 1.1137 - val_accuracy: 0.6550\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0561 - accuracy: 0.6963 - val_loss: 1.0518 - val_accuracy: 0.6950\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0149 - accuracy: 0.6913 - val_loss: 1.0026 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.9557 - accuracy: 0.7188 - val_loss: 0.9583 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.9069 - accuracy: 0.7437 - val_loss: 0.9139 - val_accuracy: 0.7100\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.8918 - accuracy: 0.7387 - val_loss: 0.8786 - val_accuracy: 0.7250\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.8251 - accuracy: 0.7613 - val_loss: 0.8495 - val_accuracy: 0.7150\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.7974 - accuracy: 0.7650 - val_loss: 0.8237 - val_accuracy: 0.7250\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.7571 - accuracy: 0.7775 - val_loss: 0.7995 - val_accuracy: 0.7450\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.7147 - accuracy: 0.8125 - val_loss: 0.7750 - val_accuracy: 0.7450\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.7351 - accuracy: 0.7975 - val_loss: 0.7592 - val_accuracy: 0.7450\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6798 - accuracy: 0.7925 - val_loss: 0.7407 - val_accuracy: 0.7450\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.6592 - accuracy: 0.8138 - val_loss: 0.7223 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.6429 - accuracy: 0.8188 - val_loss: 0.7120 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.6079 - accuracy: 0.8350 - val_loss: 0.6957 - val_accuracy: 0.7650\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6181 - accuracy: 0.8200 - val_loss: 0.6838 - val_accuracy: 0.7600\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.5783 - accuracy: 0.8313 - val_loss: 0.6686 - val_accuracy: 0.7750\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 0.5739 - accuracy: 0.8388 - val_loss: 0.6568 - val_accuracy: 0.7850\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.5415 - accuracy: 0.8462 - val_loss: 0.6490 - val_accuracy: 0.7700\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.5331 - accuracy: 0.8525 - val_loss: 0.6415 - val_accuracy: 0.7700\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.5328 - accuracy: 0.8500 - val_loss: 0.6326 - val_accuracy: 0.7700\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4985 - accuracy: 0.8675 - val_loss: 0.6272 - val_accuracy: 0.7750\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.5140 - accuracy: 0.8562 - val_loss: 0.6203 - val_accuracy: 0.7850\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4857 - accuracy: 0.8662 - val_loss: 0.6105 - val_accuracy: 0.7800\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4673 - accuracy: 0.8750 - val_loss: 0.6000 - val_accuracy: 0.7850\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4809 - accuracy: 0.8750 - val_loss: 0.5932 - val_accuracy: 0.7850\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4759 - accuracy: 0.8675 - val_loss: 0.5873 - val_accuracy: 0.8050\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4574 - accuracy: 0.8650 - val_loss: 0.5825 - val_accuracy: 0.7900\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4306 - accuracy: 0.9000 - val_loss: 0.5759 - val_accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4175 - accuracy: 0.8913 - val_loss: 0.5692 - val_accuracy: 0.7900\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4279 - accuracy: 0.8750 - val_loss: 0.5646 - val_accuracy: 0.7900\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4226 - accuracy: 0.8788 - val_loss: 0.5641 - val_accuracy: 0.7900\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4031 - accuracy: 0.8950 - val_loss: 0.5600 - val_accuracy: 0.7950\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4100 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.8000\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3746 - accuracy: 0.8963 - val_loss: 0.5493 - val_accuracy: 0.8000\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3722 - accuracy: 0.8975 - val_loss: 0.5468 - val_accuracy: 0.7900\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3719 - accuracy: 0.9100 - val_loss: 0.5459 - val_accuracy: 0.7850\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3540 - accuracy: 0.9087 - val_loss: 0.5402 - val_accuracy: 0.7950\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3662 - accuracy: 0.9050 - val_loss: 0.5346 - val_accuracy: 0.7950\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3507 - accuracy: 0.8988 - val_loss: 0.5318 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3418 - accuracy: 0.9137 - val_loss: 0.5328 - val_accuracy: 0.7850\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3405 - accuracy: 0.9212 - val_loss: 0.5258 - val_accuracy: 0.7950\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3242 - accuracy: 0.9175 - val_loss: 0.5273 - val_accuracy: 0.7950\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3003 - accuracy: 0.9262 - val_loss: 0.5217 - val_accuracy: 0.8000\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3271 - accuracy: 0.9237 - val_loss: 0.5198 - val_accuracy: 0.8050\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3174 - accuracy: 0.9100 - val_loss: 0.5186 - val_accuracy: 0.8000\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3258 - accuracy: 0.9200 - val_loss: 0.5152 - val_accuracy: 0.8000\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3065 - accuracy: 0.9162 - val_loss: 0.5202 - val_accuracy: 0.8050\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3147 - accuracy: 0.9225 - val_loss: 0.5144 - val_accuracy: 0.8050\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2909 - accuracy: 0.9212 - val_loss: 0.5101 - val_accuracy: 0.8100\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2918 - accuracy: 0.9187 - val_loss: 0.5090 - val_accuracy: 0.8150\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2797 - accuracy: 0.9362 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2898 - accuracy: 0.9312 - val_loss: 0.4983 - val_accuracy: 0.8250\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2899 - accuracy: 0.9262 - val_loss: 0.5008 - val_accuracy: 0.8150\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2916 - accuracy: 0.9237 - val_loss: 0.4992 - val_accuracy: 0.8150\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2780 - accuracy: 0.9237 - val_loss: 0.4993 - val_accuracy: 0.8000\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2842 - accuracy: 0.9312 - val_loss: 0.4991 - val_accuracy: 0.8150\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2691 - accuracy: 0.9287 - val_loss: 0.4963 - val_accuracy: 0.8200\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2581 - accuracy: 0.9438 - val_loss: 0.4961 - val_accuracy: 0.8200\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2610 - accuracy: 0.9375 - val_loss: 0.4920 - val_accuracy: 0.8200\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2476 - accuracy: 0.9413 - val_loss: 0.4921 - val_accuracy: 0.8200\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2646 - accuracy: 0.9325 - val_loss: 0.4918 - val_accuracy: 0.8400\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2496 - accuracy: 0.9450 - val_loss: 0.4891 - val_accuracy: 0.8250\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2407 - accuracy: 0.9463 - val_loss: 0.4915 - val_accuracy: 0.8100\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2578 - accuracy: 0.9250 - val_loss: 0.4890 - val_accuracy: 0.8350\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2384 - accuracy: 0.9463 - val_loss: 0.4841 - val_accuracy: 0.8350\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2270 - accuracy: 0.9413 - val_loss: 0.4874 - val_accuracy: 0.8250\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2441 - accuracy: 0.9325 - val_loss: 0.4879 - val_accuracy: 0.8300\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2490 - accuracy: 0.9425 - val_loss: 0.4891 - val_accuracy: 0.8300\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2184 - accuracy: 0.9488 - val_loss: 0.4867 - val_accuracy: 0.8250\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2278 - accuracy: 0.9475 - val_loss: 0.4843 - val_accuracy: 0.8150\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2306 - accuracy: 0.9438 - val_loss: 0.4790 - val_accuracy: 0.8250\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2271 - accuracy: 0.9463 - val_loss: 0.4796 - val_accuracy: 0.8150\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2104 - accuracy: 0.9513 - val_loss: 0.4799 - val_accuracy: 0.8200\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2119 - accuracy: 0.9463 - val_loss: 0.4821 - val_accuracy: 0.8250\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.4787 - val_accuracy: 0.8300\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2068 - accuracy: 0.9563 - val_loss: 0.4790 - val_accuracy: 0.8250\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1983 - accuracy: 0.9588 - val_loss: 0.4755 - val_accuracy: 0.8200\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2025 - accuracy: 0.9563 - val_loss: 0.4704 - val_accuracy: 0.8300\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1998 - accuracy: 0.9588 - val_loss: 0.4724 - val_accuracy: 0.8400\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2104 - accuracy: 0.9525 - val_loss: 0.4749 - val_accuracy: 0.8250\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2019 - accuracy: 0.9588 - val_loss: 0.4729 - val_accuracy: 0.8250\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2167 - accuracy: 0.9450 - val_loss: 0.4693 - val_accuracy: 0.8250\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1808 - accuracy: 0.9688 - val_loss: 0.4695 - val_accuracy: 0.8350\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1832 - accuracy: 0.9563 - val_loss: 0.4652 - val_accuracy: 0.8350\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1880 - accuracy: 0.9675 - val_loss: 0.4663 - val_accuracy: 0.8250\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1957 - accuracy: 0.9500 - val_loss: 0.4643 - val_accuracy: 0.8300\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1801 - accuracy: 0.9575 - val_loss: 0.4744 - val_accuracy: 0.8450\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1823 - accuracy: 0.9563 - val_loss: 0.4726 - val_accuracy: 0.8350\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1752 - accuracy: 0.9625 - val_loss: 0.4731 - val_accuracy: 0.8300\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1816 - accuracy: 0.9638 - val_loss: 0.4695 - val_accuracy: 0.8250\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1687 - accuracy: 0.9663 - val_loss: 0.4714 - val_accuracy: 0.8250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "outputId": "c9e75ee4-e082-4848-d225-d1fdd755e7fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy after training\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.11399999856948853\n",
            "Final accuracy: 0.8429999947547913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "outputId": "c657e6d2-121f-43ac-8229-4fd0825b45ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "outputId": "6ba5e971-4a68-4d4f-8e4c-7dd76177b474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}