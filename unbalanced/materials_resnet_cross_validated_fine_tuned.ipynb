{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-transfer-learning-resnet-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXrT70du50wBHDybZjaj53"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "outputId": "a7470255-8e9d-4c9b-f163-b535d1aefce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "outputId": "988a4c7c-cb98-4fca-d4d7-048ed5825870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "outputId": "3c642d08-641e-486f-8d33-8d70b34e8dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "outputId": "c8488557-c40b-491e-ebb8-fba9362e86c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = -27"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "outputId": "dc44914c-199a-4bfb-c145-b6d846700f1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.ResNet50V2(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 110ms/step - loss: 2.5167 - accuracy: 0.1050\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 6s 114ms/step - loss: 2.4234 - accuracy: 0.1625 - val_loss: 2.1820 - val_accuracy: 0.1900\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 6s 115ms/step - loss: 2.1611 - accuracy: 0.2488 - val_loss: 1.9334 - val_accuracy: 0.3150\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 1.8976 - accuracy: 0.3487 - val_loss: 1.7230 - val_accuracy: 0.4300\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.6727 - accuracy: 0.4400 - val_loss: 1.5549 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.5226 - accuracy: 0.5050 - val_loss: 1.4222 - val_accuracy: 0.5450\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.3570 - accuracy: 0.5725 - val_loss: 1.3136 - val_accuracy: 0.5950\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 1.2610 - accuracy: 0.6175 - val_loss: 1.2309 - val_accuracy: 0.6350\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.1729 - accuracy: 0.6525 - val_loss: 1.1584 - val_accuracy: 0.6900\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0834 - accuracy: 0.6862 - val_loss: 1.0931 - val_accuracy: 0.6950\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.0132 - accuracy: 0.7013 - val_loss: 1.0407 - val_accuracy: 0.7100\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.9607 - accuracy: 0.7075 - val_loss: 0.9963 - val_accuracy: 0.7250\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.8900 - accuracy: 0.7650 - val_loss: 0.9592 - val_accuracy: 0.7350\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.8741 - accuracy: 0.7487 - val_loss: 0.9231 - val_accuracy: 0.7400\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 6s 115ms/step - loss: 0.8276 - accuracy: 0.7650 - val_loss: 0.8957 - val_accuracy: 0.7400\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.7672 - accuracy: 0.7862 - val_loss: 0.8671 - val_accuracy: 0.7400\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.7768 - accuracy: 0.7750 - val_loss: 0.8450 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.7133 - accuracy: 0.7837 - val_loss: 0.8220 - val_accuracy: 0.7550\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.7080 - accuracy: 0.7925 - val_loss: 0.8101 - val_accuracy: 0.7550\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6948 - accuracy: 0.7912 - val_loss: 0.7925 - val_accuracy: 0.7600\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6606 - accuracy: 0.8188 - val_loss: 0.7733 - val_accuracy: 0.7550\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6315 - accuracy: 0.8200 - val_loss: 0.7580 - val_accuracy: 0.7600\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6253 - accuracy: 0.8338 - val_loss: 0.7442 - val_accuracy: 0.7650\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6173 - accuracy: 0.8100 - val_loss: 0.7367 - val_accuracy: 0.7600\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6044 - accuracy: 0.8275 - val_loss: 0.7260 - val_accuracy: 0.7600\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.5745 - accuracy: 0.8275 - val_loss: 0.7128 - val_accuracy: 0.7700\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.5843 - accuracy: 0.8350 - val_loss: 0.7114 - val_accuracy: 0.7600\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5290 - accuracy: 0.8637 - val_loss: 0.6993 - val_accuracy: 0.7700\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5392 - accuracy: 0.8550 - val_loss: 0.6956 - val_accuracy: 0.7750\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.5086 - accuracy: 0.8625 - val_loss: 0.6821 - val_accuracy: 0.7800\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4977 - accuracy: 0.8612 - val_loss: 0.6733 - val_accuracy: 0.7850\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.5100 - accuracy: 0.8438 - val_loss: 0.6661 - val_accuracy: 0.7800\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4944 - accuracy: 0.8612 - val_loss: 0.6616 - val_accuracy: 0.7800\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4703 - accuracy: 0.8675 - val_loss: 0.6557 - val_accuracy: 0.7850\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4545 - accuracy: 0.8800 - val_loss: 0.6511 - val_accuracy: 0.7850\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4338 - accuracy: 0.8888 - val_loss: 0.6478 - val_accuracy: 0.7900\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.4366 - accuracy: 0.8788 - val_loss: 0.6434 - val_accuracy: 0.7850\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4152 - accuracy: 0.8763 - val_loss: 0.6383 - val_accuracy: 0.7850\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4137 - accuracy: 0.8888 - val_loss: 0.6268 - val_accuracy: 0.7950\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4118 - accuracy: 0.8913 - val_loss: 0.6259 - val_accuracy: 0.7900\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3875 - accuracy: 0.8963 - val_loss: 0.6221 - val_accuracy: 0.7900\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4035 - accuracy: 0.8975 - val_loss: 0.6185 - val_accuracy: 0.7900\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3873 - accuracy: 0.8925 - val_loss: 0.6110 - val_accuracy: 0.7950\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3834 - accuracy: 0.8913 - val_loss: 0.6078 - val_accuracy: 0.7950\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3701 - accuracy: 0.8988 - val_loss: 0.6067 - val_accuracy: 0.8100\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3486 - accuracy: 0.9187 - val_loss: 0.6017 - val_accuracy: 0.8050\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3583 - accuracy: 0.9050 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3596 - accuracy: 0.9087 - val_loss: 0.5976 - val_accuracy: 0.8050\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3235 - accuracy: 0.9262 - val_loss: 0.5912 - val_accuracy: 0.8100\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3554 - accuracy: 0.9050 - val_loss: 0.5923 - val_accuracy: 0.8100\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3242 - accuracy: 0.9175 - val_loss: 0.5924 - val_accuracy: 0.8050\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5924 - accuracy: 0.8050\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 8s 162ms/step - loss: 0.2854 - accuracy: 0.9112 - val_loss: 0.5785 - val_accuracy: 0.7900\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.2477 - accuracy: 0.9200 - val_loss: 0.5819 - val_accuracy: 0.8200\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1829 - accuracy: 0.9450 - val_loss: 0.5863 - val_accuracy: 0.8100\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1457 - accuracy: 0.9488 - val_loss: 0.5950 - val_accuracy: 0.8250\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1479 - accuracy: 0.9500 - val_loss: 0.5930 - val_accuracy: 0.8100\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1231 - accuracy: 0.9638 - val_loss: 0.6071 - val_accuracy: 0.8200\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0774 - accuracy: 0.9800 - val_loss: 0.6521 - val_accuracy: 0.8100\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0798 - accuracy: 0.9737 - val_loss: 0.6189 - val_accuracy: 0.8100\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0509 - accuracy: 0.9825 - val_loss: 0.7021 - val_accuracy: 0.8200\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0714 - accuracy: 0.9762 - val_loss: 0.6662 - val_accuracy: 0.8250\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0403 - accuracy: 0.9900 - val_loss: 0.6814 - val_accuracy: 0.8050\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.8146 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0360 - accuracy: 0.9825 - val_loss: 0.7560 - val_accuracy: 0.8150\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.0435 - accuracy: 0.9825 - val_loss: 0.7554 - val_accuracy: 0.8200\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.7186 - val_accuracy: 0.8300\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.7629 - val_accuracy: 0.8350\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.0322 - accuracy: 0.9850 - val_loss: 0.8403 - val_accuracy: 0.8300\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.8215 - val_accuracy: 0.8100\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.7709 - val_accuracy: 0.8400\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.7897 - val_accuracy: 0.8300\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.7958 - val_accuracy: 0.8250\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 2.7296 - accuracy: 0.1200\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 2.6703 - accuracy: 0.1275 - val_loss: 2.4350 - val_accuracy: 0.1600\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 2.3274 - accuracy: 0.1950 - val_loss: 2.1869 - val_accuracy: 0.2200\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.0697 - accuracy: 0.2725 - val_loss: 1.9596 - val_accuracy: 0.3100\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.8552 - accuracy: 0.3388 - val_loss: 1.7683 - val_accuracy: 0.3650\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.6631 - accuracy: 0.4475 - val_loss: 1.6105 - val_accuracy: 0.4450\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.5465 - accuracy: 0.4988 - val_loss: 1.4817 - val_accuracy: 0.5200\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.4222 - accuracy: 0.5312 - val_loss: 1.3666 - val_accuracy: 0.5800\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.3189 - accuracy: 0.5938 - val_loss: 1.2794 - val_accuracy: 0.6100\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.2013 - accuracy: 0.6350 - val_loss: 1.1988 - val_accuracy: 0.6300\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.1217 - accuracy: 0.6637 - val_loss: 1.1315 - val_accuracy: 0.6750\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.0398 - accuracy: 0.7000 - val_loss: 1.0693 - val_accuracy: 0.6800\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.9888 - accuracy: 0.7000 - val_loss: 1.0233 - val_accuracy: 0.7000\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.9266 - accuracy: 0.7362 - val_loss: 0.9809 - val_accuracy: 0.6900\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.8893 - accuracy: 0.7538 - val_loss: 0.9406 - val_accuracy: 0.7250\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.8878 - accuracy: 0.7500 - val_loss: 0.9028 - val_accuracy: 0.7300\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8362 - accuracy: 0.7500 - val_loss: 0.8686 - val_accuracy: 0.7300\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7866 - accuracy: 0.7900 - val_loss: 0.8425 - val_accuracy: 0.7400\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7469 - accuracy: 0.7925 - val_loss: 0.8271 - val_accuracy: 0.7450\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7305 - accuracy: 0.7975 - val_loss: 0.7996 - val_accuracy: 0.7550\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7257 - accuracy: 0.7925 - val_loss: 0.7790 - val_accuracy: 0.7600\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6597 - accuracy: 0.8025 - val_loss: 0.7708 - val_accuracy: 0.7700\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6636 - accuracy: 0.8062 - val_loss: 0.7537 - val_accuracy: 0.7750\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6350 - accuracy: 0.8100 - val_loss: 0.7387 - val_accuracy: 0.7700\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5983 - accuracy: 0.8300 - val_loss: 0.7239 - val_accuracy: 0.7800\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5831 - accuracy: 0.8462 - val_loss: 0.7180 - val_accuracy: 0.7900\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5809 - accuracy: 0.8400 - val_loss: 0.7034 - val_accuracy: 0.7850\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5570 - accuracy: 0.8462 - val_loss: 0.6948 - val_accuracy: 0.7850\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5285 - accuracy: 0.8550 - val_loss: 0.6857 - val_accuracy: 0.7900\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5491 - accuracy: 0.8425 - val_loss: 0.6742 - val_accuracy: 0.7950\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5261 - accuracy: 0.8462 - val_loss: 0.6639 - val_accuracy: 0.7900\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5141 - accuracy: 0.8500 - val_loss: 0.6529 - val_accuracy: 0.8000\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5099 - accuracy: 0.8500 - val_loss: 0.6490 - val_accuracy: 0.7950\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4838 - accuracy: 0.8700 - val_loss: 0.6463 - val_accuracy: 0.8000\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4623 - accuracy: 0.8788 - val_loss: 0.6419 - val_accuracy: 0.8050\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.4525 - accuracy: 0.8813 - val_loss: 0.6298 - val_accuracy: 0.7950\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.4325 - accuracy: 0.8763 - val_loss: 0.6262 - val_accuracy: 0.8050\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.4469 - accuracy: 0.8788 - val_loss: 0.6309 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4448 - accuracy: 0.8788 - val_loss: 0.6200 - val_accuracy: 0.8050\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4256 - accuracy: 0.8938 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.4255 - accuracy: 0.8825 - val_loss: 0.6081 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3988 - accuracy: 0.9013 - val_loss: 0.6070 - val_accuracy: 0.8000\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4119 - accuracy: 0.8875 - val_loss: 0.6053 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3901 - accuracy: 0.8963 - val_loss: 0.5967 - val_accuracy: 0.8200\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.3698 - accuracy: 0.9000 - val_loss: 0.5943 - val_accuracy: 0.8100\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3832 - accuracy: 0.8938 - val_loss: 0.5917 - val_accuracy: 0.8150\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3935 - accuracy: 0.8913 - val_loss: 0.5916 - val_accuracy: 0.8150\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3553 - accuracy: 0.9050 - val_loss: 0.5871 - val_accuracy: 0.8250\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3585 - accuracy: 0.9038 - val_loss: 0.5807 - val_accuracy: 0.8250\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3466 - accuracy: 0.9025 - val_loss: 0.5815 - val_accuracy: 0.8150\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3440 - accuracy: 0.9237 - val_loss: 0.5740 - val_accuracy: 0.8250\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5740 - accuracy: 0.8250\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 0.3109 - accuracy: 0.8975 - val_loss: 0.5788 - val_accuracy: 0.8000\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.2319 - accuracy: 0.9212 - val_loss: 0.5381 - val_accuracy: 0.8250\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.2015 - accuracy: 0.9362 - val_loss: 0.5643 - val_accuracy: 0.8200\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1439 - accuracy: 0.9563 - val_loss: 0.6128 - val_accuracy: 0.8250\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1302 - accuracy: 0.9550 - val_loss: 0.6360 - val_accuracy: 0.8050\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0819 - accuracy: 0.9725 - val_loss: 0.5843 - val_accuracy: 0.8350\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1075 - accuracy: 0.9737 - val_loss: 0.6545 - val_accuracy: 0.7850\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.1024 - accuracy: 0.9675 - val_loss: 0.6115 - val_accuracy: 0.8100\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0687 - accuracy: 0.9812 - val_loss: 0.6302 - val_accuracy: 0.8200\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0577 - accuracy: 0.9850 - val_loss: 0.7361 - val_accuracy: 0.8050\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0424 - accuracy: 0.9887 - val_loss: 0.6634 - val_accuracy: 0.8150\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0357 - accuracy: 0.9875 - val_loss: 0.7210 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.7411 - val_accuracy: 0.8300\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 0.8825 - val_accuracy: 0.8050\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0251 - accuracy: 0.9937 - val_loss: 0.8798 - val_accuracy: 0.7900\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.8346 - val_accuracy: 0.8100\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0279 - accuracy: 0.9937 - val_loss: 0.7922 - val_accuracy: 0.8250\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.7455 - val_accuracy: 0.8350\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.8823 - val_accuracy: 0.8100\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.8358 - val_accuracy: 0.8400\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.8711 - val_accuracy: 0.8350\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 2.5871 - accuracy: 0.1250\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 2.5132 - accuracy: 0.1350 - val_loss: 2.2700 - val_accuracy: 0.1800\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 2.1679 - accuracy: 0.2300 - val_loss: 2.0282 - val_accuracy: 0.2900\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.9367 - accuracy: 0.3212 - val_loss: 1.8224 - val_accuracy: 0.3550\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.7357 - accuracy: 0.3900 - val_loss: 1.6507 - val_accuracy: 0.4550\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.6230 - accuracy: 0.4425 - val_loss: 1.5055 - val_accuracy: 0.5350\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.4244 - accuracy: 0.5612 - val_loss: 1.3768 - val_accuracy: 0.5700\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.3093 - accuracy: 0.5888 - val_loss: 1.2796 - val_accuracy: 0.6250\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.2179 - accuracy: 0.6237 - val_loss: 1.1949 - val_accuracy: 0.6600\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.1405 - accuracy: 0.6662 - val_loss: 1.1257 - val_accuracy: 0.6700\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 1.0849 - accuracy: 0.6612 - val_loss: 1.0626 - val_accuracy: 0.6900\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.9998 - accuracy: 0.6900 - val_loss: 1.0113 - val_accuracy: 0.7050\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.9351 - accuracy: 0.7225 - val_loss: 0.9635 - val_accuracy: 0.7350\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8870 - accuracy: 0.7400 - val_loss: 0.9262 - val_accuracy: 0.7400\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8625 - accuracy: 0.7663 - val_loss: 0.8883 - val_accuracy: 0.7400\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8220 - accuracy: 0.7700 - val_loss: 0.8551 - val_accuracy: 0.7550\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7977 - accuracy: 0.7887 - val_loss: 0.8283 - val_accuracy: 0.7650\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7883 - accuracy: 0.7575 - val_loss: 0.8019 - val_accuracy: 0.7700\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7169 - accuracy: 0.7937 - val_loss: 0.7836 - val_accuracy: 0.7700\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6917 - accuracy: 0.8112 - val_loss: 0.7596 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6602 - accuracy: 0.8275 - val_loss: 0.7390 - val_accuracy: 0.7850\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6717 - accuracy: 0.8175 - val_loss: 0.7191 - val_accuracy: 0.7850\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6304 - accuracy: 0.8275 - val_loss: 0.7084 - val_accuracy: 0.7950\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6091 - accuracy: 0.8225 - val_loss: 0.6905 - val_accuracy: 0.7950\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5772 - accuracy: 0.8475 - val_loss: 0.6813 - val_accuracy: 0.7950\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5903 - accuracy: 0.8300 - val_loss: 0.6670 - val_accuracy: 0.7950\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5883 - accuracy: 0.8413 - val_loss: 0.6549 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5557 - accuracy: 0.8562 - val_loss: 0.6467 - val_accuracy: 0.7950\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5481 - accuracy: 0.8438 - val_loss: 0.6359 - val_accuracy: 0.7900\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5282 - accuracy: 0.8462 - val_loss: 0.6249 - val_accuracy: 0.7950\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5092 - accuracy: 0.8612 - val_loss: 0.6150 - val_accuracy: 0.8150\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5019 - accuracy: 0.8625 - val_loss: 0.6055 - val_accuracy: 0.8000\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4803 - accuracy: 0.8725 - val_loss: 0.6001 - val_accuracy: 0.8150\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4779 - accuracy: 0.8650 - val_loss: 0.5955 - val_accuracy: 0.8200\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4894 - accuracy: 0.8625 - val_loss: 0.5869 - val_accuracy: 0.8150\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4500 - accuracy: 0.8800 - val_loss: 0.5817 - val_accuracy: 0.8150\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4480 - accuracy: 0.8875 - val_loss: 0.5755 - val_accuracy: 0.8200\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4534 - accuracy: 0.8712 - val_loss: 0.5666 - val_accuracy: 0.8150\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4252 - accuracy: 0.8913 - val_loss: 0.5598 - val_accuracy: 0.8250\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4172 - accuracy: 0.8925 - val_loss: 0.5560 - val_accuracy: 0.8100\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4223 - accuracy: 0.8712 - val_loss: 0.5551 - val_accuracy: 0.8300\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3984 - accuracy: 0.8963 - val_loss: 0.5498 - val_accuracy: 0.8200\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3978 - accuracy: 0.8888 - val_loss: 0.5444 - val_accuracy: 0.8250\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3756 - accuracy: 0.9000 - val_loss: 0.5430 - val_accuracy: 0.8150\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3797 - accuracy: 0.9075 - val_loss: 0.5393 - val_accuracy: 0.8250\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3941 - accuracy: 0.8888 - val_loss: 0.5346 - val_accuracy: 0.8250\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3695 - accuracy: 0.9087 - val_loss: 0.5294 - val_accuracy: 0.8200\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3442 - accuracy: 0.9087 - val_loss: 0.5263 - val_accuracy: 0.8200\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3290 - accuracy: 0.9112 - val_loss: 0.5241 - val_accuracy: 0.8200\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3488 - accuracy: 0.9025 - val_loss: 0.5185 - val_accuracy: 0.8150\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3506 - accuracy: 0.9038 - val_loss: 0.5192 - val_accuracy: 0.8200\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5192 - accuracy: 0.8200\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.2973 - accuracy: 0.9025 - val_loss: 0.4646 - val_accuracy: 0.8550\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.2312 - accuracy: 0.9287 - val_loss: 0.4650 - val_accuracy: 0.8400\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.2126 - accuracy: 0.9312 - val_loss: 0.4642 - val_accuracy: 0.8500\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1628 - accuracy: 0.9550 - val_loss: 0.4670 - val_accuracy: 0.8400\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1269 - accuracy: 0.9575 - val_loss: 0.5033 - val_accuracy: 0.8500\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1054 - accuracy: 0.9613 - val_loss: 0.5130 - val_accuracy: 0.8300\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0842 - accuracy: 0.9775 - val_loss: 0.5372 - val_accuracy: 0.8400\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0744 - accuracy: 0.9762 - val_loss: 0.5096 - val_accuracy: 0.8350\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0688 - accuracy: 0.9775 - val_loss: 0.5139 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.5283 - val_accuracy: 0.8450\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.5404 - val_accuracy: 0.8500\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.5708 - val_accuracy: 0.8450\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0498 - accuracy: 0.9825 - val_loss: 0.5579 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0395 - accuracy: 0.9850 - val_loss: 0.5808 - val_accuracy: 0.8450\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 0.6136 - val_accuracy: 0.8600\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.5374 - val_accuracy: 0.8500\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 8s 150ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.6570 - val_accuracy: 0.8350\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.6518 - val_accuracy: 0.8100\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.6174 - val_accuracy: 0.8300\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.6390 - val_accuracy: 0.8350\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.6284 - val_accuracy: 0.8350\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 2.6390 - accuracy: 0.0900\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.6000 - accuracy: 0.1200 - val_loss: 2.3309 - val_accuracy: 0.1600\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 2.2762 - accuracy: 0.2000 - val_loss: 2.0686 - val_accuracy: 0.2400\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.0099 - accuracy: 0.2988 - val_loss: 1.8567 - val_accuracy: 0.3250\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.7732 - accuracy: 0.4075 - val_loss: 1.6869 - val_accuracy: 0.4300\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.6121 - accuracy: 0.4663 - val_loss: 1.5349 - val_accuracy: 0.4950\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.5025 - accuracy: 0.5050 - val_loss: 1.4165 - val_accuracy: 0.5400\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.3763 - accuracy: 0.5763 - val_loss: 1.3030 - val_accuracy: 0.5900\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.2629 - accuracy: 0.6125 - val_loss: 1.2164 - val_accuracy: 0.6400\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.1732 - accuracy: 0.6388 - val_loss: 1.1445 - val_accuracy: 0.6550\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0985 - accuracy: 0.6725 - val_loss: 1.0850 - val_accuracy: 0.6650\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0160 - accuracy: 0.6925 - val_loss: 1.0301 - val_accuracy: 0.7100\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.9586 - accuracy: 0.7050 - val_loss: 0.9831 - val_accuracy: 0.7150\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.9063 - accuracy: 0.7350 - val_loss: 0.9435 - val_accuracy: 0.7250\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8898 - accuracy: 0.7412 - val_loss: 0.9103 - val_accuracy: 0.7400\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8211 - accuracy: 0.7462 - val_loss: 0.8747 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.8086 - accuracy: 0.7675 - val_loss: 0.8477 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.7440 - accuracy: 0.7987 - val_loss: 0.8268 - val_accuracy: 0.7450\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7403 - accuracy: 0.7750 - val_loss: 0.8083 - val_accuracy: 0.7400\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.7109 - accuracy: 0.8000 - val_loss: 0.7846 - val_accuracy: 0.7550\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6939 - accuracy: 0.8025 - val_loss: 0.7717 - val_accuracy: 0.7700\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6417 - accuracy: 0.8112 - val_loss: 0.7545 - val_accuracy: 0.7700\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6678 - accuracy: 0.8188 - val_loss: 0.7391 - val_accuracy: 0.7750\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6191 - accuracy: 0.8263 - val_loss: 0.7243 - val_accuracy: 0.7800\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5891 - accuracy: 0.8263 - val_loss: 0.7162 - val_accuracy: 0.7750\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5684 - accuracy: 0.8512 - val_loss: 0.7088 - val_accuracy: 0.7850\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5483 - accuracy: 0.8575 - val_loss: 0.6957 - val_accuracy: 0.7950\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5449 - accuracy: 0.8487 - val_loss: 0.6857 - val_accuracy: 0.7950\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5489 - accuracy: 0.8562 - val_loss: 0.6764 - val_accuracy: 0.7950\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5306 - accuracy: 0.8537 - val_loss: 0.6657 - val_accuracy: 0.7950\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5112 - accuracy: 0.8575 - val_loss: 0.6627 - val_accuracy: 0.7950\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4875 - accuracy: 0.8612 - val_loss: 0.6590 - val_accuracy: 0.8000\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4776 - accuracy: 0.8587 - val_loss: 0.6552 - val_accuracy: 0.8000\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4702 - accuracy: 0.8662 - val_loss: 0.6461 - val_accuracy: 0.8000\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4683 - accuracy: 0.8600 - val_loss: 0.6431 - val_accuracy: 0.7900\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4574 - accuracy: 0.8800 - val_loss: 0.6342 - val_accuracy: 0.8050\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4414 - accuracy: 0.8825 - val_loss: 0.6352 - val_accuracy: 0.8100\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4380 - accuracy: 0.8737 - val_loss: 0.6303 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4294 - accuracy: 0.8825 - val_loss: 0.6218 - val_accuracy: 0.8100\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3990 - accuracy: 0.8950 - val_loss: 0.6175 - val_accuracy: 0.8100\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4041 - accuracy: 0.8950 - val_loss: 0.6178 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4013 - accuracy: 0.8763 - val_loss: 0.6127 - val_accuracy: 0.8150\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3919 - accuracy: 0.9050 - val_loss: 0.6066 - val_accuracy: 0.8200\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3715 - accuracy: 0.9075 - val_loss: 0.6110 - val_accuracy: 0.8150\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3755 - accuracy: 0.9087 - val_loss: 0.6053 - val_accuracy: 0.8150\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3722 - accuracy: 0.9062 - val_loss: 0.6053 - val_accuracy: 0.8100\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3676 - accuracy: 0.9087 - val_loss: 0.5997 - val_accuracy: 0.8150\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3601 - accuracy: 0.9075 - val_loss: 0.5985 - val_accuracy: 0.8050\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3648 - accuracy: 0.8950 - val_loss: 0.5922 - val_accuracy: 0.8200\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3468 - accuracy: 0.8975 - val_loss: 0.5963 - val_accuracy: 0.8150\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.3149 - accuracy: 0.9150 - val_loss: 0.5915 - val_accuracy: 0.8250\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5915 - accuracy: 0.8250\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 0.2769 - accuracy: 0.9075 - val_loss: 0.5763 - val_accuracy: 0.8150\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.2281 - accuracy: 0.9162 - val_loss: 0.5647 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1576 - accuracy: 0.9425 - val_loss: 0.6088 - val_accuracy: 0.8400\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1744 - accuracy: 0.9350 - val_loss: 0.5785 - val_accuracy: 0.8600\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1342 - accuracy: 0.9575 - val_loss: 0.6121 - val_accuracy: 0.8450\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1070 - accuracy: 0.9650 - val_loss: 0.5979 - val_accuracy: 0.8450\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0810 - accuracy: 0.9825 - val_loss: 0.6300 - val_accuracy: 0.8600\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0686 - accuracy: 0.9787 - val_loss: 0.7786 - val_accuracy: 0.8300\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0675 - accuracy: 0.9725 - val_loss: 0.8088 - val_accuracy: 0.8100\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0547 - accuracy: 0.9837 - val_loss: 0.8792 - val_accuracy: 0.7900\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0369 - accuracy: 0.9900 - val_loss: 0.7649 - val_accuracy: 0.8300\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0385 - accuracy: 0.9850 - val_loss: 0.8015 - val_accuracy: 0.8550\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0328 - accuracy: 0.9937 - val_loss: 0.8498 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.8355 - val_accuracy: 0.8600\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0268 - accuracy: 0.9875 - val_loss: 0.8894 - val_accuracy: 0.8550\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.9067 - val_accuracy: 0.8450\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.0257 - accuracy: 0.9937 - val_loss: 0.9041 - val_accuracy: 0.8450\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.9336 - val_accuracy: 0.8550\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.8301 - val_accuracy: 0.8450\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.9666 - val_accuracy: 0.8250\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.9888 - val_accuracy: 0.8400\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 2.7179 - accuracy: 0.1150\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.5261 - accuracy: 0.1488 - val_loss: 2.3015 - val_accuracy: 0.1900\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.2044 - accuracy: 0.2062 - val_loss: 2.0390 - val_accuracy: 0.2800\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.9276 - accuracy: 0.3413 - val_loss: 1.8298 - val_accuracy: 0.3500\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.7705 - accuracy: 0.4050 - val_loss: 1.6593 - val_accuracy: 0.4500\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.5849 - accuracy: 0.4950 - val_loss: 1.5133 - val_accuracy: 0.4950\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.4274 - accuracy: 0.5412 - val_loss: 1.3978 - val_accuracy: 0.5550\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.3316 - accuracy: 0.5800 - val_loss: 1.3014 - val_accuracy: 0.5700\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.2124 - accuracy: 0.6300 - val_loss: 1.2191 - val_accuracy: 0.5900\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.1334 - accuracy: 0.6700 - val_loss: 1.1553 - val_accuracy: 0.6050\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0751 - accuracy: 0.6938 - val_loss: 1.0931 - val_accuracy: 0.6200\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0091 - accuracy: 0.7063 - val_loss: 1.0378 - val_accuracy: 0.6350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.9824 - accuracy: 0.7237 - val_loss: 0.9936 - val_accuracy: 0.6550\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8951 - accuracy: 0.7462 - val_loss: 0.9572 - val_accuracy: 0.6650\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.8601 - accuracy: 0.7600 - val_loss: 0.9220 - val_accuracy: 0.6900\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7921 - accuracy: 0.7788 - val_loss: 0.8936 - val_accuracy: 0.6950\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7816 - accuracy: 0.7862 - val_loss: 0.8692 - val_accuracy: 0.7050\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7736 - accuracy: 0.7775 - val_loss: 0.8442 - val_accuracy: 0.7000\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7222 - accuracy: 0.8075 - val_loss: 0.8217 - val_accuracy: 0.7150\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6744 - accuracy: 0.8313 - val_loss: 0.7977 - val_accuracy: 0.7300\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6692 - accuracy: 0.8238 - val_loss: 0.7759 - val_accuracy: 0.7350\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6302 - accuracy: 0.8313 - val_loss: 0.7625 - val_accuracy: 0.7350\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6426 - accuracy: 0.8163 - val_loss: 0.7506 - val_accuracy: 0.7450\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6204 - accuracy: 0.8263 - val_loss: 0.7325 - val_accuracy: 0.7500\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5803 - accuracy: 0.8562 - val_loss: 0.7264 - val_accuracy: 0.7500\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5757 - accuracy: 0.8425 - val_loss: 0.7091 - val_accuracy: 0.7650\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5817 - accuracy: 0.8388 - val_loss: 0.6967 - val_accuracy: 0.7600\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5513 - accuracy: 0.8562 - val_loss: 0.6888 - val_accuracy: 0.7650\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5327 - accuracy: 0.8587 - val_loss: 0.6788 - val_accuracy: 0.7600\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5249 - accuracy: 0.8587 - val_loss: 0.6713 - val_accuracy: 0.7700\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5353 - accuracy: 0.8487 - val_loss: 0.6596 - val_accuracy: 0.7750\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4802 - accuracy: 0.8650 - val_loss: 0.6481 - val_accuracy: 0.7750\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4880 - accuracy: 0.8587 - val_loss: 0.6412 - val_accuracy: 0.7800\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4879 - accuracy: 0.8687 - val_loss: 0.6387 - val_accuracy: 0.7850\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4573 - accuracy: 0.8800 - val_loss: 0.6331 - val_accuracy: 0.7750\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4452 - accuracy: 0.8737 - val_loss: 0.6251 - val_accuracy: 0.7850\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4432 - accuracy: 0.8750 - val_loss: 0.6237 - val_accuracy: 0.7900\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4481 - accuracy: 0.8750 - val_loss: 0.6103 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4149 - accuracy: 0.8838 - val_loss: 0.6063 - val_accuracy: 0.8000\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4054 - accuracy: 0.8975 - val_loss: 0.6042 - val_accuracy: 0.7950\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4321 - accuracy: 0.8725 - val_loss: 0.5959 - val_accuracy: 0.8050\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4162 - accuracy: 0.8925 - val_loss: 0.5953 - val_accuracy: 0.8050\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4009 - accuracy: 0.8975 - val_loss: 0.5905 - val_accuracy: 0.8050\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4010 - accuracy: 0.8775 - val_loss: 0.5825 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3766 - accuracy: 0.9000 - val_loss: 0.5779 - val_accuracy: 0.8050\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3806 - accuracy: 0.9025 - val_loss: 0.5740 - val_accuracy: 0.8050\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3584 - accuracy: 0.9125 - val_loss: 0.5706 - val_accuracy: 0.8050\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3639 - accuracy: 0.9000 - val_loss: 0.5611 - val_accuracy: 0.8100\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3496 - accuracy: 0.9175 - val_loss: 0.5627 - val_accuracy: 0.8000\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3554 - accuracy: 0.9075 - val_loss: 0.5667 - val_accuracy: 0.8050\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3475 - accuracy: 0.9038 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5561 - accuracy: 0.8000\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.2952 - accuracy: 0.9087 - val_loss: 0.4905 - val_accuracy: 0.8050\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.2197 - accuracy: 0.9262 - val_loss: 0.5268 - val_accuracy: 0.8050\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1934 - accuracy: 0.9362 - val_loss: 0.5100 - val_accuracy: 0.8050\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1630 - accuracy: 0.9400 - val_loss: 0.5197 - val_accuracy: 0.8300\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1335 - accuracy: 0.9625 - val_loss: 0.5497 - val_accuracy: 0.8200\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.0993 - accuracy: 0.9700 - val_loss: 0.5599 - val_accuracy: 0.8150\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0860 - accuracy: 0.9700 - val_loss: 0.5595 - val_accuracy: 0.8200\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0810 - accuracy: 0.9675 - val_loss: 0.6057 - val_accuracy: 0.8100\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0791 - accuracy: 0.9775 - val_loss: 0.6046 - val_accuracy: 0.8250\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0649 - accuracy: 0.9825 - val_loss: 0.5684 - val_accuracy: 0.8250\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 0.6430 - val_accuracy: 0.8300\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.6097 - val_accuracy: 0.8050\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 0.7026 - val_accuracy: 0.8250\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.6736 - val_accuracy: 0.8200\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0448 - accuracy: 0.9800 - val_loss: 0.6659 - val_accuracy: 0.8200\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.6511 - val_accuracy: 0.8200\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.6848 - val_accuracy: 0.8300\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.0268 - accuracy: 0.9950 - val_loss: 0.6421 - val_accuracy: 0.8250\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.7203 - val_accuracy: 0.8200\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 0.7044 - val_accuracy: 0.8250\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.7431 - val_accuracy: 0.8300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "outputId": "b4017007-e799-43af-e6ff-8cc555f41c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.11099999994039536\n",
            "Accuracy before fine-tuning: 0.8149999976158142\n",
            "Final accuracy: 0.8459999918937683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "outputId": "f9174ff3-f70c-4306-8d4f-e52de5f36997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "outputId": "bd2ad80e-92ec-48de-f790-108db70003a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}