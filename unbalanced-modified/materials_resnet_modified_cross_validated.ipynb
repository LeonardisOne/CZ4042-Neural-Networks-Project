{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-resnet-modified-cross-validated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6EqK85yFFL7U0/p3CIWIJ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71605210-03b6-4b4f-ef6e-9611e49d3b2a"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47938ae-4209-48dd-98d3-ccc329afdbf2"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b0df85-c38c-404b-e3b9-6c3d3ea71e50"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724f388a-430d-46de-ef36-7c8209b1c43a"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVOP5fIPwEx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300ecb84-4283-4b3f-fdc6-30ccf15cff79"
      },
      "source": [
        "# get pre-trained model\n",
        "base_model = keras.applications.ResNet50V2(include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2kAceGVW0e"
      },
      "source": [
        "# don't train base model weights\n",
        "base_model.trainable = False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGkReMX60ScJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85037e5-f333-47b5-fc41-8dfed69a02cd"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 305, 305, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 150, 150, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 152, 152, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 75, 75, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 75, 75, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 75, 75, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 75, 75, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 75, 75, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 75, 75, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 75, 75, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 75, 75, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 75, 75, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 75, 75, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 75, 75, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 75, 75, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 75, 75, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 75, 75, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 75, 75, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 75, 75, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 75, 75, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 75, 75, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 75, 75, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 38, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 38, 38, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 38, 38, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 38, 38, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 38, 38, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 38, 38, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 38, 38, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 38, 38, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 38, 38, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 38, 38, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 38, 38, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 38, 38, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 38, 38, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 38, 38, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 38, 38, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 38, 38, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 19, 19, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 19, 19, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 19, 19, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 19, 19, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 19, 19, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 19, 19, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 19, 19, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 19, 19, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 19, 19, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 19, 19, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 19, 19, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 19, 19, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 19, 19, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 19, 19, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 19, 19, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 19, 19, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 19, 19, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 19, 19, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 19, 19, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 19, 19, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 19, 19, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 10, 10, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 1024) 0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 10, 10, 1024) 0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 10, 10, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 10, 10, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 10, 10, 512)  0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 10, 10, 512)  0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 10, 10, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 10, 10, 2048) 0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 10, 10, 2048) 8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 10, 10, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 10, 10, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 10, 10, 512)  0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 10, 10, 512)  0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 10, 10, 2048) 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 10, 10, 2048) 8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 10, 10, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 10, 10, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 10, 10, 512)  0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 10, 10, 512)  0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 10, 10, 2048) 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 10, 10, 2048) 8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 10, 10, 2048) 0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model():\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 100"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bebb37-bdd5-4ac7-cdeb-978c7786e930"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model()\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy']))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 106ms/step - loss: 2.5718 - accuracy: 0.0900\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 111ms/step - loss: 2.4763 - accuracy: 0.1425 - val_loss: 1.9140 - val_accuracy: 0.3600\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 111ms/step - loss: 1.8768 - accuracy: 0.3638 - val_loss: 1.5422 - val_accuracy: 0.5450\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 112ms/step - loss: 1.5732 - accuracy: 0.4837 - val_loss: 1.2544 - val_accuracy: 0.6650\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 112ms/step - loss: 1.2719 - accuracy: 0.5875 - val_loss: 1.0396 - val_accuracy: 0.7250\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 112ms/step - loss: 1.1102 - accuracy: 0.6438 - val_loss: 0.9059 - val_accuracy: 0.7550\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 112ms/step - loss: 0.9778 - accuracy: 0.7188 - val_loss: 0.8183 - val_accuracy: 0.7650\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 113ms/step - loss: 0.8848 - accuracy: 0.7287 - val_loss: 0.7502 - val_accuracy: 0.7750\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 113ms/step - loss: 0.8166 - accuracy: 0.7550 - val_loss: 0.7064 - val_accuracy: 0.7950\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 114ms/step - loss: 0.7209 - accuracy: 0.7775 - val_loss: 0.6633 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 114ms/step - loss: 0.6687 - accuracy: 0.7862 - val_loss: 0.6370 - val_accuracy: 0.7950\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 114ms/step - loss: 0.6221 - accuracy: 0.8100 - val_loss: 0.6038 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 115ms/step - loss: 0.5698 - accuracy: 0.8188 - val_loss: 0.5990 - val_accuracy: 0.8050\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 115ms/step - loss: 0.5441 - accuracy: 0.8300 - val_loss: 0.5752 - val_accuracy: 0.8050\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.5316 - accuracy: 0.8400 - val_loss: 0.5664 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.5047 - accuracy: 0.8275 - val_loss: 0.5473 - val_accuracy: 0.8200\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 116ms/step - loss: 0.4671 - accuracy: 0.8550 - val_loss: 0.5393 - val_accuracy: 0.8200\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4509 - accuracy: 0.8512 - val_loss: 0.5371 - val_accuracy: 0.8200\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4349 - accuracy: 0.8600 - val_loss: 0.5349 - val_accuracy: 0.8400\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.4017 - accuracy: 0.8737 - val_loss: 0.5426 - val_accuracy: 0.8200\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4063 - accuracy: 0.8813 - val_loss: 0.5428 - val_accuracy: 0.8200\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3636 - accuracy: 0.8938 - val_loss: 0.5368 - val_accuracy: 0.8200\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3683 - accuracy: 0.8825 - val_loss: 0.5232 - val_accuracy: 0.8300\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3616 - accuracy: 0.8900 - val_loss: 0.5288 - val_accuracy: 0.8400\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3541 - accuracy: 0.8888 - val_loss: 0.5242 - val_accuracy: 0.8400\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2886 - accuracy: 0.9162 - val_loss: 0.5177 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2890 - accuracy: 0.9100 - val_loss: 0.5116 - val_accuracy: 0.8500\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2857 - accuracy: 0.9187 - val_loss: 0.5113 - val_accuracy: 0.8450\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2917 - accuracy: 0.9050 - val_loss: 0.5237 - val_accuracy: 0.8400\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2846 - accuracy: 0.9100 - val_loss: 0.5131 - val_accuracy: 0.8450\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2673 - accuracy: 0.9237 - val_loss: 0.5150 - val_accuracy: 0.8450\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2640 - accuracy: 0.9187 - val_loss: 0.5023 - val_accuracy: 0.8500\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2508 - accuracy: 0.9237 - val_loss: 0.5065 - val_accuracy: 0.8450\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2391 - accuracy: 0.9212 - val_loss: 0.5099 - val_accuracy: 0.8500\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2576 - accuracy: 0.9200 - val_loss: 0.5141 - val_accuracy: 0.8450\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2253 - accuracy: 0.9337 - val_loss: 0.5229 - val_accuracy: 0.8450\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2222 - accuracy: 0.9375 - val_loss: 0.5225 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1946 - accuracy: 0.9450 - val_loss: 0.5122 - val_accuracy: 0.8450\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1954 - accuracy: 0.9450 - val_loss: 0.5186 - val_accuracy: 0.8400\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1979 - accuracy: 0.9450 - val_loss: 0.5300 - val_accuracy: 0.8450\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1931 - accuracy: 0.9325 - val_loss: 0.5148 - val_accuracy: 0.8400\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2109 - accuracy: 0.9450 - val_loss: 0.5217 - val_accuracy: 0.8450\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1915 - accuracy: 0.9513 - val_loss: 0.5204 - val_accuracy: 0.8450\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1884 - accuracy: 0.9438 - val_loss: 0.5229 - val_accuracy: 0.8400\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1653 - accuracy: 0.9538 - val_loss: 0.5231 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1966 - accuracy: 0.9488 - val_loss: 0.5183 - val_accuracy: 0.8450\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2056 - accuracy: 0.9337 - val_loss: 0.5186 - val_accuracy: 0.8550\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1584 - accuracy: 0.9625 - val_loss: 0.5214 - val_accuracy: 0.8400\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1656 - accuracy: 0.9550 - val_loss: 0.5200 - val_accuracy: 0.8450\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1530 - accuracy: 0.9625 - val_loss: 0.5241 - val_accuracy: 0.8450\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1523 - accuracy: 0.9550 - val_loss: 0.5369 - val_accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1607 - accuracy: 0.9575 - val_loss: 0.5363 - val_accuracy: 0.8400\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1529 - accuracy: 0.9563 - val_loss: 0.5340 - val_accuracy: 0.8300\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1302 - accuracy: 0.9638 - val_loss: 0.5293 - val_accuracy: 0.8300\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1344 - accuracy: 0.9663 - val_loss: 0.5366 - val_accuracy: 0.8350\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1304 - accuracy: 0.9625 - val_loss: 0.5312 - val_accuracy: 0.8250\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1380 - accuracy: 0.9613 - val_loss: 0.5320 - val_accuracy: 0.8300\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1259 - accuracy: 0.9625 - val_loss: 0.5560 - val_accuracy: 0.8200\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1223 - accuracy: 0.9650 - val_loss: 0.5317 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1297 - accuracy: 0.9650 - val_loss: 0.5546 - val_accuracy: 0.8350\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1577 - accuracy: 0.9488 - val_loss: 0.5382 - val_accuracy: 0.8250\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1226 - accuracy: 0.9675 - val_loss: 0.5509 - val_accuracy: 0.8300\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1144 - accuracy: 0.9675 - val_loss: 0.5393 - val_accuracy: 0.8350\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1355 - accuracy: 0.9550 - val_loss: 0.5402 - val_accuracy: 0.8400\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1215 - accuracy: 0.9688 - val_loss: 0.5596 - val_accuracy: 0.8250\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1004 - accuracy: 0.9750 - val_loss: 0.5554 - val_accuracy: 0.8350\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1094 - accuracy: 0.9700 - val_loss: 0.5498 - val_accuracy: 0.8250\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1040 - accuracy: 0.9725 - val_loss: 0.5442 - val_accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1002 - accuracy: 0.9737 - val_loss: 0.5601 - val_accuracy: 0.8350\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1086 - accuracy: 0.9700 - val_loss: 0.5653 - val_accuracy: 0.8250\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.1108 - accuracy: 0.9700 - val_loss: 0.5658 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1143 - accuracy: 0.9650 - val_loss: 0.5499 - val_accuracy: 0.8400\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0898 - accuracy: 0.9762 - val_loss: 0.5568 - val_accuracy: 0.8400\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1071 - accuracy: 0.9725 - val_loss: 0.5494 - val_accuracy: 0.8300\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1095 - accuracy: 0.9688 - val_loss: 0.5337 - val_accuracy: 0.8300\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1018 - accuracy: 0.9737 - val_loss: 0.5443 - val_accuracy: 0.8350\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0993 - accuracy: 0.9700 - val_loss: 0.5419 - val_accuracy: 0.8250\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0829 - accuracy: 0.9800 - val_loss: 0.5658 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0973 - accuracy: 0.9675 - val_loss: 0.5480 - val_accuracy: 0.8300\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0883 - accuracy: 0.9737 - val_loss: 0.5538 - val_accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0825 - accuracy: 0.9725 - val_loss: 0.5534 - val_accuracy: 0.8300\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0745 - accuracy: 0.9850 - val_loss: 0.5675 - val_accuracy: 0.8300\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0964 - accuracy: 0.9663 - val_loss: 0.5537 - val_accuracy: 0.8400\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0947 - accuracy: 0.9800 - val_loss: 0.5820 - val_accuracy: 0.8350\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0857 - accuracy: 0.9762 - val_loss: 0.5542 - val_accuracy: 0.8300\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0994 - accuracy: 0.9775 - val_loss: 0.5695 - val_accuracy: 0.8350\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0717 - accuracy: 0.9850 - val_loss: 0.5665 - val_accuracy: 0.8400\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0845 - accuracy: 0.9762 - val_loss: 0.5524 - val_accuracy: 0.8500\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0843 - accuracy: 0.9787 - val_loss: 0.5624 - val_accuracy: 0.8500\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0696 - accuracy: 0.9875 - val_loss: 0.5647 - val_accuracy: 0.8450\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.5704 - val_accuracy: 0.8400\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0696 - accuracy: 0.9837 - val_loss: 0.5824 - val_accuracy: 0.8350\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0602 - accuracy: 0.9900 - val_loss: 0.5856 - val_accuracy: 0.8400\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0795 - accuracy: 0.9712 - val_loss: 0.5708 - val_accuracy: 0.8300\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0612 - accuracy: 0.9900 - val_loss: 0.5915 - val_accuracy: 0.8300\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0662 - accuracy: 0.9825 - val_loss: 0.6085 - val_accuracy: 0.8300\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.0644 - accuracy: 0.9837 - val_loss: 0.6010 - val_accuracy: 0.8300\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0611 - accuracy: 0.9850 - val_loss: 0.5933 - val_accuracy: 0.8250\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0761 - accuracy: 0.9800 - val_loss: 0.5989 - val_accuracy: 0.8250\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0723 - accuracy: 0.9825 - val_loss: 0.5943 - val_accuracy: 0.8300\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.0676 - accuracy: 0.9862 - val_loss: 0.6028 - val_accuracy: 0.8250\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 2.5950 - accuracy: 0.1050\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.3940 - accuracy: 0.1575 - val_loss: 1.9462 - val_accuracy: 0.3400\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.8750 - accuracy: 0.3625 - val_loss: 1.5857 - val_accuracy: 0.5550\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.5774 - accuracy: 0.4712 - val_loss: 1.3237 - val_accuracy: 0.6350\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.3047 - accuracy: 0.5850 - val_loss: 1.0999 - val_accuracy: 0.6900\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0817 - accuracy: 0.6787 - val_loss: 0.9623 - val_accuracy: 0.7300\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.9830 - accuracy: 0.7038 - val_loss: 0.8486 - val_accuracy: 0.7400\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.8606 - accuracy: 0.7538 - val_loss: 0.7960 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7891 - accuracy: 0.7487 - val_loss: 0.7512 - val_accuracy: 0.7450\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7123 - accuracy: 0.7900 - val_loss: 0.7052 - val_accuracy: 0.7800\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.6481 - accuracy: 0.8050 - val_loss: 0.6792 - val_accuracy: 0.7750\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6007 - accuracy: 0.8150 - val_loss: 0.6599 - val_accuracy: 0.7750\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5802 - accuracy: 0.8188 - val_loss: 0.6366 - val_accuracy: 0.7900\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.5210 - accuracy: 0.8537 - val_loss: 0.6374 - val_accuracy: 0.7700\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4840 - accuracy: 0.8500 - val_loss: 0.6059 - val_accuracy: 0.8100\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5062 - accuracy: 0.8363 - val_loss: 0.5959 - val_accuracy: 0.8250\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4282 - accuracy: 0.8700 - val_loss: 0.5931 - val_accuracy: 0.8100\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4182 - accuracy: 0.8662 - val_loss: 0.5692 - val_accuracy: 0.8150\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4530 - accuracy: 0.8525 - val_loss: 0.5564 - val_accuracy: 0.8250\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3747 - accuracy: 0.8737 - val_loss: 0.5806 - val_accuracy: 0.7850\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.4020 - accuracy: 0.8725 - val_loss: 0.5414 - val_accuracy: 0.8350\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3719 - accuracy: 0.8850 - val_loss: 0.5586 - val_accuracy: 0.8150\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3609 - accuracy: 0.8825 - val_loss: 0.5495 - val_accuracy: 0.8150\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3313 - accuracy: 0.8938 - val_loss: 0.5388 - val_accuracy: 0.8200\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3197 - accuracy: 0.8950 - val_loss: 0.5387 - val_accuracy: 0.8250\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3029 - accuracy: 0.9162 - val_loss: 0.5397 - val_accuracy: 0.8250\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2982 - accuracy: 0.9162 - val_loss: 0.5196 - val_accuracy: 0.8550\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2788 - accuracy: 0.9137 - val_loss: 0.5293 - val_accuracy: 0.8550\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2751 - accuracy: 0.9100 - val_loss: 0.5260 - val_accuracy: 0.8400\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.3042 - accuracy: 0.9087 - val_loss: 0.5239 - val_accuracy: 0.8500\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2828 - accuracy: 0.9100 - val_loss: 0.5263 - val_accuracy: 0.8350\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2599 - accuracy: 0.9187 - val_loss: 0.5320 - val_accuracy: 0.8400\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2669 - accuracy: 0.9137 - val_loss: 0.5199 - val_accuracy: 0.8450\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2396 - accuracy: 0.9300 - val_loss: 0.5184 - val_accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2218 - accuracy: 0.9388 - val_loss: 0.5168 - val_accuracy: 0.8450\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2050 - accuracy: 0.9475 - val_loss: 0.5141 - val_accuracy: 0.8250\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2104 - accuracy: 0.9413 - val_loss: 0.5186 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2285 - accuracy: 0.9225 - val_loss: 0.5056 - val_accuracy: 0.8400\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2372 - accuracy: 0.9362 - val_loss: 0.5195 - val_accuracy: 0.8350\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2284 - accuracy: 0.9312 - val_loss: 0.4949 - val_accuracy: 0.8500\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2063 - accuracy: 0.9425 - val_loss: 0.5103 - val_accuracy: 0.8550\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2125 - accuracy: 0.9425 - val_loss: 0.5245 - val_accuracy: 0.8450\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1902 - accuracy: 0.9500 - val_loss: 0.5146 - val_accuracy: 0.8400\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1805 - accuracy: 0.9500 - val_loss: 0.5197 - val_accuracy: 0.8400\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1712 - accuracy: 0.9575 - val_loss: 0.5373 - val_accuracy: 0.8300\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1745 - accuracy: 0.9550 - val_loss: 0.5195 - val_accuracy: 0.8400\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1742 - accuracy: 0.9513 - val_loss: 0.5143 - val_accuracy: 0.8450\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1782 - accuracy: 0.9488 - val_loss: 0.5238 - val_accuracy: 0.8400\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1682 - accuracy: 0.9438 - val_loss: 0.5091 - val_accuracy: 0.8500\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1589 - accuracy: 0.9588 - val_loss: 0.4963 - val_accuracy: 0.8400\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1507 - accuracy: 0.9575 - val_loss: 0.5188 - val_accuracy: 0.8350\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1561 - accuracy: 0.9575 - val_loss: 0.5164 - val_accuracy: 0.8350\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1489 - accuracy: 0.9588 - val_loss: 0.5417 - val_accuracy: 0.8300\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1462 - accuracy: 0.9525 - val_loss: 0.5278 - val_accuracy: 0.8400\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1431 - accuracy: 0.9650 - val_loss: 0.5296 - val_accuracy: 0.8500\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1375 - accuracy: 0.9663 - val_loss: 0.5005 - val_accuracy: 0.8450\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1587 - accuracy: 0.9563 - val_loss: 0.5294 - val_accuracy: 0.8550\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1269 - accuracy: 0.9638 - val_loss: 0.5049 - val_accuracy: 0.8450\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1229 - accuracy: 0.9675 - val_loss: 0.4996 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1362 - accuracy: 0.9588 - val_loss: 0.5042 - val_accuracy: 0.8450\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1390 - accuracy: 0.9675 - val_loss: 0.5043 - val_accuracy: 0.8500\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1081 - accuracy: 0.9675 - val_loss: 0.5211 - val_accuracy: 0.8550\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1368 - accuracy: 0.9588 - val_loss: 0.5164 - val_accuracy: 0.8550\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1289 - accuracy: 0.9675 - val_loss: 0.5078 - val_accuracy: 0.8500\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1066 - accuracy: 0.9700 - val_loss: 0.5338 - val_accuracy: 0.8350\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1165 - accuracy: 0.9663 - val_loss: 0.5123 - val_accuracy: 0.8350\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1032 - accuracy: 0.9750 - val_loss: 0.5128 - val_accuracy: 0.8500\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1076 - accuracy: 0.9725 - val_loss: 0.5316 - val_accuracy: 0.8350\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1145 - accuracy: 0.9675 - val_loss: 0.5136 - val_accuracy: 0.8450\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1112 - accuracy: 0.9712 - val_loss: 0.5352 - val_accuracy: 0.8450\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1081 - accuracy: 0.9750 - val_loss: 0.5131 - val_accuracy: 0.8500\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0907 - accuracy: 0.9775 - val_loss: 0.5260 - val_accuracy: 0.8450\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1015 - accuracy: 0.9675 - val_loss: 0.5266 - val_accuracy: 0.8400\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0946 - accuracy: 0.9762 - val_loss: 0.5212 - val_accuracy: 0.8350\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1062 - accuracy: 0.9688 - val_loss: 0.5033 - val_accuracy: 0.8450\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1039 - accuracy: 0.9725 - val_loss: 0.5379 - val_accuracy: 0.8350\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0941 - accuracy: 0.9737 - val_loss: 0.5121 - val_accuracy: 0.8550\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0934 - accuracy: 0.9688 - val_loss: 0.5277 - val_accuracy: 0.8500\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0948 - accuracy: 0.9750 - val_loss: 0.5494 - val_accuracy: 0.8300\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0924 - accuracy: 0.9725 - val_loss: 0.5291 - val_accuracy: 0.8400\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0711 - accuracy: 0.9850 - val_loss: 0.5409 - val_accuracy: 0.8400\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0837 - accuracy: 0.9800 - val_loss: 0.5390 - val_accuracy: 0.8400\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0714 - accuracy: 0.9812 - val_loss: 0.5756 - val_accuracy: 0.8250\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0823 - accuracy: 0.9837 - val_loss: 0.5218 - val_accuracy: 0.8400\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0936 - accuracy: 0.9725 - val_loss: 0.5201 - val_accuracy: 0.8500\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0854 - accuracy: 0.9787 - val_loss: 0.5455 - val_accuracy: 0.8450\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.5153 - val_accuracy: 0.8500\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0867 - accuracy: 0.9775 - val_loss: 0.5347 - val_accuracy: 0.8500\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1006 - accuracy: 0.9675 - val_loss: 0.5510 - val_accuracy: 0.8300\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0804 - accuracy: 0.9837 - val_loss: 0.5318 - val_accuracy: 0.8400\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0927 - accuracy: 0.9663 - val_loss: 0.5402 - val_accuracy: 0.8400\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0683 - accuracy: 0.9850 - val_loss: 0.5344 - val_accuracy: 0.8500\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0690 - accuracy: 0.9837 - val_loss: 0.5290 - val_accuracy: 0.8550\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0691 - accuracy: 0.9800 - val_loss: 0.5304 - val_accuracy: 0.8600\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0795 - accuracy: 0.9812 - val_loss: 0.5097 - val_accuracy: 0.8450\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0590 - accuracy: 0.9900 - val_loss: 0.5277 - val_accuracy: 0.8550\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0682 - accuracy: 0.9812 - val_loss: 0.5537 - val_accuracy: 0.8500\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.0701 - accuracy: 0.9850 - val_loss: 0.5650 - val_accuracy: 0.8500\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0671 - accuracy: 0.9850 - val_loss: 0.5638 - val_accuracy: 0.8550\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0659 - accuracy: 0.9837 - val_loss: 0.5655 - val_accuracy: 0.8550\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0519 - accuracy: 0.9900 - val_loss: 0.5386 - val_accuracy: 0.8450\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 2.5384 - accuracy: 0.1000\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 2.4428 - accuracy: 0.1737 - val_loss: 1.9326 - val_accuracy: 0.3450\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.8415 - accuracy: 0.3625 - val_loss: 1.5467 - val_accuracy: 0.5450\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.5324 - accuracy: 0.5200 - val_loss: 1.2551 - val_accuracy: 0.6750\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.2749 - accuracy: 0.5875 - val_loss: 1.0410 - val_accuracy: 0.7250\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0761 - accuracy: 0.6762 - val_loss: 0.9009 - val_accuracy: 0.7500\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.9149 - accuracy: 0.7237 - val_loss: 0.8082 - val_accuracy: 0.7600\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.7927 - accuracy: 0.7525 - val_loss: 0.7253 - val_accuracy: 0.7700\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.7035 - accuracy: 0.7950 - val_loss: 0.6745 - val_accuracy: 0.8100\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6811 - accuracy: 0.7850 - val_loss: 0.6278 - val_accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6492 - accuracy: 0.7975 - val_loss: 0.6017 - val_accuracy: 0.8250\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.6344 - accuracy: 0.7962 - val_loss: 0.5772 - val_accuracy: 0.8300\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5903 - accuracy: 0.8125 - val_loss: 0.5633 - val_accuracy: 0.8300\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.5499 - accuracy: 0.8263 - val_loss: 0.5494 - val_accuracy: 0.8350\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4927 - accuracy: 0.8375 - val_loss: 0.5242 - val_accuracy: 0.8450\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4699 - accuracy: 0.8487 - val_loss: 0.5085 - val_accuracy: 0.8350\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4723 - accuracy: 0.8462 - val_loss: 0.4986 - val_accuracy: 0.8350\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4490 - accuracy: 0.8537 - val_loss: 0.4895 - val_accuracy: 0.8350\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4166 - accuracy: 0.8712 - val_loss: 0.4844 - val_accuracy: 0.8450\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4050 - accuracy: 0.8675 - val_loss: 0.4834 - val_accuracy: 0.8300\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3608 - accuracy: 0.8888 - val_loss: 0.4760 - val_accuracy: 0.8450\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3583 - accuracy: 0.8950 - val_loss: 0.4657 - val_accuracy: 0.8500\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3306 - accuracy: 0.8913 - val_loss: 0.4624 - val_accuracy: 0.8500\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3553 - accuracy: 0.8825 - val_loss: 0.4520 - val_accuracy: 0.8450\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2922 - accuracy: 0.9175 - val_loss: 0.4542 - val_accuracy: 0.8550\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3150 - accuracy: 0.9075 - val_loss: 0.4421 - val_accuracy: 0.8500\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2866 - accuracy: 0.9038 - val_loss: 0.4415 - val_accuracy: 0.8450\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3135 - accuracy: 0.8938 - val_loss: 0.4317 - val_accuracy: 0.8600\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2666 - accuracy: 0.9175 - val_loss: 0.4348 - val_accuracy: 0.8550\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2782 - accuracy: 0.9162 - val_loss: 0.4255 - val_accuracy: 0.8550\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2562 - accuracy: 0.9250 - val_loss: 0.4277 - val_accuracy: 0.8500\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2807 - accuracy: 0.9137 - val_loss: 0.4255 - val_accuracy: 0.8450\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2408 - accuracy: 0.9300 - val_loss: 0.4212 - val_accuracy: 0.8550\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2633 - accuracy: 0.9187 - val_loss: 0.4314 - val_accuracy: 0.8400\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2448 - accuracy: 0.9200 - val_loss: 0.4188 - val_accuracy: 0.8600\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2105 - accuracy: 0.9400 - val_loss: 0.4161 - val_accuracy: 0.8600\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2548 - accuracy: 0.9287 - val_loss: 0.4227 - val_accuracy: 0.8550\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2008 - accuracy: 0.9475 - val_loss: 0.4202 - val_accuracy: 0.8550\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1987 - accuracy: 0.9500 - val_loss: 0.4230 - val_accuracy: 0.8650\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.2214 - accuracy: 0.9287 - val_loss: 0.4192 - val_accuracy: 0.8550\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2135 - accuracy: 0.9413 - val_loss: 0.4207 - val_accuracy: 0.8500\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2139 - accuracy: 0.9375 - val_loss: 0.4161 - val_accuracy: 0.8550\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2136 - accuracy: 0.9438 - val_loss: 0.4075 - val_accuracy: 0.8600\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1925 - accuracy: 0.9463 - val_loss: 0.4142 - val_accuracy: 0.8700\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1584 - accuracy: 0.9563 - val_loss: 0.4242 - val_accuracy: 0.8650\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1722 - accuracy: 0.9525 - val_loss: 0.4096 - val_accuracy: 0.8700\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1590 - accuracy: 0.9575 - val_loss: 0.4174 - val_accuracy: 0.8500\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1741 - accuracy: 0.9463 - val_loss: 0.4116 - val_accuracy: 0.8550\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1548 - accuracy: 0.9613 - val_loss: 0.4089 - val_accuracy: 0.8600\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1538 - accuracy: 0.9588 - val_loss: 0.4178 - val_accuracy: 0.8600\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1670 - accuracy: 0.9550 - val_loss: 0.4189 - val_accuracy: 0.8550\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1562 - accuracy: 0.9525 - val_loss: 0.4207 - val_accuracy: 0.8600\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1498 - accuracy: 0.9563 - val_loss: 0.4236 - val_accuracy: 0.8600\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1708 - accuracy: 0.9500 - val_loss: 0.4305 - val_accuracy: 0.8550\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1287 - accuracy: 0.9625 - val_loss: 0.4287 - val_accuracy: 0.8650\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1379 - accuracy: 0.9638 - val_loss: 0.4220 - val_accuracy: 0.8600\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1407 - accuracy: 0.9588 - val_loss: 0.4112 - val_accuracy: 0.8700\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1298 - accuracy: 0.9588 - val_loss: 0.4173 - val_accuracy: 0.8700\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1221 - accuracy: 0.9675 - val_loss: 0.4186 - val_accuracy: 0.8700\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1525 - accuracy: 0.9550 - val_loss: 0.4195 - val_accuracy: 0.8650\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1080 - accuracy: 0.9725 - val_loss: 0.4245 - val_accuracy: 0.8650\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1164 - accuracy: 0.9700 - val_loss: 0.4313 - val_accuracy: 0.8550\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1007 - accuracy: 0.9775 - val_loss: 0.4125 - val_accuracy: 0.8650\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1308 - accuracy: 0.9550 - val_loss: 0.4134 - val_accuracy: 0.8700\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1199 - accuracy: 0.9675 - val_loss: 0.4180 - val_accuracy: 0.8600\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1244 - accuracy: 0.9663 - val_loss: 0.4183 - val_accuracy: 0.8600\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.4203 - val_accuracy: 0.8550\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1130 - accuracy: 0.9712 - val_loss: 0.4166 - val_accuracy: 0.8550\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1175 - accuracy: 0.9625 - val_loss: 0.4152 - val_accuracy: 0.8700\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1205 - accuracy: 0.9650 - val_loss: 0.4226 - val_accuracy: 0.8550\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0966 - accuracy: 0.9762 - val_loss: 0.4200 - val_accuracy: 0.8600\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 0.1219 - accuracy: 0.9675 - val_loss: 0.4127 - val_accuracy: 0.8600\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0936 - accuracy: 0.9787 - val_loss: 0.4231 - val_accuracy: 0.8550\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1189 - accuracy: 0.9613 - val_loss: 0.4152 - val_accuracy: 0.8450\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0806 - accuracy: 0.9875 - val_loss: 0.4122 - val_accuracy: 0.8600\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1119 - accuracy: 0.9725 - val_loss: 0.4113 - val_accuracy: 0.8500\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0927 - accuracy: 0.9750 - val_loss: 0.4168 - val_accuracy: 0.8550\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0934 - accuracy: 0.9762 - val_loss: 0.4344 - val_accuracy: 0.8600\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0834 - accuracy: 0.9850 - val_loss: 0.4251 - val_accuracy: 0.8500\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0994 - accuracy: 0.9700 - val_loss: 0.4303 - val_accuracy: 0.8600\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0903 - accuracy: 0.9775 - val_loss: 0.4216 - val_accuracy: 0.8500\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0831 - accuracy: 0.9737 - val_loss: 0.4202 - val_accuracy: 0.8600\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0804 - accuracy: 0.9787 - val_loss: 0.4318 - val_accuracy: 0.8600\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0793 - accuracy: 0.9837 - val_loss: 0.4275 - val_accuracy: 0.8500\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1010 - accuracy: 0.9712 - val_loss: 0.4289 - val_accuracy: 0.8550\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0881 - accuracy: 0.9800 - val_loss: 0.4270 - val_accuracy: 0.8500\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0771 - accuracy: 0.9812 - val_loss: 0.4329 - val_accuracy: 0.8550\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0752 - accuracy: 0.9787 - val_loss: 0.4288 - val_accuracy: 0.8500\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.4238 - val_accuracy: 0.8550\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0769 - accuracy: 0.9800 - val_loss: 0.4112 - val_accuracy: 0.8650\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0731 - accuracy: 0.9862 - val_loss: 0.4121 - val_accuracy: 0.8500\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0614 - accuracy: 0.9862 - val_loss: 0.4082 - val_accuracy: 0.8650\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0758 - accuracy: 0.9762 - val_loss: 0.4362 - val_accuracy: 0.8500\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0754 - accuracy: 0.9787 - val_loss: 0.4284 - val_accuracy: 0.8550\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0764 - accuracy: 0.9837 - val_loss: 0.4244 - val_accuracy: 0.8600\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0726 - accuracy: 0.9850 - val_loss: 0.4260 - val_accuracy: 0.8550\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0787 - accuracy: 0.9787 - val_loss: 0.4245 - val_accuracy: 0.8550\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0807 - accuracy: 0.9750 - val_loss: 0.4361 - val_accuracy: 0.8500\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0809 - accuracy: 0.9800 - val_loss: 0.4153 - val_accuracy: 0.8650\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0705 - accuracy: 0.9812 - val_loss: 0.4145 - val_accuracy: 0.8550\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.4395 - val_accuracy: 0.8500\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 2.6955 - accuracy: 0.1350\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 2.3898 - accuracy: 0.1762 - val_loss: 1.9366 - val_accuracy: 0.3250\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.8892 - accuracy: 0.3462 - val_loss: 1.5680 - val_accuracy: 0.5100\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.4883 - accuracy: 0.5113 - val_loss: 1.3040 - val_accuracy: 0.5600\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 1.2879 - accuracy: 0.5987 - val_loss: 1.0996 - val_accuracy: 0.6650\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.1351 - accuracy: 0.6275 - val_loss: 0.9759 - val_accuracy: 0.6700\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.9943 - accuracy: 0.6950 - val_loss: 0.8540 - val_accuracy: 0.7650\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.8618 - accuracy: 0.7312 - val_loss: 0.8023 - val_accuracy: 0.7500\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.8030 - accuracy: 0.7387 - val_loss: 0.7549 - val_accuracy: 0.7700\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.7129 - accuracy: 0.7638 - val_loss: 0.7310 - val_accuracy: 0.7600\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6591 - accuracy: 0.7887 - val_loss: 0.6899 - val_accuracy: 0.7800\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6329 - accuracy: 0.7887 - val_loss: 0.6798 - val_accuracy: 0.7900\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5634 - accuracy: 0.8188 - val_loss: 0.6611 - val_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.5370 - accuracy: 0.8363 - val_loss: 0.6407 - val_accuracy: 0.7900\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.5136 - accuracy: 0.8375 - val_loss: 0.6327 - val_accuracy: 0.7800\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.4661 - accuracy: 0.8500 - val_loss: 0.6197 - val_accuracy: 0.7900\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4617 - accuracy: 0.8512 - val_loss: 0.6248 - val_accuracy: 0.7950\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4266 - accuracy: 0.8675 - val_loss: 0.6256 - val_accuracy: 0.7750\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4299 - accuracy: 0.8687 - val_loss: 0.6047 - val_accuracy: 0.8050\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3776 - accuracy: 0.8925 - val_loss: 0.5961 - val_accuracy: 0.7900\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3772 - accuracy: 0.8813 - val_loss: 0.6014 - val_accuracy: 0.7850\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3685 - accuracy: 0.8950 - val_loss: 0.6085 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3355 - accuracy: 0.8988 - val_loss: 0.5964 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3250 - accuracy: 0.9050 - val_loss: 0.5957 - val_accuracy: 0.7850\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.3288 - accuracy: 0.8913 - val_loss: 0.6012 - val_accuracy: 0.7900\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3460 - accuracy: 0.8800 - val_loss: 0.5927 - val_accuracy: 0.7750\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3100 - accuracy: 0.8938 - val_loss: 0.6004 - val_accuracy: 0.7950\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2941 - accuracy: 0.9137 - val_loss: 0.6063 - val_accuracy: 0.7900\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2697 - accuracy: 0.9125 - val_loss: 0.6013 - val_accuracy: 0.7950\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3096 - accuracy: 0.9050 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2799 - accuracy: 0.9087 - val_loss: 0.5847 - val_accuracy: 0.8100\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2538 - accuracy: 0.9212 - val_loss: 0.6084 - val_accuracy: 0.8050\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2225 - accuracy: 0.9350 - val_loss: 0.5887 - val_accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2447 - accuracy: 0.9237 - val_loss: 0.5945 - val_accuracy: 0.8100\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2259 - accuracy: 0.9312 - val_loss: 0.6066 - val_accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2338 - accuracy: 0.9275 - val_loss: 0.5909 - val_accuracy: 0.7950\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2131 - accuracy: 0.9375 - val_loss: 0.6059 - val_accuracy: 0.8050\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2044 - accuracy: 0.9425 - val_loss: 0.5979 - val_accuracy: 0.8100\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2162 - accuracy: 0.9388 - val_loss: 0.5814 - val_accuracy: 0.8300\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2232 - accuracy: 0.9212 - val_loss: 0.6045 - val_accuracy: 0.8100\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2001 - accuracy: 0.9400 - val_loss: 0.6103 - val_accuracy: 0.8100\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2005 - accuracy: 0.9400 - val_loss: 0.6097 - val_accuracy: 0.8050\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1967 - accuracy: 0.9425 - val_loss: 0.6114 - val_accuracy: 0.8050\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 0.1902 - accuracy: 0.9475 - val_loss: 0.5937 - val_accuracy: 0.8150\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 0.1764 - accuracy: 0.9438 - val_loss: 0.6087 - val_accuracy: 0.8200\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1614 - accuracy: 0.9575 - val_loss: 0.6198 - val_accuracy: 0.8100\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1564 - accuracy: 0.9575 - val_loss: 0.6189 - val_accuracy: 0.8050\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1627 - accuracy: 0.9550 - val_loss: 0.6386 - val_accuracy: 0.8000\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1697 - accuracy: 0.9500 - val_loss: 0.5984 - val_accuracy: 0.8200\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1574 - accuracy: 0.9588 - val_loss: 0.6342 - val_accuracy: 0.8050\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1610 - accuracy: 0.9500 - val_loss: 0.6204 - val_accuracy: 0.8200\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1544 - accuracy: 0.9588 - val_loss: 0.6100 - val_accuracy: 0.8200\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1437 - accuracy: 0.9688 - val_loss: 0.6371 - val_accuracy: 0.8200\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1360 - accuracy: 0.9650 - val_loss: 0.6254 - val_accuracy: 0.8050\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1368 - accuracy: 0.9563 - val_loss: 0.6249 - val_accuracy: 0.8150\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1499 - accuracy: 0.9650 - val_loss: 0.6153 - val_accuracy: 0.8050\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1483 - accuracy: 0.9550 - val_loss: 0.6069 - val_accuracy: 0.8150\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1320 - accuracy: 0.9563 - val_loss: 0.6221 - val_accuracy: 0.8200\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1334 - accuracy: 0.9688 - val_loss: 0.6552 - val_accuracy: 0.8050\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1369 - accuracy: 0.9625 - val_loss: 0.6113 - val_accuracy: 0.8150\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1532 - accuracy: 0.9563 - val_loss: 0.6251 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1285 - accuracy: 0.9638 - val_loss: 0.6332 - val_accuracy: 0.8000\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1106 - accuracy: 0.9675 - val_loss: 0.6112 - val_accuracy: 0.8100\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1097 - accuracy: 0.9663 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1171 - accuracy: 0.9712 - val_loss: 0.6193 - val_accuracy: 0.8050\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1211 - accuracy: 0.9663 - val_loss: 0.6335 - val_accuracy: 0.8050\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1084 - accuracy: 0.9700 - val_loss: 0.6420 - val_accuracy: 0.8100\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1069 - accuracy: 0.9725 - val_loss: 0.6516 - val_accuracy: 0.8050\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0958 - accuracy: 0.9762 - val_loss: 0.6269 - val_accuracy: 0.8100\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1208 - accuracy: 0.9688 - val_loss: 0.6352 - val_accuracy: 0.8100\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1012 - accuracy: 0.9725 - val_loss: 0.6554 - val_accuracy: 0.8150\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1191 - accuracy: 0.9663 - val_loss: 0.6648 - val_accuracy: 0.8150\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1038 - accuracy: 0.9725 - val_loss: 0.6396 - val_accuracy: 0.8150\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1099 - accuracy: 0.9688 - val_loss: 0.6292 - val_accuracy: 0.8150\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1049 - accuracy: 0.9787 - val_loss: 0.6451 - val_accuracy: 0.8050\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0736 - accuracy: 0.9837 - val_loss: 0.6364 - val_accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0974 - accuracy: 0.9712 - val_loss: 0.6291 - val_accuracy: 0.8150\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0808 - accuracy: 0.9800 - val_loss: 0.6191 - val_accuracy: 0.8050\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0842 - accuracy: 0.9812 - val_loss: 0.6404 - val_accuracy: 0.8150\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0850 - accuracy: 0.9812 - val_loss: 0.6412 - val_accuracy: 0.8150\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0826 - accuracy: 0.9825 - val_loss: 0.6295 - val_accuracy: 0.8100\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0811 - accuracy: 0.9750 - val_loss: 0.6356 - val_accuracy: 0.8050\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1058 - accuracy: 0.9638 - val_loss: 0.6571 - val_accuracy: 0.8100\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0861 - accuracy: 0.9762 - val_loss: 0.6448 - val_accuracy: 0.8150\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1015 - accuracy: 0.9712 - val_loss: 0.6171 - val_accuracy: 0.8150\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0877 - accuracy: 0.9787 - val_loss: 0.6574 - val_accuracy: 0.8050\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0810 - accuracy: 0.9825 - val_loss: 0.6556 - val_accuracy: 0.8100\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0846 - accuracy: 0.9812 - val_loss: 0.6456 - val_accuracy: 0.8050\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0888 - accuracy: 0.9750 - val_loss: 0.6435 - val_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0696 - accuracy: 0.9850 - val_loss: 0.6498 - val_accuracy: 0.8050\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 122ms/step - loss: 0.0730 - accuracy: 0.9812 - val_loss: 0.6496 - val_accuracy: 0.8050\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0661 - accuracy: 0.9837 - val_loss: 0.6513 - val_accuracy: 0.8000\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0635 - accuracy: 0.9850 - val_loss: 0.6759 - val_accuracy: 0.8100\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0785 - accuracy: 0.9775 - val_loss: 0.6563 - val_accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0778 - accuracy: 0.9787 - val_loss: 0.6698 - val_accuracy: 0.8050\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.6943 - val_accuracy: 0.7900\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.6543 - val_accuracy: 0.7950\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0752 - accuracy: 0.9825 - val_loss: 0.6795 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0654 - accuracy: 0.9825 - val_loss: 0.6548 - val_accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0715 - accuracy: 0.9812 - val_loss: 0.6664 - val_accuracy: 0.7900\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0635 - accuracy: 0.9812 - val_loss: 0.6623 - val_accuracy: 0.8100\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 2.4043 - accuracy: 0.0850\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 2.2840 - accuracy: 0.1925 - val_loss: 1.8508 - val_accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.8238 - accuracy: 0.4038 - val_loss: 1.5011 - val_accuracy: 0.5800\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.4898 - accuracy: 0.5113 - val_loss: 1.2222 - val_accuracy: 0.6450\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.2143 - accuracy: 0.6525 - val_loss: 1.0305 - val_accuracy: 0.7050\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.0597 - accuracy: 0.6662 - val_loss: 0.9007 - val_accuracy: 0.7550\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.9496 - accuracy: 0.7100 - val_loss: 0.8224 - val_accuracy: 0.7550\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.8512 - accuracy: 0.7387 - val_loss: 0.7581 - val_accuracy: 0.7700\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.7304 - accuracy: 0.7788 - val_loss: 0.7068 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.6815 - accuracy: 0.7850 - val_loss: 0.6652 - val_accuracy: 0.7700\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6276 - accuracy: 0.8062 - val_loss: 0.6400 - val_accuracy: 0.7900\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.6516 - accuracy: 0.7725 - val_loss: 0.6005 - val_accuracy: 0.8100\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.5781 - accuracy: 0.8225 - val_loss: 0.6027 - val_accuracy: 0.7950\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.5361 - accuracy: 0.8363 - val_loss: 0.5828 - val_accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.5003 - accuracy: 0.8425 - val_loss: 0.5609 - val_accuracy: 0.8100\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.4566 - accuracy: 0.8462 - val_loss: 0.5506 - val_accuracy: 0.8100\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4782 - accuracy: 0.8537 - val_loss: 0.5499 - val_accuracy: 0.8050\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4491 - accuracy: 0.8612 - val_loss: 0.5352 - val_accuracy: 0.8100\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4334 - accuracy: 0.8562 - val_loss: 0.5287 - val_accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3901 - accuracy: 0.8750 - val_loss: 0.5145 - val_accuracy: 0.8100\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.4025 - accuracy: 0.8725 - val_loss: 0.5108 - val_accuracy: 0.8050\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3443 - accuracy: 0.8950 - val_loss: 0.5060 - val_accuracy: 0.8100\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.3647 - accuracy: 0.8838 - val_loss: 0.5152 - val_accuracy: 0.7950\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3632 - accuracy: 0.8788 - val_loss: 0.4969 - val_accuracy: 0.8350\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3527 - accuracy: 0.8875 - val_loss: 0.4927 - val_accuracy: 0.8200\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2871 - accuracy: 0.9262 - val_loss: 0.4944 - val_accuracy: 0.8200\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2997 - accuracy: 0.9025 - val_loss: 0.5016 - val_accuracy: 0.8300\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.3252 - accuracy: 0.9050 - val_loss: 0.5068 - val_accuracy: 0.8150\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.2607 - accuracy: 0.9225 - val_loss: 0.4937 - val_accuracy: 0.8250\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2988 - accuracy: 0.9050 - val_loss: 0.4956 - val_accuracy: 0.8200\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2541 - accuracy: 0.9212 - val_loss: 0.4929 - val_accuracy: 0.8300\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.2596 - accuracy: 0.9225 - val_loss: 0.4988 - val_accuracy: 0.8150\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2535 - accuracy: 0.9200 - val_loss: 0.4891 - val_accuracy: 0.8150\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2334 - accuracy: 0.9312 - val_loss: 0.4888 - val_accuracy: 0.8250\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2431 - accuracy: 0.9287 - val_loss: 0.4725 - val_accuracy: 0.8150\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2219 - accuracy: 0.9400 - val_loss: 0.4899 - val_accuracy: 0.8100\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2122 - accuracy: 0.9388 - val_loss: 0.4909 - val_accuracy: 0.8150\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2109 - accuracy: 0.9350 - val_loss: 0.4613 - val_accuracy: 0.8250\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2308 - accuracy: 0.9275 - val_loss: 0.4750 - val_accuracy: 0.8200\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2073 - accuracy: 0.9400 - val_loss: 0.4761 - val_accuracy: 0.8050\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2100 - accuracy: 0.9388 - val_loss: 0.4797 - val_accuracy: 0.8050\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2062 - accuracy: 0.9413 - val_loss: 0.4680 - val_accuracy: 0.8200\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.2014 - accuracy: 0.9425 - val_loss: 0.4727 - val_accuracy: 0.8150\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1689 - accuracy: 0.9463 - val_loss: 0.4634 - val_accuracy: 0.8200\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1792 - accuracy: 0.9500 - val_loss: 0.4613 - val_accuracy: 0.8200\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1518 - accuracy: 0.9600 - val_loss: 0.4508 - val_accuracy: 0.8250\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1584 - accuracy: 0.9563 - val_loss: 0.4660 - val_accuracy: 0.8200\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1767 - accuracy: 0.9388 - val_loss: 0.4693 - val_accuracy: 0.8100\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1520 - accuracy: 0.9638 - val_loss: 0.4770 - val_accuracy: 0.8200\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1550 - accuracy: 0.9663 - val_loss: 0.4587 - val_accuracy: 0.8250\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1313 - accuracy: 0.9650 - val_loss: 0.4597 - val_accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1499 - accuracy: 0.9563 - val_loss: 0.4812 - val_accuracy: 0.8200\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1543 - accuracy: 0.9550 - val_loss: 0.4628 - val_accuracy: 0.8300\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1423 - accuracy: 0.9613 - val_loss: 0.4580 - val_accuracy: 0.8300\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1242 - accuracy: 0.9775 - val_loss: 0.4606 - val_accuracy: 0.8400\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1381 - accuracy: 0.9600 - val_loss: 0.4684 - val_accuracy: 0.8400\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1366 - accuracy: 0.9625 - val_loss: 0.4848 - val_accuracy: 0.8250\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1410 - accuracy: 0.9638 - val_loss: 0.4857 - val_accuracy: 0.8100\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1328 - accuracy: 0.9638 - val_loss: 0.4902 - val_accuracy: 0.8150\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1391 - accuracy: 0.9625 - val_loss: 0.4798 - val_accuracy: 0.8400\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1277 - accuracy: 0.9688 - val_loss: 0.4753 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1296 - accuracy: 0.9638 - val_loss: 0.4742 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1407 - accuracy: 0.9550 - val_loss: 0.4876 - val_accuracy: 0.8250\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1166 - accuracy: 0.9675 - val_loss: 0.4821 - val_accuracy: 0.8300\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1174 - accuracy: 0.9638 - val_loss: 0.4788 - val_accuracy: 0.8300\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1077 - accuracy: 0.9700 - val_loss: 0.4715 - val_accuracy: 0.8300\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0993 - accuracy: 0.9787 - val_loss: 0.4801 - val_accuracy: 0.8200\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.1013 - accuracy: 0.9775 - val_loss: 0.4708 - val_accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1225 - accuracy: 0.9700 - val_loss: 0.4731 - val_accuracy: 0.8300\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1069 - accuracy: 0.9737 - val_loss: 0.4713 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.1035 - accuracy: 0.9688 - val_loss: 0.4767 - val_accuracy: 0.8400\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.1105 - accuracy: 0.9750 - val_loss: 0.4890 - val_accuracy: 0.8150\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.0815 - accuracy: 0.9825 - val_loss: 0.4723 - val_accuracy: 0.8350\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0983 - accuracy: 0.9737 - val_loss: 0.4523 - val_accuracy: 0.8150\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0908 - accuracy: 0.9775 - val_loss: 0.4721 - val_accuracy: 0.8200\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0972 - accuracy: 0.9688 - val_loss: 0.4792 - val_accuracy: 0.8400\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0947 - accuracy: 0.9737 - val_loss: 0.4756 - val_accuracy: 0.8250\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0968 - accuracy: 0.9775 - val_loss: 0.4680 - val_accuracy: 0.8200\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0828 - accuracy: 0.9775 - val_loss: 0.4794 - val_accuracy: 0.8200\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0918 - accuracy: 0.9775 - val_loss: 0.4863 - val_accuracy: 0.8200\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0819 - accuracy: 0.9762 - val_loss: 0.4803 - val_accuracy: 0.8250\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0885 - accuracy: 0.9775 - val_loss: 0.4859 - val_accuracy: 0.8200\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0733 - accuracy: 0.9825 - val_loss: 0.4909 - val_accuracy: 0.8150\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0968 - accuracy: 0.9737 - val_loss: 0.4962 - val_accuracy: 0.8150\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0878 - accuracy: 0.9787 - val_loss: 0.4781 - val_accuracy: 0.8200\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0882 - accuracy: 0.9775 - val_loss: 0.4834 - val_accuracy: 0.8150\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0805 - accuracy: 0.9737 - val_loss: 0.4634 - val_accuracy: 0.8350\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 0.0791 - accuracy: 0.9825 - val_loss: 0.4689 - val_accuracy: 0.8250\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0751 - accuracy: 0.9825 - val_loss: 0.4774 - val_accuracy: 0.8300\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0706 - accuracy: 0.9862 - val_loss: 0.4761 - val_accuracy: 0.8350\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0693 - accuracy: 0.9812 - val_loss: 0.4786 - val_accuracy: 0.8300\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0854 - accuracy: 0.9812 - val_loss: 0.4841 - val_accuracy: 0.8250\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0628 - accuracy: 0.9862 - val_loss: 0.4805 - val_accuracy: 0.8350\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0730 - accuracy: 0.9837 - val_loss: 0.4669 - val_accuracy: 0.8300\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0940 - accuracy: 0.9663 - val_loss: 0.4537 - val_accuracy: 0.8350\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 0.4819 - val_accuracy: 0.8250\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0835 - accuracy: 0.9737 - val_loss: 0.4781 - val_accuracy: 0.8250\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0637 - accuracy: 0.9862 - val_loss: 0.4780 - val_accuracy: 0.8150\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0860 - accuracy: 0.9737 - val_loss: 0.4719 - val_accuracy: 0.8400\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0816 - accuracy: 0.9712 - val_loss: 0.4766 - val_accuracy: 0.8300\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0611 - accuracy: 0.9837 - val_loss: 0.4862 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72996503-f51b-497d-833f-6b477c9e5b35"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy after training\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.1030000016093254\n",
            "Final accuracy: 0.8509999990463257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "6c456e4a-ef53-4056-ac6e-149e500b2406"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0b772c54-ffd0-4938-a0c5-853ce112c0a2"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}