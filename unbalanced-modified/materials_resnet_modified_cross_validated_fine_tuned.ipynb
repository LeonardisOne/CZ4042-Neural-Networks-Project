{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-resnet-modified-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfUPxO64b2pVACqgk05Wdr"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5b6a7c-001e-4f4b-f951-03a71eb3f89c"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a4f59e-f3d2-4428-9967-2e36a038160c"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5869d99-3707-4c3c-d1c1-622b5477e02a"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621eba9f-2a9f-44c4-aa18-c960a4e88348"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = -27"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86378c48-6727-4e69-d28b-cbae925501a0"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.ResNet50V2(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 6s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 234ms/step - loss: 2.6420 - accuracy: 0.0800\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 2.3796 - accuracy: 0.1675 - val_loss: 2.0174 - val_accuracy: 0.2300\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 242ms/step - loss: 1.8514 - accuracy: 0.3425 - val_loss: 1.6267 - val_accuracy: 0.4750\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 242ms/step - loss: 1.5000 - accuracy: 0.5063 - val_loss: 1.3504 - val_accuracy: 0.5950\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.2757 - accuracy: 0.5863 - val_loss: 1.1509 - val_accuracy: 0.6550\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.0470 - accuracy: 0.6575 - val_loss: 1.0024 - val_accuracy: 0.7100\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.9555 - accuracy: 0.6913 - val_loss: 0.9164 - val_accuracy: 0.7450\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.8274 - accuracy: 0.7400 - val_loss: 0.8429 - val_accuracy: 0.7400\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.7497 - accuracy: 0.7563 - val_loss: 0.8064 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6974 - accuracy: 0.7950 - val_loss: 0.7699 - val_accuracy: 0.7600\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6465 - accuracy: 0.7937 - val_loss: 0.7281 - val_accuracy: 0.7800\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6342 - accuracy: 0.8075 - val_loss: 0.7081 - val_accuracy: 0.7750\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5733 - accuracy: 0.8087 - val_loss: 0.6809 - val_accuracy: 0.7900\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5453 - accuracy: 0.8275 - val_loss: 0.6615 - val_accuracy: 0.8100\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5291 - accuracy: 0.8438 - val_loss: 0.6479 - val_accuracy: 0.7900\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4600 - accuracy: 0.8600 - val_loss: 0.6448 - val_accuracy: 0.7900\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4425 - accuracy: 0.8562 - val_loss: 0.6233 - val_accuracy: 0.8050\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4344 - accuracy: 0.8550 - val_loss: 0.6263 - val_accuracy: 0.8000\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4374 - accuracy: 0.8537 - val_loss: 0.6186 - val_accuracy: 0.7950\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3964 - accuracy: 0.8800 - val_loss: 0.6121 - val_accuracy: 0.8050\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3769 - accuracy: 0.8863 - val_loss: 0.5993 - val_accuracy: 0.8100\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3496 - accuracy: 0.9000 - val_loss: 0.6111 - val_accuracy: 0.7950\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3132 - accuracy: 0.9112 - val_loss: 0.5996 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3334 - accuracy: 0.8950 - val_loss: 0.5891 - val_accuracy: 0.8100\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3296 - accuracy: 0.8925 - val_loss: 0.6146 - val_accuracy: 0.7850\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3126 - accuracy: 0.9025 - val_loss: 0.5888 - val_accuracy: 0.8050\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2791 - accuracy: 0.9150 - val_loss: 0.5874 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2997 - accuracy: 0.9000 - val_loss: 0.6080 - val_accuracy: 0.7800\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2860 - accuracy: 0.9125 - val_loss: 0.5990 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2630 - accuracy: 0.9175 - val_loss: 0.6105 - val_accuracy: 0.7850\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2624 - accuracy: 0.9175 - val_loss: 0.5941 - val_accuracy: 0.7800\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2490 - accuracy: 0.9312 - val_loss: 0.5861 - val_accuracy: 0.8000\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2626 - accuracy: 0.9150 - val_loss: 0.5867 - val_accuracy: 0.7900\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2533 - accuracy: 0.9162 - val_loss: 0.5807 - val_accuracy: 0.8050\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2292 - accuracy: 0.9287 - val_loss: 0.5715 - val_accuracy: 0.8050\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1923 - accuracy: 0.9513 - val_loss: 0.5707 - val_accuracy: 0.8250\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2450 - accuracy: 0.9300 - val_loss: 0.5769 - val_accuracy: 0.8100\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2255 - accuracy: 0.9325 - val_loss: 0.5783 - val_accuracy: 0.8200\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2072 - accuracy: 0.9337 - val_loss: 0.5809 - val_accuracy: 0.8150\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1832 - accuracy: 0.9500 - val_loss: 0.5846 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1814 - accuracy: 0.9475 - val_loss: 0.5908 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.1994 - accuracy: 0.9337 - val_loss: 0.5679 - val_accuracy: 0.8200\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.2041 - accuracy: 0.9375 - val_loss: 0.5839 - val_accuracy: 0.8150\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1638 - accuracy: 0.9563 - val_loss: 0.5756 - val_accuracy: 0.8150\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1710 - accuracy: 0.9463 - val_loss: 0.5834 - val_accuracy: 0.8150\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1957 - accuracy: 0.9375 - val_loss: 0.5775 - val_accuracy: 0.8200\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.1709 - accuracy: 0.9463 - val_loss: 0.6007 - val_accuracy: 0.8200\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1660 - accuracy: 0.9600 - val_loss: 0.5771 - val_accuracy: 0.8300\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1445 - accuracy: 0.9688 - val_loss: 0.5865 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1389 - accuracy: 0.9525 - val_loss: 0.5909 - val_accuracy: 0.8350\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1605 - accuracy: 0.9513 - val_loss: 0.5860 - val_accuracy: 0.8300\n",
            "13/13 [==============================] - 2s 168ms/step - loss: 0.5860 - accuracy: 0.8300\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.1578 - accuracy: 0.9488 - val_loss: 0.6281 - val_accuracy: 0.8400\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.1119 - accuracy: 0.9625 - val_loss: 0.6619 - val_accuracy: 0.8300\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.1052 - accuracy: 0.9613 - val_loss: 0.6340 - val_accuracy: 0.8400\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0776 - accuracy: 0.9775 - val_loss: 0.6765 - val_accuracy: 0.8150\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0648 - accuracy: 0.9775 - val_loss: 0.6855 - val_accuracy: 0.8200\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.7495 - val_accuracy: 0.8300\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0675 - accuracy: 0.9787 - val_loss: 0.7218 - val_accuracy: 0.8350\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0711 - accuracy: 0.9775 - val_loss: 0.7037 - val_accuracy: 0.8300\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.7650 - val_accuracy: 0.8200\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.7634 - val_accuracy: 0.8200\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0415 - accuracy: 0.9850 - val_loss: 0.7956 - val_accuracy: 0.8250\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0620 - accuracy: 0.9762 - val_loss: 0.7984 - val_accuracy: 0.8200\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0305 - accuracy: 0.9925 - val_loss: 0.8438 - val_accuracy: 0.8200\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.7866 - val_accuracy: 0.8350\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0352 - accuracy: 0.9875 - val_loss: 0.8835 - val_accuracy: 0.7850\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0292 - accuracy: 0.9862 - val_loss: 0.8824 - val_accuracy: 0.8150\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0366 - accuracy: 0.9862 - val_loss: 0.8465 - val_accuracy: 0.8300\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0399 - accuracy: 0.9837 - val_loss: 0.8944 - val_accuracy: 0.8300\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.8640 - val_accuracy: 0.8250\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0187 - accuracy: 0.9925 - val_loss: 0.9048 - val_accuracy: 0.8400\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.9229 - val_accuracy: 0.8350\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 176ms/step - loss: 2.4992 - accuracy: 0.1250\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 2.3900 - accuracy: 0.1813 - val_loss: 1.8483 - val_accuracy: 0.4100\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.8143 - accuracy: 0.3750 - val_loss: 1.4902 - val_accuracy: 0.5650\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.4990 - accuracy: 0.5350 - val_loss: 1.2384 - val_accuracy: 0.6750\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 1.2527 - accuracy: 0.6100 - val_loss: 1.0325 - val_accuracy: 0.7300\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 1.0712 - accuracy: 0.6725 - val_loss: 0.9065 - val_accuracy: 0.7550\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.9347 - accuracy: 0.7150 - val_loss: 0.8059 - val_accuracy: 0.7550\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.8334 - accuracy: 0.7450 - val_loss: 0.7473 - val_accuracy: 0.7700\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.7429 - accuracy: 0.7738 - val_loss: 0.7187 - val_accuracy: 0.7850\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.7029 - accuracy: 0.7775 - val_loss: 0.6764 - val_accuracy: 0.7800\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.6565 - accuracy: 0.8037 - val_loss: 0.6435 - val_accuracy: 0.8000\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.6297 - accuracy: 0.8100 - val_loss: 0.6545 - val_accuracy: 0.7800\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.5535 - accuracy: 0.8263 - val_loss: 0.6162 - val_accuracy: 0.8150\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5581 - accuracy: 0.8288 - val_loss: 0.6032 - val_accuracy: 0.8050\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.5195 - accuracy: 0.8313 - val_loss: 0.5914 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4701 - accuracy: 0.8525 - val_loss: 0.5802 - val_accuracy: 0.8100\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4961 - accuracy: 0.8438 - val_loss: 0.5629 - val_accuracy: 0.8250\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4319 - accuracy: 0.8625 - val_loss: 0.5686 - val_accuracy: 0.8150\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4345 - accuracy: 0.8600 - val_loss: 0.5548 - val_accuracy: 0.8100\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.4124 - accuracy: 0.8675 - val_loss: 0.5524 - val_accuracy: 0.8200\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 243ms/step - loss: 0.4038 - accuracy: 0.8650 - val_loss: 0.5529 - val_accuracy: 0.8250\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3517 - accuracy: 0.8913 - val_loss: 0.5398 - val_accuracy: 0.8150\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3474 - accuracy: 0.8925 - val_loss: 0.5450 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3403 - accuracy: 0.8950 - val_loss: 0.5443 - val_accuracy: 0.8150\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3102 - accuracy: 0.9162 - val_loss: 0.5093 - val_accuracy: 0.8350\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.3343 - accuracy: 0.8950 - val_loss: 0.5160 - val_accuracy: 0.8300\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2685 - accuracy: 0.9112 - val_loss: 0.5210 - val_accuracy: 0.8200\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2742 - accuracy: 0.9175 - val_loss: 0.5158 - val_accuracy: 0.8250\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2946 - accuracy: 0.9025 - val_loss: 0.5111 - val_accuracy: 0.8250\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2501 - accuracy: 0.9275 - val_loss: 0.5120 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2466 - accuracy: 0.9237 - val_loss: 0.5207 - val_accuracy: 0.8350\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2438 - accuracy: 0.9375 - val_loss: 0.5197 - val_accuracy: 0.8350\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2678 - accuracy: 0.9187 - val_loss: 0.4944 - val_accuracy: 0.8350\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2333 - accuracy: 0.9287 - val_loss: 0.5214 - val_accuracy: 0.8250\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2255 - accuracy: 0.9300 - val_loss: 0.5080 - val_accuracy: 0.8350\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2223 - accuracy: 0.9362 - val_loss: 0.5037 - val_accuracy: 0.8450\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2271 - accuracy: 0.9325 - val_loss: 0.5080 - val_accuracy: 0.8300\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2278 - accuracy: 0.9350 - val_loss: 0.4894 - val_accuracy: 0.8350\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2235 - accuracy: 0.9225 - val_loss: 0.5076 - val_accuracy: 0.8250\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2080 - accuracy: 0.9337 - val_loss: 0.5110 - val_accuracy: 0.8250\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.2079 - accuracy: 0.9388 - val_loss: 0.5055 - val_accuracy: 0.8200\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.2342 - accuracy: 0.9225 - val_loss: 0.5143 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1730 - accuracy: 0.9525 - val_loss: 0.4925 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1643 - accuracy: 0.9613 - val_loss: 0.5191 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1644 - accuracy: 0.9488 - val_loss: 0.5271 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1921 - accuracy: 0.9388 - val_loss: 0.5099 - val_accuracy: 0.8300\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1797 - accuracy: 0.9525 - val_loss: 0.5160 - val_accuracy: 0.8350\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.1670 - accuracy: 0.9463 - val_loss: 0.5168 - val_accuracy: 0.8350\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.1830 - accuracy: 0.9475 - val_loss: 0.5119 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1588 - accuracy: 0.9613 - val_loss: 0.5111 - val_accuracy: 0.8350\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.1516 - accuracy: 0.9575 - val_loss: 0.5110 - val_accuracy: 0.8250\n",
            "13/13 [==============================] - 2s 170ms/step - loss: 0.5110 - accuracy: 0.8250\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.1286 - accuracy: 0.9500 - val_loss: 0.5399 - val_accuracy: 0.8300\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.5702 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0903 - accuracy: 0.9688 - val_loss: 0.5729 - val_accuracy: 0.8350\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.1002 - accuracy: 0.9725 - val_loss: 0.5903 - val_accuracy: 0.8200\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0731 - accuracy: 0.9800 - val_loss: 0.5976 - val_accuracy: 0.8400\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0774 - accuracy: 0.9712 - val_loss: 0.5658 - val_accuracy: 0.8300\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.7143 - val_accuracy: 0.8150\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 305ms/step - loss: 0.0561 - accuracy: 0.9825 - val_loss: 0.6770 - val_accuracy: 0.8250\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0688 - accuracy: 0.9800 - val_loss: 0.6615 - val_accuracy: 0.8300\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0642 - accuracy: 0.9825 - val_loss: 0.7127 - val_accuracy: 0.8250\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.7058 - val_accuracy: 0.8150\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0369 - accuracy: 0.9862 - val_loss: 0.7568 - val_accuracy: 0.8150\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.8321 - val_accuracy: 0.8050\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.7992 - val_accuracy: 0.8300\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.8649 - val_accuracy: 0.8200\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0259 - accuracy: 0.9900 - val_loss: 0.8290 - val_accuracy: 0.8300\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0419 - accuracy: 0.9812 - val_loss: 0.8199 - val_accuracy: 0.8200\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0287 - accuracy: 0.9937 - val_loss: 0.8706 - val_accuracy: 0.8350\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0253 - accuracy: 0.9950 - val_loss: 0.8475 - val_accuracy: 0.8250\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.8724 - val_accuracy: 0.8250\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.9960 - val_accuracy: 0.8150\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 2.5624 - accuracy: 0.1000\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 2.3331 - accuracy: 0.1813 - val_loss: 1.9137 - val_accuracy: 0.3900\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 1.7960 - accuracy: 0.3925 - val_loss: 1.5350 - val_accuracy: 0.5650\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 1.4536 - accuracy: 0.5375 - val_loss: 1.2611 - val_accuracy: 0.6600\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 1.2216 - accuracy: 0.6363 - val_loss: 1.0657 - val_accuracy: 0.7300\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 1.0247 - accuracy: 0.6913 - val_loss: 0.9201 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.9115 - accuracy: 0.7138 - val_loss: 0.8320 - val_accuracy: 0.7550\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.8208 - accuracy: 0.7550 - val_loss: 0.7529 - val_accuracy: 0.7750\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.7287 - accuracy: 0.7763 - val_loss: 0.7166 - val_accuracy: 0.7750\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.7255 - accuracy: 0.7738 - val_loss: 0.6819 - val_accuracy: 0.7800\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.6485 - accuracy: 0.7937 - val_loss: 0.6411 - val_accuracy: 0.8050\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.6616 - accuracy: 0.7912 - val_loss: 0.6114 - val_accuracy: 0.8000\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5606 - accuracy: 0.8300 - val_loss: 0.5875 - val_accuracy: 0.8050\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 12s 244ms/step - loss: 0.5292 - accuracy: 0.8462 - val_loss: 0.5779 - val_accuracy: 0.8150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4926 - accuracy: 0.8475 - val_loss: 0.5562 - val_accuracy: 0.8150\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4998 - accuracy: 0.8275 - val_loss: 0.5493 - val_accuracy: 0.8200\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4724 - accuracy: 0.8338 - val_loss: 0.5246 - val_accuracy: 0.8300\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.4461 - accuracy: 0.8625 - val_loss: 0.5226 - val_accuracy: 0.8400\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.4235 - accuracy: 0.8750 - val_loss: 0.5213 - val_accuracy: 0.8250\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 12s 245ms/step - loss: 0.3997 - accuracy: 0.8800 - val_loss: 0.5102 - val_accuracy: 0.8200\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.4030 - accuracy: 0.8788 - val_loss: 0.5051 - val_accuracy: 0.8200\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.3620 - accuracy: 0.8763 - val_loss: 0.5025 - val_accuracy: 0.8350\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.3640 - accuracy: 0.8813 - val_loss: 0.5067 - val_accuracy: 0.8400\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 12s 246ms/step - loss: 0.3248 - accuracy: 0.8950 - val_loss: 0.4994 - val_accuracy: 0.8300\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.3407 - accuracy: 0.8875 - val_loss: 0.4905 - val_accuracy: 0.8250\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.2891 - accuracy: 0.9087 - val_loss: 0.4894 - val_accuracy: 0.8400\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.3262 - accuracy: 0.8950 - val_loss: 0.4856 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.3225 - accuracy: 0.9013 - val_loss: 0.4835 - val_accuracy: 0.8400\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2801 - accuracy: 0.9200 - val_loss: 0.4840 - val_accuracy: 0.8450\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2785 - accuracy: 0.9075 - val_loss: 0.4825 - val_accuracy: 0.8350\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2827 - accuracy: 0.9175 - val_loss: 0.4893 - val_accuracy: 0.8450\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2685 - accuracy: 0.9250 - val_loss: 0.4712 - val_accuracy: 0.8450\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2449 - accuracy: 0.9250 - val_loss: 0.4709 - val_accuracy: 0.8550\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.2951 - accuracy: 0.9162 - val_loss: 0.4688 - val_accuracy: 0.8500\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.2270 - accuracy: 0.9388 - val_loss: 0.4668 - val_accuracy: 0.8500\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.2379 - accuracy: 0.9187 - val_loss: 0.4596 - val_accuracy: 0.8600\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2452 - accuracy: 0.9275 - val_loss: 0.4662 - val_accuracy: 0.8550\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 12s 247ms/step - loss: 0.2007 - accuracy: 0.9600 - val_loss: 0.4655 - val_accuracy: 0.8600\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.2122 - accuracy: 0.9312 - val_loss: 0.4618 - val_accuracy: 0.8650\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.1956 - accuracy: 0.9413 - val_loss: 0.4529 - val_accuracy: 0.8650\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2175 - accuracy: 0.9388 - val_loss: 0.4643 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2059 - accuracy: 0.9413 - val_loss: 0.4571 - val_accuracy: 0.8600\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.1792 - accuracy: 0.9563 - val_loss: 0.4546 - val_accuracy: 0.8650\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.2117 - accuracy: 0.9400 - val_loss: 0.4638 - val_accuracy: 0.8600\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2091 - accuracy: 0.9413 - val_loss: 0.4460 - val_accuracy: 0.8750\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.1822 - accuracy: 0.9475 - val_loss: 0.4478 - val_accuracy: 0.8650\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.1709 - accuracy: 0.9525 - val_loss: 0.4433 - val_accuracy: 0.8700\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.1714 - accuracy: 0.9550 - val_loss: 0.4485 - val_accuracy: 0.8800\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.1438 - accuracy: 0.9600 - val_loss: 0.4468 - val_accuracy: 0.8650\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 12s 248ms/step - loss: 0.1686 - accuracy: 0.9450 - val_loss: 0.4447 - val_accuracy: 0.8600\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.1809 - accuracy: 0.9362 - val_loss: 0.4508 - val_accuracy: 0.8700\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 0.4508 - accuracy: 0.8700\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 327ms/step - loss: 0.1476 - accuracy: 0.9613 - val_loss: 0.5202 - val_accuracy: 0.8550\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.1331 - accuracy: 0.9463 - val_loss: 0.4821 - val_accuracy: 0.8800\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.1114 - accuracy: 0.9588 - val_loss: 0.5019 - val_accuracy: 0.8600\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.5175 - val_accuracy: 0.8700\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.5332 - val_accuracy: 0.8600\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.5228 - val_accuracy: 0.8650\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0724 - accuracy: 0.9700 - val_loss: 0.5068 - val_accuracy: 0.8800\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0745 - accuracy: 0.9762 - val_loss: 0.5297 - val_accuracy: 0.8700\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0629 - accuracy: 0.9762 - val_loss: 0.5946 - val_accuracy: 0.8550\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0505 - accuracy: 0.9812 - val_loss: 0.5558 - val_accuracy: 0.8800\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0413 - accuracy: 0.9850 - val_loss: 0.5908 - val_accuracy: 0.8650\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0539 - accuracy: 0.9812 - val_loss: 0.5980 - val_accuracy: 0.8600\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 306ms/step - loss: 0.0594 - accuracy: 0.9800 - val_loss: 0.5848 - val_accuracy: 0.8650\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0650 - accuracy: 0.9787 - val_loss: 0.5911 - val_accuracy: 0.8650\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.5752 - val_accuracy: 0.8700\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.6331 - val_accuracy: 0.8550\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0520 - accuracy: 0.9787 - val_loss: 0.6208 - val_accuracy: 0.8600\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.6169 - val_accuracy: 0.8650\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.6405 - val_accuracy: 0.8650\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 0.6190 - val_accuracy: 0.8700\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.6875 - val_accuracy: 0.8500\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 181ms/step - loss: 2.5879 - accuracy: 0.0950\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 2.3293 - accuracy: 0.2013 - val_loss: 1.9318 - val_accuracy: 0.3550\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 1.8321 - accuracy: 0.3812 - val_loss: 1.5374 - val_accuracy: 0.5500\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 1.4945 - accuracy: 0.5063 - val_loss: 1.2443 - val_accuracy: 0.6500\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 1.2456 - accuracy: 0.6162 - val_loss: 1.0409 - val_accuracy: 0.7250\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 1.0249 - accuracy: 0.7038 - val_loss: 0.8885 - val_accuracy: 0.7650\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.9541 - accuracy: 0.7125 - val_loss: 0.8020 - val_accuracy: 0.7750\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.8121 - accuracy: 0.7437 - val_loss: 0.7319 - val_accuracy: 0.7850\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.7083 - accuracy: 0.7825 - val_loss: 0.6803 - val_accuracy: 0.8100\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.7092 - accuracy: 0.7937 - val_loss: 0.6568 - val_accuracy: 0.7950\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.6322 - accuracy: 0.7900 - val_loss: 0.6205 - val_accuracy: 0.8150\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.5910 - accuracy: 0.8112 - val_loss: 0.6014 - val_accuracy: 0.8400\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.5188 - accuracy: 0.8475 - val_loss: 0.5773 - val_accuracy: 0.8350\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.5183 - accuracy: 0.8350 - val_loss: 0.5984 - val_accuracy: 0.8200\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.4896 - accuracy: 0.8500 - val_loss: 0.5516 - val_accuracy: 0.8350\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.4534 - accuracy: 0.8587 - val_loss: 0.5623 - val_accuracy: 0.8250\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.4202 - accuracy: 0.8775 - val_loss: 0.5689 - val_accuracy: 0.8150\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.4134 - accuracy: 0.8700 - val_loss: 0.5542 - val_accuracy: 0.8250\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.4280 - accuracy: 0.8662 - val_loss: 0.5523 - val_accuracy: 0.8300\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3802 - accuracy: 0.8788 - val_loss: 0.5508 - val_accuracy: 0.8100\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.3742 - accuracy: 0.8775 - val_loss: 0.5685 - val_accuracy: 0.8150\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3874 - accuracy: 0.8737 - val_loss: 0.5527 - val_accuracy: 0.8400\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.3313 - accuracy: 0.9000 - val_loss: 0.5269 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3392 - accuracy: 0.8888 - val_loss: 0.5380 - val_accuracy: 0.8300\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2977 - accuracy: 0.9150 - val_loss: 0.5477 - val_accuracy: 0.8200\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2897 - accuracy: 0.9187 - val_loss: 0.5494 - val_accuracy: 0.8400\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2982 - accuracy: 0.9062 - val_loss: 0.5354 - val_accuracy: 0.8250\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3134 - accuracy: 0.8988 - val_loss: 0.5665 - val_accuracy: 0.8150\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2466 - accuracy: 0.9350 - val_loss: 0.5248 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2576 - accuracy: 0.9237 - val_loss: 0.5515 - val_accuracy: 0.8400\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2734 - accuracy: 0.9137 - val_loss: 0.5444 - val_accuracy: 0.8400\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2357 - accuracy: 0.9287 - val_loss: 0.5371 - val_accuracy: 0.8500\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2373 - accuracy: 0.9325 - val_loss: 0.5390 - val_accuracy: 0.8400\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 0.2344 - accuracy: 0.9300 - val_loss: 0.5447 - val_accuracy: 0.8400\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2269 - accuracy: 0.9337 - val_loss: 0.5409 - val_accuracy: 0.8400\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1888 - accuracy: 0.9425 - val_loss: 0.5319 - val_accuracy: 0.8400\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2224 - accuracy: 0.9337 - val_loss: 0.5444 - val_accuracy: 0.8500\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2276 - accuracy: 0.9438 - val_loss: 0.5634 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1913 - accuracy: 0.9413 - val_loss: 0.5606 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2236 - accuracy: 0.9300 - val_loss: 0.5577 - val_accuracy: 0.8350\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1885 - accuracy: 0.9388 - val_loss: 0.5622 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2094 - accuracy: 0.9350 - val_loss: 0.5705 - val_accuracy: 0.8400\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.1767 - accuracy: 0.9513 - val_loss: 0.5570 - val_accuracy: 0.8300\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1788 - accuracy: 0.9425 - val_loss: 0.5493 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1644 - accuracy: 0.9525 - val_loss: 0.5554 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1724 - accuracy: 0.9538 - val_loss: 0.5491 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1598 - accuracy: 0.9500 - val_loss: 0.5557 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1702 - accuracy: 0.9563 - val_loss: 0.5516 - val_accuracy: 0.8350\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1521 - accuracy: 0.9575 - val_loss: 0.5571 - val_accuracy: 0.8300\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1631 - accuracy: 0.9500 - val_loss: 0.5562 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1462 - accuracy: 0.9638 - val_loss: 0.5645 - val_accuracy: 0.8400\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 0.5645 - accuracy: 0.8400\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 328ms/step - loss: 0.1366 - accuracy: 0.9588 - val_loss: 0.6621 - val_accuracy: 0.8200\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.1045 - accuracy: 0.9675 - val_loss: 0.6296 - val_accuracy: 0.8300\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.1158 - accuracy: 0.9600 - val_loss: 0.6711 - val_accuracy: 0.8250\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0936 - accuracy: 0.9688 - val_loss: 0.6589 - val_accuracy: 0.8450\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.7531 - val_accuracy: 0.8350\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0607 - accuracy: 0.9825 - val_loss: 0.7645 - val_accuracy: 0.8250\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0767 - accuracy: 0.9775 - val_loss: 0.7071 - val_accuracy: 0.8300\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 0.7345 - val_accuracy: 0.8300\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0450 - accuracy: 0.9837 - val_loss: 0.8056 - val_accuracy: 0.8200\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.7946 - val_accuracy: 0.8400\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.8803 - val_accuracy: 0.7950\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.9436 - val_accuracy: 0.8000\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 310ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.8775 - val_accuracy: 0.8150\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.8882 - val_accuracy: 0.8300\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.9409 - val_accuracy: 0.8150\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.9724 - val_accuracy: 0.8150\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0231 - accuracy: 0.9962 - val_loss: 0.8604 - val_accuracy: 0.8300\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.8391 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 0.9298 - val_accuracy: 0.8350\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.9521 - val_accuracy: 0.8350\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0287 - accuracy: 0.9937 - val_loss: 1.0432 - val_accuracy: 0.8100\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 2.6256 - accuracy: 0.1050\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 12s 249ms/step - loss: 2.3459 - accuracy: 0.1700 - val_loss: 1.9531 - val_accuracy: 0.3600\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 1.8746 - accuracy: 0.3625 - val_loss: 1.6204 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 1.4935 - accuracy: 0.5200 - val_loss: 1.3415 - val_accuracy: 0.6050\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 1.2450 - accuracy: 0.6187 - val_loss: 1.1521 - val_accuracy: 0.6450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 1.1063 - accuracy: 0.6325 - val_loss: 1.0448 - val_accuracy: 0.6650\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.9950 - accuracy: 0.6837 - val_loss: 0.9502 - val_accuracy: 0.6800\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.8569 - accuracy: 0.7387 - val_loss: 0.8886 - val_accuracy: 0.6900\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.8150 - accuracy: 0.7250 - val_loss: 0.8295 - val_accuracy: 0.7050\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.7303 - accuracy: 0.7575 - val_loss: 0.7813 - val_accuracy: 0.7200\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.6538 - accuracy: 0.7987 - val_loss: 0.7435 - val_accuracy: 0.7450\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.6528 - accuracy: 0.7925 - val_loss: 0.7106 - val_accuracy: 0.7350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.6004 - accuracy: 0.8050 - val_loss: 0.6973 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.5615 - accuracy: 0.8400 - val_loss: 0.6767 - val_accuracy: 0.7550\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.5221 - accuracy: 0.8325 - val_loss: 0.6518 - val_accuracy: 0.7700\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.5074 - accuracy: 0.8350 - val_loss: 0.6411 - val_accuracy: 0.7850\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.4638 - accuracy: 0.8525 - val_loss: 0.6272 - val_accuracy: 0.7800\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.4601 - accuracy: 0.8662 - val_loss: 0.6218 - val_accuracy: 0.7850\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.4470 - accuracy: 0.8525 - val_loss: 0.6022 - val_accuracy: 0.7900\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.3962 - accuracy: 0.8788 - val_loss: 0.5938 - val_accuracy: 0.8050\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.4089 - accuracy: 0.8687 - val_loss: 0.5844 - val_accuracy: 0.8100\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3791 - accuracy: 0.8813 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3618 - accuracy: 0.8863 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3298 - accuracy: 0.8988 - val_loss: 0.5685 - val_accuracy: 0.8150\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.3429 - accuracy: 0.8875 - val_loss: 0.5570 - val_accuracy: 0.7950\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.3297 - accuracy: 0.8863 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2891 - accuracy: 0.9137 - val_loss: 0.5524 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2828 - accuracy: 0.9175 - val_loss: 0.5593 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.2779 - accuracy: 0.9250 - val_loss: 0.5440 - val_accuracy: 0.8100\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2921 - accuracy: 0.9075 - val_loss: 0.5471 - val_accuracy: 0.8100\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2860 - accuracy: 0.9137 - val_loss: 0.5442 - val_accuracy: 0.8050\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2717 - accuracy: 0.9250 - val_loss: 0.5300 - val_accuracy: 0.8050\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2364 - accuracy: 0.9312 - val_loss: 0.5424 - val_accuracy: 0.8100\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2480 - accuracy: 0.9375 - val_loss: 0.5327 - val_accuracy: 0.8150\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2631 - accuracy: 0.9250 - val_loss: 0.5413 - val_accuracy: 0.8100\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2631 - accuracy: 0.9225 - val_loss: 0.5287 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 12s 250ms/step - loss: 0.2330 - accuracy: 0.9362 - val_loss: 0.5275 - val_accuracy: 0.8100\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 252ms/step - loss: 0.2048 - accuracy: 0.9388 - val_loss: 0.5393 - val_accuracy: 0.8150\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2284 - accuracy: 0.9337 - val_loss: 0.5374 - val_accuracy: 0.8100\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.2111 - accuracy: 0.9312 - val_loss: 0.5258 - val_accuracy: 0.8250\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1864 - accuracy: 0.9463 - val_loss: 0.5334 - val_accuracy: 0.8100\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1800 - accuracy: 0.9400 - val_loss: 0.5298 - val_accuracy: 0.8150\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1856 - accuracy: 0.9488 - val_loss: 0.5400 - val_accuracy: 0.8100\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1837 - accuracy: 0.9525 - val_loss: 0.5429 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1802 - accuracy: 0.9425 - val_loss: 0.5483 - val_accuracy: 0.8100\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 253ms/step - loss: 0.1848 - accuracy: 0.9475 - val_loss: 0.5715 - val_accuracy: 0.8100\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 250ms/step - loss: 0.1756 - accuracy: 0.9513 - val_loss: 0.5525 - val_accuracy: 0.8100\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1563 - accuracy: 0.9525 - val_loss: 0.5564 - val_accuracy: 0.8100\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1594 - accuracy: 0.9563 - val_loss: 0.5309 - val_accuracy: 0.8100\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1615 - accuracy: 0.9563 - val_loss: 0.5491 - val_accuracy: 0.8100\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 251ms/step - loss: 0.1651 - accuracy: 0.9563 - val_loss: 0.5431 - val_accuracy: 0.8200\n",
            "13/13 [==============================] - 2s 172ms/step - loss: 0.5431 - accuracy: 0.8200\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 23,828,362\n",
            "Trainable params: 12,346,762\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 16s 329ms/step - loss: 0.1577 - accuracy: 0.9463 - val_loss: 0.5492 - val_accuracy: 0.8200\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.1492 - accuracy: 0.9488 - val_loss: 0.5519 - val_accuracy: 0.8250\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 15s 310ms/step - loss: 0.0923 - accuracy: 0.9700 - val_loss: 0.5607 - val_accuracy: 0.8300\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0898 - accuracy: 0.9737 - val_loss: 0.5949 - val_accuracy: 0.8300\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0768 - accuracy: 0.9712 - val_loss: 0.5716 - val_accuracy: 0.8100\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.6950 - val_accuracy: 0.8100\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0516 - accuracy: 0.9800 - val_loss: 0.6630 - val_accuracy: 0.8050\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0577 - accuracy: 0.9800 - val_loss: 0.6664 - val_accuracy: 0.8200\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.6165 - val_accuracy: 0.8250\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0430 - accuracy: 0.9900 - val_loss: 0.6532 - val_accuracy: 0.8450\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0410 - accuracy: 0.9825 - val_loss: 0.6147 - val_accuracy: 0.8300\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.6718 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.6542 - val_accuracy: 0.8250\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 0.7165 - val_accuracy: 0.8150\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0323 - accuracy: 0.9875 - val_loss: 0.7154 - val_accuracy: 0.8150\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 0.7371 - val_accuracy: 0.8150\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.7356 - val_accuracy: 0.8150\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.7958 - val_accuracy: 0.8200\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 15s 308ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.7245 - val_accuracy: 0.8450\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.7124 - val_accuracy: 0.8450\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.8011 - val_accuracy: 0.8150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ec94b5-ad49-434d-da8e-bd62e35c312a"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.10099999904632569\n",
            "Accuracy before fine-tuning: 0.8369999885559082\n",
            "Final accuracy: 0.8520000100135803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a1130ee6-0fd1-4eaf-9a46-45f84be50153"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c7874d79-0013-40b2-b74c-8e7a1f147892"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}