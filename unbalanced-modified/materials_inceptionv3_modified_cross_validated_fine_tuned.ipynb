{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-modified-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkaORmkEBaCSzmCQXZmyu4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686438df-e5d4-4282-cfb1-9a01e37d46e8"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is required for pre-trained models like Inception V3\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6274894-b273-443a-a139-fa4fc7fd8a46"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff211cb2-b040-4b90-920b-ccfd79d96038"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc13ee3-aad0-4e05-c121-a7c0d764cacd"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.inception_v3.preprocess_input"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 249"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca0b286-4c27-4aad-bd73-3b1c34f2b669"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.InceptionV3(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 2.5034 - accuracy: 0.1100\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 2.3019 - accuracy: 0.1675 - val_loss: 2.0478 - val_accuracy: 0.3000\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 1.9730 - accuracy: 0.3275 - val_loss: 1.7889 - val_accuracy: 0.4700\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.7493 - accuracy: 0.4512 - val_loss: 1.5589 - val_accuracy: 0.5600\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.4484 - accuracy: 0.5675 - val_loss: 1.3529 - val_accuracy: 0.6100\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.2608 - accuracy: 0.6225 - val_loss: 1.2077 - val_accuracy: 0.6450\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.1213 - accuracy: 0.6612 - val_loss: 1.1117 - val_accuracy: 0.6650\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.0349 - accuracy: 0.6938 - val_loss: 1.0212 - val_accuracy: 0.6950\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.9269 - accuracy: 0.7362 - val_loss: 0.9632 - val_accuracy: 0.6950\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.8685 - accuracy: 0.7475 - val_loss: 0.9135 - val_accuracy: 0.7150\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.8292 - accuracy: 0.7513 - val_loss: 0.8700 - val_accuracy: 0.7250\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.7459 - accuracy: 0.7738 - val_loss: 0.8445 - val_accuracy: 0.7150\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.7222 - accuracy: 0.7800 - val_loss: 0.8338 - val_accuracy: 0.7000\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6695 - accuracy: 0.8188 - val_loss: 0.8259 - val_accuracy: 0.7150\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.6570 - accuracy: 0.8062 - val_loss: 0.7930 - val_accuracy: 0.7200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6253 - accuracy: 0.8112 - val_loss: 0.7694 - val_accuracy: 0.7150\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5861 - accuracy: 0.8275 - val_loss: 0.7465 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.5552 - accuracy: 0.8375 - val_loss: 0.7375 - val_accuracy: 0.7650\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.5359 - accuracy: 0.8475 - val_loss: 0.7328 - val_accuracy: 0.7400\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5627 - accuracy: 0.8263 - val_loss: 0.7095 - val_accuracy: 0.7600\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4882 - accuracy: 0.8512 - val_loss: 0.7012 - val_accuracy: 0.7750\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5048 - accuracy: 0.8388 - val_loss: 0.7177 - val_accuracy: 0.7450\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4624 - accuracy: 0.8500 - val_loss: 0.7004 - val_accuracy: 0.7450\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4881 - accuracy: 0.8600 - val_loss: 0.6903 - val_accuracy: 0.7550\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4435 - accuracy: 0.8750 - val_loss: 0.6883 - val_accuracy: 0.7500\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.4243 - accuracy: 0.8687 - val_loss: 0.6881 - val_accuracy: 0.7600\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.4096 - accuracy: 0.8900 - val_loss: 0.6760 - val_accuracy: 0.7650\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3984 - accuracy: 0.8863 - val_loss: 0.6731 - val_accuracy: 0.7800\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.4292 - accuracy: 0.8587 - val_loss: 0.6496 - val_accuracy: 0.7900\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3797 - accuracy: 0.8900 - val_loss: 0.6488 - val_accuracy: 0.7700\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3615 - accuracy: 0.8913 - val_loss: 0.6595 - val_accuracy: 0.7750\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3668 - accuracy: 0.8988 - val_loss: 0.6601 - val_accuracy: 0.7700\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3506 - accuracy: 0.8988 - val_loss: 0.6461 - val_accuracy: 0.7750\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3369 - accuracy: 0.9038 - val_loss: 0.6428 - val_accuracy: 0.7750\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3226 - accuracy: 0.9162 - val_loss: 0.6666 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3457 - accuracy: 0.8988 - val_loss: 0.6284 - val_accuracy: 0.7900\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3086 - accuracy: 0.9112 - val_loss: 0.6380 - val_accuracy: 0.7600\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3122 - accuracy: 0.8988 - val_loss: 0.6505 - val_accuracy: 0.7750\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2970 - accuracy: 0.9200 - val_loss: 0.6347 - val_accuracy: 0.7750\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2946 - accuracy: 0.9200 - val_loss: 0.6203 - val_accuracy: 0.7900\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2792 - accuracy: 0.9287 - val_loss: 0.6254 - val_accuracy: 0.7750\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2836 - accuracy: 0.9162 - val_loss: 0.6191 - val_accuracy: 0.7850\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2570 - accuracy: 0.9300 - val_loss: 0.6269 - val_accuracy: 0.7850\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2700 - accuracy: 0.9187 - val_loss: 0.6157 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2738 - accuracy: 0.9187 - val_loss: 0.6243 - val_accuracy: 0.7900\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2370 - accuracy: 0.9287 - val_loss: 0.6394 - val_accuracy: 0.7750\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2422 - accuracy: 0.9337 - val_loss: 0.6621 - val_accuracy: 0.7750\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2656 - accuracy: 0.9175 - val_loss: 0.6305 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2531 - accuracy: 0.9212 - val_loss: 0.6270 - val_accuracy: 0.7750\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2178 - accuracy: 0.9413 - val_loss: 0.6387 - val_accuracy: 0.7700\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2090 - accuracy: 0.9450 - val_loss: 0.6093 - val_accuracy: 0.8000\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 0.6093 - accuracy: 0.8000\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.2436 - accuracy: 0.9275 - val_loss: 0.6007 - val_accuracy: 0.8050\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.2043 - accuracy: 0.9325 - val_loss: 0.5874 - val_accuracy: 0.8000\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1522 - accuracy: 0.9513 - val_loss: 0.6090 - val_accuracy: 0.8200\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1036 - accuracy: 0.9688 - val_loss: 0.6002 - val_accuracy: 0.8200\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1328 - accuracy: 0.9600 - val_loss: 0.6197 - val_accuracy: 0.8300\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1107 - accuracy: 0.9625 - val_loss: 0.6071 - val_accuracy: 0.8350\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0814 - accuracy: 0.9688 - val_loss: 0.5833 - val_accuracy: 0.8250\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0931 - accuracy: 0.9712 - val_loss: 0.6001 - val_accuracy: 0.8200\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0507 - accuracy: 0.9875 - val_loss: 0.6078 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.6632 - val_accuracy: 0.8200\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0564 - accuracy: 0.9825 - val_loss: 0.6547 - val_accuracy: 0.8200\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.6256 - val_accuracy: 0.8300\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0431 - accuracy: 0.9912 - val_loss: 0.6368 - val_accuracy: 0.8250\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0472 - accuracy: 0.9862 - val_loss: 0.6225 - val_accuracy: 0.8400\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.6379 - val_accuracy: 0.8250\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.6822 - val_accuracy: 0.8150\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0402 - accuracy: 0.9862 - val_loss: 0.6673 - val_accuracy: 0.8250\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.6928 - val_accuracy: 0.8200\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 0.6815 - val_accuracy: 0.8200\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.6260 - val_accuracy: 0.8500\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0189 - accuracy: 0.9962 - val_loss: 0.6407 - val_accuracy: 0.8300\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 2.6254 - accuracy: 0.0850\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 2.3382 - accuracy: 0.1450 - val_loss: 2.1043 - val_accuracy: 0.2850\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 2.0452 - accuracy: 0.2738 - val_loss: 1.8037 - val_accuracy: 0.5200\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.7364 - accuracy: 0.4475 - val_loss: 1.5278 - val_accuracy: 0.6300\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.5116 - accuracy: 0.5312 - val_loss: 1.2791 - val_accuracy: 0.7150\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.2753 - accuracy: 0.6200 - val_loss: 1.1375 - val_accuracy: 0.7450\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.1646 - accuracy: 0.6538 - val_loss: 1.0436 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.0245 - accuracy: 0.7013 - val_loss: 0.9273 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.9453 - accuracy: 0.7212 - val_loss: 0.8819 - val_accuracy: 0.7750\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.8496 - accuracy: 0.7487 - val_loss: 0.8064 - val_accuracy: 0.7900\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.7793 - accuracy: 0.7638 - val_loss: 0.7541 - val_accuracy: 0.7650\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.7942 - accuracy: 0.7675 - val_loss: 0.7293 - val_accuracy: 0.7800\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6798 - accuracy: 0.8112 - val_loss: 0.7009 - val_accuracy: 0.8000\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6811 - accuracy: 0.7962 - val_loss: 0.6950 - val_accuracy: 0.7650\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6429 - accuracy: 0.8000 - val_loss: 0.6970 - val_accuracy: 0.7800\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6562 - accuracy: 0.7987 - val_loss: 0.6682 - val_accuracy: 0.8100\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.6100 - accuracy: 0.8188 - val_loss: 0.6315 - val_accuracy: 0.8100\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5711 - accuracy: 0.8288 - val_loss: 0.6353 - val_accuracy: 0.7900\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5171 - accuracy: 0.8400 - val_loss: 0.6139 - val_accuracy: 0.7950\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5439 - accuracy: 0.8313 - val_loss: 0.6210 - val_accuracy: 0.8050\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4833 - accuracy: 0.8537 - val_loss: 0.6137 - val_accuracy: 0.8000\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4975 - accuracy: 0.8512 - val_loss: 0.5948 - val_accuracy: 0.8050\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4514 - accuracy: 0.8637 - val_loss: 0.6070 - val_accuracy: 0.7900\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4670 - accuracy: 0.8600 - val_loss: 0.5820 - val_accuracy: 0.8150\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4602 - accuracy: 0.8487 - val_loss: 0.5878 - val_accuracy: 0.8150\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4014 - accuracy: 0.8763 - val_loss: 0.5739 - val_accuracy: 0.8100\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4250 - accuracy: 0.8637 - val_loss: 0.5823 - val_accuracy: 0.7900\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3992 - accuracy: 0.8825 - val_loss: 0.5728 - val_accuracy: 0.8200\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3926 - accuracy: 0.8725 - val_loss: 0.5523 - val_accuracy: 0.8100\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3868 - accuracy: 0.8863 - val_loss: 0.5394 - val_accuracy: 0.8100\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3371 - accuracy: 0.9075 - val_loss: 0.5780 - val_accuracy: 0.7900\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3607 - accuracy: 0.8900 - val_loss: 0.5495 - val_accuracy: 0.8100\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3623 - accuracy: 0.8913 - val_loss: 0.5312 - val_accuracy: 0.8000\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3280 - accuracy: 0.9062 - val_loss: 0.5414 - val_accuracy: 0.8150\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3391 - accuracy: 0.9013 - val_loss: 0.5447 - val_accuracy: 0.8150\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3379 - accuracy: 0.8963 - val_loss: 0.5499 - val_accuracy: 0.8050\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3119 - accuracy: 0.9137 - val_loss: 0.5386 - val_accuracy: 0.8200\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2887 - accuracy: 0.9175 - val_loss: 0.6078 - val_accuracy: 0.7950\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2936 - accuracy: 0.9250 - val_loss: 0.5415 - val_accuracy: 0.8200\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3154 - accuracy: 0.9038 - val_loss: 0.5416 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2730 - accuracy: 0.9337 - val_loss: 0.5288 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2550 - accuracy: 0.9287 - val_loss: 0.5496 - val_accuracy: 0.8050\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2866 - accuracy: 0.9187 - val_loss: 0.5264 - val_accuracy: 0.8300\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2908 - accuracy: 0.9150 - val_loss: 0.5287 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2368 - accuracy: 0.9312 - val_loss: 0.5355 - val_accuracy: 0.8250\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2598 - accuracy: 0.9300 - val_loss: 0.5472 - val_accuracy: 0.8150\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2437 - accuracy: 0.9312 - val_loss: 0.5303 - val_accuracy: 0.8150\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2593 - accuracy: 0.9200 - val_loss: 0.5260 - val_accuracy: 0.8250\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2659 - accuracy: 0.9212 - val_loss: 0.5035 - val_accuracy: 0.8400\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2439 - accuracy: 0.9375 - val_loss: 0.5303 - val_accuracy: 0.8200\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2522 - accuracy: 0.9212 - val_loss: 0.5440 - val_accuracy: 0.8100\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 0.5440 - accuracy: 0.8100\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 100ms/step - loss: 0.2322 - accuracy: 0.9225 - val_loss: 0.4932 - val_accuracy: 0.8200\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1952 - accuracy: 0.9438 - val_loss: 0.5372 - val_accuracy: 0.8150\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1461 - accuracy: 0.9550 - val_loss: 0.5178 - val_accuracy: 0.8300\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1338 - accuracy: 0.9613 - val_loss: 0.5160 - val_accuracy: 0.8300\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1207 - accuracy: 0.9600 - val_loss: 0.5198 - val_accuracy: 0.8050\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0951 - accuracy: 0.9688 - val_loss: 0.5020 - val_accuracy: 0.8350\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0659 - accuracy: 0.9812 - val_loss: 0.5273 - val_accuracy: 0.8300\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0844 - accuracy: 0.9762 - val_loss: 0.5110 - val_accuracy: 0.8450\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0757 - accuracy: 0.9762 - val_loss: 0.5452 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0612 - accuracy: 0.9775 - val_loss: 0.5181 - val_accuracy: 0.8400\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0643 - accuracy: 0.9812 - val_loss: 0.5714 - val_accuracy: 0.8350\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0490 - accuracy: 0.9887 - val_loss: 0.5177 - val_accuracy: 0.8450\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.5630 - val_accuracy: 0.8300\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0433 - accuracy: 0.9850 - val_loss: 0.5583 - val_accuracy: 0.8200\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0408 - accuracy: 0.9887 - val_loss: 0.5760 - val_accuracy: 0.8450\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0426 - accuracy: 0.9875 - val_loss: 0.5832 - val_accuracy: 0.8650\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0250 - accuracy: 0.9950 - val_loss: 0.6486 - val_accuracy: 0.8350\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0334 - accuracy: 0.9925 - val_loss: 0.5971 - val_accuracy: 0.8550\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.6169 - val_accuracy: 0.8300\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.6508 - val_accuracy: 0.8500\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 0.5982 - val_accuracy: 0.8500\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 2.3925 - accuracy: 0.1300\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 2.2966 - accuracy: 0.1775 - val_loss: 2.0132 - val_accuracy: 0.4050\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.9443 - accuracy: 0.3413 - val_loss: 1.7242 - val_accuracy: 0.5600\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.6598 - accuracy: 0.4850 - val_loss: 1.4293 - val_accuracy: 0.6700\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.4231 - accuracy: 0.5688 - val_loss: 1.2176 - val_accuracy: 0.7300\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.2427 - accuracy: 0.6175 - val_loss: 1.0393 - val_accuracy: 0.7550\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.0852 - accuracy: 0.6812 - val_loss: 0.9231 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.9799 - accuracy: 0.7025 - val_loss: 0.8345 - val_accuracy: 0.8050\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.8871 - accuracy: 0.7325 - val_loss: 0.7760 - val_accuracy: 0.8200\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.8170 - accuracy: 0.7563 - val_loss: 0.7122 - val_accuracy: 0.8200\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.7708 - accuracy: 0.7588 - val_loss: 0.7212 - val_accuracy: 0.8050\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.7507 - accuracy: 0.7725 - val_loss: 0.6496 - val_accuracy: 0.8350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.7004 - accuracy: 0.7950 - val_loss: 0.6311 - val_accuracy: 0.8450\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6533 - accuracy: 0.8138 - val_loss: 0.6166 - val_accuracy: 0.8500\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6225 - accuracy: 0.8100 - val_loss: 0.5833 - val_accuracy: 0.8450\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5726 - accuracy: 0.8325 - val_loss: 0.5832 - val_accuracy: 0.8450\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5492 - accuracy: 0.8450 - val_loss: 0.5753 - val_accuracy: 0.8400\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5842 - accuracy: 0.8238 - val_loss: 0.5791 - val_accuracy: 0.8250\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5387 - accuracy: 0.8325 - val_loss: 0.5498 - val_accuracy: 0.8500\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5185 - accuracy: 0.8537 - val_loss: 0.5458 - val_accuracy: 0.8300\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4879 - accuracy: 0.8675 - val_loss: 0.5323 - val_accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4457 - accuracy: 0.8637 - val_loss: 0.5248 - val_accuracy: 0.8500\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4274 - accuracy: 0.8813 - val_loss: 0.5266 - val_accuracy: 0.8450\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4804 - accuracy: 0.8512 - val_loss: 0.5189 - val_accuracy: 0.8400\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4116 - accuracy: 0.8863 - val_loss: 0.5345 - val_accuracy: 0.8400\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3997 - accuracy: 0.8825 - val_loss: 0.5048 - val_accuracy: 0.8450\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3907 - accuracy: 0.8712 - val_loss: 0.5048 - val_accuracy: 0.8450\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3884 - accuracy: 0.8737 - val_loss: 0.4940 - val_accuracy: 0.8400\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3951 - accuracy: 0.8763 - val_loss: 0.4875 - val_accuracy: 0.8550\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3625 - accuracy: 0.8875 - val_loss: 0.4994 - val_accuracy: 0.8450\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3615 - accuracy: 0.8950 - val_loss: 0.4813 - val_accuracy: 0.8550\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3742 - accuracy: 0.8963 - val_loss: 0.4863 - val_accuracy: 0.8450\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3533 - accuracy: 0.9013 - val_loss: 0.4928 - val_accuracy: 0.8450\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3385 - accuracy: 0.8988 - val_loss: 0.4958 - val_accuracy: 0.8450\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3283 - accuracy: 0.8913 - val_loss: 0.4798 - val_accuracy: 0.8500\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3142 - accuracy: 0.9000 - val_loss: 0.4781 - val_accuracy: 0.8500\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2994 - accuracy: 0.9137 - val_loss: 0.4879 - val_accuracy: 0.8400\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3226 - accuracy: 0.9062 - val_loss: 0.4824 - val_accuracy: 0.8500\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2869 - accuracy: 0.9200 - val_loss: 0.4667 - val_accuracy: 0.8550\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3023 - accuracy: 0.9137 - val_loss: 0.4826 - val_accuracy: 0.8550\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2798 - accuracy: 0.9212 - val_loss: 0.4907 - val_accuracy: 0.8450\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3223 - accuracy: 0.8975 - val_loss: 0.4665 - val_accuracy: 0.8550\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2864 - accuracy: 0.9162 - val_loss: 0.4664 - val_accuracy: 0.8500\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2808 - accuracy: 0.9212 - val_loss: 0.4907 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2821 - accuracy: 0.9187 - val_loss: 0.5102 - val_accuracy: 0.8300\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2576 - accuracy: 0.9112 - val_loss: 0.4793 - val_accuracy: 0.8550\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2568 - accuracy: 0.9237 - val_loss: 0.4749 - val_accuracy: 0.8450\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2476 - accuracy: 0.9250 - val_loss: 0.4747 - val_accuracy: 0.8600\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.2673 - accuracy: 0.9150 - val_loss: 0.4815 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2238 - accuracy: 0.9337 - val_loss: 0.4618 - val_accuracy: 0.8550\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2526 - accuracy: 0.9162 - val_loss: 0.4628 - val_accuracy: 0.8700\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 0.4628 - accuracy: 0.8700\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.2180 - accuracy: 0.9187 - val_loss: 0.4647 - val_accuracy: 0.8550\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.2104 - accuracy: 0.9337 - val_loss: 0.4505 - val_accuracy: 0.8650\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1470 - accuracy: 0.9588 - val_loss: 0.4674 - val_accuracy: 0.8650\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1435 - accuracy: 0.9588 - val_loss: 0.4502 - val_accuracy: 0.8600\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1136 - accuracy: 0.9712 - val_loss: 0.4925 - val_accuracy: 0.8550\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1023 - accuracy: 0.9725 - val_loss: 0.4534 - val_accuracy: 0.8650\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0927 - accuracy: 0.9762 - val_loss: 0.4745 - val_accuracy: 0.8700\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0686 - accuracy: 0.9787 - val_loss: 0.4975 - val_accuracy: 0.8750\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.4699 - val_accuracy: 0.8600\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0593 - accuracy: 0.9862 - val_loss: 0.5111 - val_accuracy: 0.8650\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0611 - accuracy: 0.9862 - val_loss: 0.4845 - val_accuracy: 0.8650\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.5309 - val_accuracy: 0.8700\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0424 - accuracy: 0.9900 - val_loss: 0.4885 - val_accuracy: 0.8550\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0429 - accuracy: 0.9800 - val_loss: 0.5461 - val_accuracy: 0.8650\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.5602 - val_accuracy: 0.8750\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0425 - accuracy: 0.9887 - val_loss: 0.5648 - val_accuracy: 0.8600\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0362 - accuracy: 0.9925 - val_loss: 0.5748 - val_accuracy: 0.8750\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.5872 - val_accuracy: 0.8700\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0397 - accuracy: 0.9850 - val_loss: 0.6032 - val_accuracy: 0.8600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.6081 - val_accuracy: 0.8750\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 0.5743 - val_accuracy: 0.8750\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 2.6036 - accuracy: 0.0950\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 2.3424 - accuracy: 0.1637 - val_loss: 2.0393 - val_accuracy: 0.3550\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.9227 - accuracy: 0.3675 - val_loss: 1.7104 - val_accuracy: 0.5550\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.6541 - accuracy: 0.4500 - val_loss: 1.4355 - val_accuracy: 0.6500\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.3706 - accuracy: 0.6037 - val_loss: 1.2137 - val_accuracy: 0.6950\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 1.2133 - accuracy: 0.6450 - val_loss: 1.0588 - val_accuracy: 0.7700\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.0519 - accuracy: 0.7063 - val_loss: 0.9256 - val_accuracy: 0.8000\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.9891 - accuracy: 0.7013 - val_loss: 0.8775 - val_accuracy: 0.7850\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.9000 - accuracy: 0.7387 - val_loss: 0.8044 - val_accuracy: 0.7900\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.8373 - accuracy: 0.7588 - val_loss: 0.7409 - val_accuracy: 0.7950\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.7604 - accuracy: 0.7550 - val_loss: 0.7322 - val_accuracy: 0.7900\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.7096 - accuracy: 0.7887 - val_loss: 0.6955 - val_accuracy: 0.8100\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.6503 - accuracy: 0.7925 - val_loss: 0.6629 - val_accuracy: 0.8050\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6614 - accuracy: 0.7850 - val_loss: 0.6593 - val_accuracy: 0.8300\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.6052 - accuracy: 0.8163 - val_loss: 0.6232 - val_accuracy: 0.8450\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5942 - accuracy: 0.8188 - val_loss: 0.6440 - val_accuracy: 0.8200\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5559 - accuracy: 0.8413 - val_loss: 0.5979 - val_accuracy: 0.8350\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5602 - accuracy: 0.8275 - val_loss: 0.6363 - val_accuracy: 0.8000\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.5200 - accuracy: 0.8537 - val_loss: 0.5991 - val_accuracy: 0.8200\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4519 - accuracy: 0.8600 - val_loss: 0.6290 - val_accuracy: 0.8400\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4709 - accuracy: 0.8562 - val_loss: 0.5879 - val_accuracy: 0.8150\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4527 - accuracy: 0.8587 - val_loss: 0.6045 - val_accuracy: 0.8300\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.4547 - accuracy: 0.8625 - val_loss: 0.5934 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4207 - accuracy: 0.8800 - val_loss: 0.5692 - val_accuracy: 0.8200\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3845 - accuracy: 0.8875 - val_loss: 0.5842 - val_accuracy: 0.8250\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4215 - accuracy: 0.8712 - val_loss: 0.5666 - val_accuracy: 0.8200\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3742 - accuracy: 0.9025 - val_loss: 0.5529 - val_accuracy: 0.8050\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3922 - accuracy: 0.8800 - val_loss: 0.5868 - val_accuracy: 0.8150\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3733 - accuracy: 0.8950 - val_loss: 0.5459 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4091 - accuracy: 0.8687 - val_loss: 0.5684 - val_accuracy: 0.8350\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3197 - accuracy: 0.9087 - val_loss: 0.5836 - val_accuracy: 0.8200\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3532 - accuracy: 0.8863 - val_loss: 0.5669 - val_accuracy: 0.8150\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3410 - accuracy: 0.8988 - val_loss: 0.5560 - val_accuracy: 0.8250\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3402 - accuracy: 0.8925 - val_loss: 0.5810 - val_accuracy: 0.8150\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2726 - accuracy: 0.9200 - val_loss: 0.5646 - val_accuracy: 0.8200\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2997 - accuracy: 0.9150 - val_loss: 0.5726 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3073 - accuracy: 0.9200 - val_loss: 0.5758 - val_accuracy: 0.8100\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2866 - accuracy: 0.9050 - val_loss: 0.5910 - val_accuracy: 0.8000\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3059 - accuracy: 0.9062 - val_loss: 0.5714 - val_accuracy: 0.8150\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2807 - accuracy: 0.9100 - val_loss: 0.5882 - val_accuracy: 0.8100\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2649 - accuracy: 0.9212 - val_loss: 0.5483 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.2535 - accuracy: 0.9400 - val_loss: 0.5504 - val_accuracy: 0.8100\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2721 - accuracy: 0.9250 - val_loss: 0.5765 - val_accuracy: 0.8150\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2500 - accuracy: 0.9212 - val_loss: 0.5411 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2757 - accuracy: 0.9137 - val_loss: 0.5590 - val_accuracy: 0.8200\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2302 - accuracy: 0.9287 - val_loss: 0.5548 - val_accuracy: 0.8250\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2530 - accuracy: 0.9262 - val_loss: 0.5867 - val_accuracy: 0.8100\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2256 - accuracy: 0.9375 - val_loss: 0.5887 - val_accuracy: 0.7850\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2369 - accuracy: 0.9275 - val_loss: 0.5720 - val_accuracy: 0.8100\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2324 - accuracy: 0.9400 - val_loss: 0.5719 - val_accuracy: 0.8200\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2177 - accuracy: 0.9375 - val_loss: 0.5675 - val_accuracy: 0.8200\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 0.5675 - accuracy: 0.8200\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.2211 - accuracy: 0.9200 - val_loss: 0.5676 - val_accuracy: 0.8250\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1669 - accuracy: 0.9425 - val_loss: 0.5651 - val_accuracy: 0.8450\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1498 - accuracy: 0.9475 - val_loss: 0.6076 - val_accuracy: 0.8300\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1254 - accuracy: 0.9638 - val_loss: 0.5941 - val_accuracy: 0.8350\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1111 - accuracy: 0.9613 - val_loss: 0.6227 - val_accuracy: 0.8250\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1135 - accuracy: 0.9613 - val_loss: 0.6206 - val_accuracy: 0.8400\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0971 - accuracy: 0.9688 - val_loss: 0.6350 - val_accuracy: 0.8350\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0583 - accuracy: 0.9812 - val_loss: 0.6881 - val_accuracy: 0.8400\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0491 - accuracy: 0.9887 - val_loss: 0.7116 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.7058 - val_accuracy: 0.8350\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0585 - accuracy: 0.9825 - val_loss: 0.7528 - val_accuracy: 0.8300\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 0.7477 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.7647 - val_accuracy: 0.8300\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0384 - accuracy: 0.9850 - val_loss: 0.7724 - val_accuracy: 0.8350\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.8308 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0327 - accuracy: 0.9875 - val_loss: 0.7628 - val_accuracy: 0.8350\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.8325 - val_accuracy: 0.8350\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.7993 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.8141 - val_accuracy: 0.8450\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.7770 - val_accuracy: 0.8550\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0293 - accuracy: 0.9925 - val_loss: 0.7648 - val_accuracy: 0.8600\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 1s 44ms/step - loss: 2.4526 - accuracy: 0.0750\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 2.2752 - accuracy: 0.1488 - val_loss: 2.0969 - val_accuracy: 0.2750\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 1.9001 - accuracy: 0.3562 - val_loss: 1.7818 - val_accuracy: 0.5200\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.6408 - accuracy: 0.4900 - val_loss: 1.5076 - val_accuracy: 0.6450\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.3817 - accuracy: 0.5888 - val_loss: 1.2892 - val_accuracy: 0.6800\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 1.1966 - accuracy: 0.6463 - val_loss: 1.1317 - val_accuracy: 0.7200\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 1.0229 - accuracy: 0.7113 - val_loss: 1.0101 - val_accuracy: 0.7750\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.9192 - accuracy: 0.7312 - val_loss: 0.9397 - val_accuracy: 0.7600\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.8333 - accuracy: 0.7588 - val_loss: 0.9060 - val_accuracy: 0.7600\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.7535 - accuracy: 0.7825 - val_loss: 0.8665 - val_accuracy: 0.7800\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.7376 - accuracy: 0.7775 - val_loss: 0.8167 - val_accuracy: 0.7900\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.7387 - accuracy: 0.7788 - val_loss: 0.7780 - val_accuracy: 0.7950\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6504 - accuracy: 0.8112 - val_loss: 0.7570 - val_accuracy: 0.8100\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.6447 - accuracy: 0.8012 - val_loss: 0.7732 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.5945 - accuracy: 0.8238 - val_loss: 0.7057 - val_accuracy: 0.8100\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.5638 - accuracy: 0.8325 - val_loss: 0.7137 - val_accuracy: 0.8000\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5542 - accuracy: 0.8288 - val_loss: 0.6767 - val_accuracy: 0.8150\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.5099 - accuracy: 0.8600 - val_loss: 0.6512 - val_accuracy: 0.8450\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4929 - accuracy: 0.8575 - val_loss: 0.6878 - val_accuracy: 0.7900\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.5037 - accuracy: 0.8425 - val_loss: 0.6713 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4661 - accuracy: 0.8675 - val_loss: 0.6386 - val_accuracy: 0.8150\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.4664 - accuracy: 0.8625 - val_loss: 0.6534 - val_accuracy: 0.8050\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4539 - accuracy: 0.8612 - val_loss: 0.6565 - val_accuracy: 0.7950\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4000 - accuracy: 0.8825 - val_loss: 0.6085 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4118 - accuracy: 0.8825 - val_loss: 0.6397 - val_accuracy: 0.7800\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4525 - accuracy: 0.8650 - val_loss: 0.6562 - val_accuracy: 0.8000\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.4027 - accuracy: 0.8850 - val_loss: 0.6386 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.3292 - accuracy: 0.9000 - val_loss: 0.6217 - val_accuracy: 0.8300\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3348 - accuracy: 0.8925 - val_loss: 0.6301 - val_accuracy: 0.7950\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3718 - accuracy: 0.8925 - val_loss: 0.6324 - val_accuracy: 0.7900\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 3s 65ms/step - loss: 0.3577 - accuracy: 0.8925 - val_loss: 0.6495 - val_accuracy: 0.7950\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3640 - accuracy: 0.8875 - val_loss: 0.6250 - val_accuracy: 0.8050\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3223 - accuracy: 0.9000 - val_loss: 0.6170 - val_accuracy: 0.8050\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3209 - accuracy: 0.9038 - val_loss: 0.5985 - val_accuracy: 0.8500\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.3022 - accuracy: 0.9087 - val_loss: 0.6057 - val_accuracy: 0.8250\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2993 - accuracy: 0.9137 - val_loss: 0.6078 - val_accuracy: 0.8150\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.3126 - accuracy: 0.8913 - val_loss: 0.6089 - val_accuracy: 0.8050\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2742 - accuracy: 0.9287 - val_loss: 0.6120 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2909 - accuracy: 0.9087 - val_loss: 0.6073 - val_accuracy: 0.8250\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2622 - accuracy: 0.9250 - val_loss: 0.5849 - val_accuracy: 0.8250\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2762 - accuracy: 0.9300 - val_loss: 0.5787 - val_accuracy: 0.8300\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2448 - accuracy: 0.9362 - val_loss: 0.6097 - val_accuracy: 0.8200\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2583 - accuracy: 0.9287 - val_loss: 0.6503 - val_accuracy: 0.7800\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2296 - accuracy: 0.9413 - val_loss: 0.6194 - val_accuracy: 0.8100\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2551 - accuracy: 0.9325 - val_loss: 0.6592 - val_accuracy: 0.7950\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2605 - accuracy: 0.9275 - val_loss: 0.6208 - val_accuracy: 0.7950\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 3s 69ms/step - loss: 0.2498 - accuracy: 0.9187 - val_loss: 0.6038 - val_accuracy: 0.8050\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2713 - accuracy: 0.9150 - val_loss: 0.6426 - val_accuracy: 0.7850\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2306 - accuracy: 0.9362 - val_loss: 0.6140 - val_accuracy: 0.8100\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 3s 67ms/step - loss: 0.2265 - accuracy: 0.9337 - val_loss: 0.6000 - val_accuracy: 0.8100\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.2499 - accuracy: 0.9262 - val_loss: 0.6443 - val_accuracy: 0.7900\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.6443 - accuracy: 0.7900\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Functional)    (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 22,066,346\n",
            "Trainable params: 11,378,442\n",
            "Non-trainable params: 10,687,904\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.2136 - accuracy: 0.9400 - val_loss: 0.6033 - val_accuracy: 0.8050\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1658 - accuracy: 0.9500 - val_loss: 0.5887 - val_accuracy: 0.8200\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1584 - accuracy: 0.9525 - val_loss: 0.6033 - val_accuracy: 0.8100\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1217 - accuracy: 0.9625 - val_loss: 0.5964 - val_accuracy: 0.8200\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0971 - accuracy: 0.9737 - val_loss: 0.6228 - val_accuracy: 0.8050\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0848 - accuracy: 0.9725 - val_loss: 0.6489 - val_accuracy: 0.7900\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0773 - accuracy: 0.9725 - val_loss: 0.6108 - val_accuracy: 0.8250\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0642 - accuracy: 0.9812 - val_loss: 0.6391 - val_accuracy: 0.8100\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0476 - accuracy: 0.9875 - val_loss: 0.6277 - val_accuracy: 0.8200\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 0.6258 - val_accuracy: 0.8200\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.6610 - val_accuracy: 0.8050\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0467 - accuracy: 0.9862 - val_loss: 0.6677 - val_accuracy: 0.8000\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0430 - accuracy: 0.9875 - val_loss: 0.6198 - val_accuracy: 0.8350\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.6832 - val_accuracy: 0.8250\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.6387 - val_accuracy: 0.8250\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.7207 - val_accuracy: 0.8000\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.6640 - val_accuracy: 0.8200\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.7016 - val_accuracy: 0.8150\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0269 - accuracy: 0.9875 - val_loss: 0.7548 - val_accuracy: 0.8100\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.7125 - val_accuracy: 0.8300\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0307 - accuracy: 0.9925 - val_loss: 0.7292 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb10a219-66d7-4d2a-d13c-180ce73633ef"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.0989999994635582\n",
            "Accuracy before fine-tuning: 0.8180000066757203\n",
            "Final accuracy: 0.8600000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "da2966e5-02fd-4c69-a76e-596f31ae3400"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e2a28513-c73a-4277-8093-91a8eca2a4cf"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU5dn48e+dyb7vhCyQsEZIICyCO6CIuO+ixVa0rrVafVuXtrZaq69afdVqtf3hhlvBBaUuuFRFwRVC2JfIFiBhSwIJCdmT5/fHOYlDSMIQMplJ5v5c17mYOdvcM0zmPs9ynkeMMSillPJdfp4OQCmllGdpIlBKKR+niUAppXycJgKllPJxmgiUUsrHaSJQSikfp4lAdQkR+UhErurqfT1JRApEZLIbzvuliFxrP54uIp+6sm8nXqefiFSKiKOzsSrfoInAh9k/Es1Lk4hUOz2ffiTnMsacaYx5uav39UYicreILGxjfbyI1IlIlqvnMsa8boyZ0kVxHZS4jDHbjDHhxpjGrjh/q9cyIjKoq8+rPEMTgQ+zfyTCjTHhwDbgXKd1rzfvJyL+novSK70GnCAiGa3WXw6sMsas9kBMSnWaJgJ1CBGZKCKFInKXiOwCXhKRGBH5QESKRWSf/TjV6Rjn6o4ZIvK1iDxm77tFRM7s5L4ZIrJQRCpE5DMReUZEXmsnbldi/KuIfGOf71MRiXfa/nMR2SoipSLyx/Y+H2NMIfAF8PNWm34BvHK4OFrFPENEvnZ6frqIrBeRchH5ByBO2waKyBd2fCUi8rqIRNvbXgX6Ae/bJbo7RSTdvnL3t/dJFpH3RGSviGwUkeuczn2fiLwpIq/Yn80aERnb3mfQHhGJss9RbH+W94iIn71tkIh8Zb+3EhF5w14vIvKEiOwRkf0isupISlXq6GkiUO1JAmKB/sD1WN+Vl+zn/YBq4B8dHD8eyAfigb8BL4iIdGLffwOLgTjgPg798XXmSow/A64GEoFA4HcAIjIM+Kd9/mT79dr88ba97ByLiAwFcux4j/Szaj5HPPAOcA/WZ7EJONF5F+AhO75jgDSszwRjzM85uFT3tzZeYg5QaB9/CfC/InKq0/bz7H2igfdcibkNTwNRwABgAlZyvNre9lfgUyAG67N92l4/BTgFGGIfexlQ2onXVp1ljNFFF4ACYLL9eCJQBwR3sH8OsM/p+ZfAtfbjGcBGp22hgAGSjmRfrB/RBiDUaftrwGsuvqe2YrzH6fmvgI/tx38G5jhtC7M/g8ntnDsU2A+cYD9/EPhPJz+rr+3HvwC+d9pPsH64r23nvBcAy9r6P7Sfp9ufpT9W0mgEIpy2PwTMsh/fB3zmtG0YUN3BZ2uAQa3WOezPbJjTuhuAL+3HrwAzgdRWx50K/AgcB/h5+m/BFxctEaj2FBtjapqfiEioiPw/u7i/H1gIREv7PVJ2NT8wxlTZD8OPcN9kYK/TOoDt7QXsYoy7nB5XOcWU7HxuY8wBOrgqtWN6C/iFXXqZjvVD15nPqlnrGIzzcxHpIyJzRKTIPu9rWCUHVzR/lhVO67YCKU7PW382wXJk7UPxQIB93rZe406s5LbYrnq6BsAY8wVW6eMZYI+IzBSRyCN4XXWUNBGo9rQelva3wFBgvDEmEqsoD0512G6wE4gVkVCndWkd7H80Me50Prf9mnGHOeZlrGqM04EI4P2jjKN1DMLB7/d/sf5fsu3zXtnqnB0NJbwD67OMcFrXDyg6TExHogSox6oSO+Q1jDG7jDHXGWOSsUoKz4rd88gY85QxZgxWSWQIcEcXxqUOQxOBclUEVl13mYjEAve6+wWNMVuBXOA+EQkUkeOBc90U49vAOSJykogEAvdz+L+PRUAZVnXHHGNM3VHG8SEwXEQusq/Eb8WqImsWAVQC5SKSwqE/lrux6uYPYYzZDnwLPCQiwSIyAvglVqmiswLtcwWLSLC97k3gQRGJEJH+wP80v4aIXOrUaL4PK3E1icixIjJeRAKAA0AN0HQUcakjpIlAuepJIATrqu974ONuet3pwPFY1TQPAG8Ate3s2+kYjTFrgJuxGnt3Yv1QFR7mGINVHdTf/veo4jDGlACXAg9jvd/BwDdOu/wFGA2UYyWNd1qd4iHgHhEpE5HftfESV2C1G+wA3gXuNcZ85kps7ViDlfCal6uBW7B+zDcDX2N9ni/a+x8L/CAilViN0b8xxmwGIoHnsD7zrVjv/dGjiEsdIbEba5TqEewuh+uNMW4vkSjlK7REoLyaXW0wUET8RGQqcD4wz9NxKdWb6B2jytslYVWBxGFV1dxkjFnm2ZCU6l20akgppXycVg0ppZSP63FVQ/Hx8SY9Pd3TYSilVI+ydOnSEmNMQlvb3JYIRCQNq0tdH6z+wjONMX9vtc9E4D/AFnvVO8aY+zs6b3p6Orm5uV0fsFJK9WIisrW9be4sETQAvzXG5Nl3My4Vkf8aY9a22m+RMeYcN8ahlFKqA25rIzDG7DTG5NmPK4B1HDyuiVJKKS/QLY3FIpIOjAJ+aGPz8SKyQqzpC4e3c/z1IpIrIrnFxcVujFQppXyP2xuLRSQcmAvcZozZ32pzHtDfGFMpImdh3Sg0uPU5jDEzscZzYezYsdrfVamjVF9fT2FhITU1NYffWfUowcHBpKamEhAQ4PIxbk0E9iBSc4HXjTGtx0XBOTEYY+aLyLMiEm+PuaKUcpPCwkIiIiJIT0+n/fmCVE9jjKG0tJTCwkIyMlrPpNo+t1UN2UPovgCsM8Y83s4+Sc0zUYnIODsenZlIKTerqakhLi5Ok0AvIyLExcUdcUnPnSWCE7Gm8lslIsvtdX/AGp8cY8y/sKbLu0lEGrBGL7zc6K3OSnULTQK9U2f+X92WCIwxX3OYiTiMMf+gc/OiKqU8bOeBnQD0Devr4UjU0dIhJpRSnVLTUENNQ+cam0tLS8nJySEnJ4ekpCRSUlJantfV1XV4bG5uLrfeeuthX+OEE07oVGytffnll5xzTu++1anHDTGhlOr54uLiWL7cqjG+7777CA8P53e/+2kunYaGBvz92/55Gjt2LGPHjj3sa3z77bddE6wP0BKBUsorzJgxgxtvvJHx48dz5513snjxYo4//nhGjRrFCSecQH5+PnDwFfp9993HNddcw8SJExkwYABPPfVUy/nCw8Nb9p84cSKXXHIJmZmZTJ8+neamyPnz55OZmcmYMWO49dZbj+jKf/bs2WRnZ5OVlcVdd90FQGNjIzNmzCArK4vs7GyeeOIJAJ566imGDRvGiBEjuPzyy4/+w+piWiJQysf95f01rN3R+hafw6tptKqFgh27Dtk2LDmSe89t8/7QDhUWFvLtt9/icDjYv38/ixYtwt/fn88++4w//OEPzJ0795Bj1q9fz4IFC6ioqGDo0KHcdNNNh/ShX7ZsGWvWrCE5OZkTTzyRb775hrFjx3LDDTewcOFCMjIyuOKKK1yOc8eOHdx1110sXbqUmJgYpkyZwrx580hLS6OoqIjVq1cDUFZWBsDDDz/Mli1bCAoKalnnTbREoJTyGpdeeikOhwOA8vJyLr30UrKysrj99ttZs2ZNm8ecffbZBAUFER8fT2JiIrt37z5kn3HjxpGamoqfnx85OTkUFBSwfv16BgwY0NLf/kgSwZIlS5g4cSIJCQn4+/szffp0Fi5cyIABA9i8eTO33HILH3/8MZGRkQCMGDGC6dOn89prr7Vb5eVJ3heRUqpbdebKHWBLuTVocEaU6zcuHU5YWFjL4z/96U9MmjSJd999l4KCAiZOnNjmMUFBQS2PHQ4HDQ0NndqnK8TExLBixQo++eQT/vWvf/Hmm2/y4osv8uGHH7Jw4ULef/99HnzwQVatWuVVCUFLBEopr1ReXk5KijVO5axZs7r8/EOHDmXz5s0UFBQA8MYbb7h87Lhx4/jqq68oKSmhsbGR2bNnM2HCBEpKSmhqauLiiy/mgQceIC8vj6amJrZv386kSZN45JFHKC8vp7Kyssvfz9HwnpSklFJO7rzzTq666ioeeOABzj777C4/f0hICM8++yxTp04lLCyMY489tt19P//8c1JTU1uev/XWWzz88MNMmjQJYwxnn302559/PitWrODqq6+mqakJgIceeojGxkauvPJKysvLMcZw6623Eh0d3eXv52j0uDmLx44dazozMc26nft5J6+QW04bTGSw64MxKdUbrVu3jmOOOeaozuGOqqHuVllZSXh4OMYYbr75ZgYPHsztt9/u6bCOWlv/vyKy1BjTZr9bn6kaKtpXzXOLtrBxj3cVyZRSnvPcc8+Rk5PD8OHDKS8v54YbbvB0SB7hM1VDAxOtPsWb9lQyul+Mh6NRSnmD22+/vVeUAI6Wz5QI0mJCCHT4san4gKdDUUopr+IzicDf4Ud6fCibirVqSCmlnPlMIgAYmBCuiUAppVrxuUSwrbSK+sYmT4eilFJew7cSQWIYDU2GraVVng5FKZ82adIkPvnkk4PWPfnkk9x0003tHjNx4kSau46fddZZbY7Zc9999/HYY491+Nrz5s1j7dq1Lc///Oc/89lnnx1J+G3qycNV+1YiSLB6DmkXUqU864orrmDOnDkHrZszZ47L4/3Mnz+/0zdltU4E999/P5MnT+7UuXoLn0oEA+xEoO0ESnnWJZdcwocfftgyCU1BQQE7duzg5JNP5qabbmLs2LEMHz6ce++9t83j09PTKSkpAeDBBx9kyJAhnHTSSS1DVYN1j8Cxxx7LyJEjufjii6mqquLbb7/lvffe44477iAnJ4dNmzYxY8YM3n77bcC6g3jUqFFkZ2dzzTXXUFtb2/J69957L6NHjyY7O5v169e7/F57wnDVPnMfAUB4kD9JkcGaCJRy9tHdsGvVER+W1FhtPXCEtLExG858uN1jY2NjGTduHB999BHnn38+c+bM4bLLLkNEePDBB4mNjaWxsZHTTjuNlStXMmLEiDbPs3TpUubMmcPy5ctpaGhg9OjRjBkzBoCLLrqI6667DoB77rmHF154gVtuuYXzzjuPc845h0suueSgc9XU1DBjxgw+//xzhgwZwi9+8Qv++c9/cttttwEQHx9PXl4ezz77LI899hjPP//8YT+jnjJctU+VCMBqJ9B7CZTyPOfqIedqoTfffJPRo0czatQo1qxZc1A1TmuLFi3iwgsvJDQ0lMjISM4777yWbatXr+bkk08mOzub119/vd1hrJvl5+eTkZHBkCFDALjqqqtYuHBhy/aLLroIgDFjxrQMVHc4PWW4ap8qEYDVTvBuXhHGGETE0+Eo5XkdXLl3ZNdRjjV0/vnnc/vtt5OXl0dVVRVjxoxhy5YtPPbYYyxZsoSYmBhmzJhBTU3n5kWeMWMG8+bNY+TIkcyaNYsvv/yyU+dp1jyUdVcMY+1tw1X7XokgIZyK2gaKK2o9HYpSPi08PJxJkyZxzTXXtJQG9u/fT1hYGFFRUezevZuPPvqow3OccsopzJs3j+rqaioqKnj//fdbtlVUVNC3b1/q6+t5/fXXW9ZHRERQUVFxyLmGDh1KQUEBGzduBODVV19lwoQJR/Uee8pw1T5ZIgDYWFxJYmSwh6NRyrddccUVXHjhhS1VRCNHjmTUqFFkZmaSlpbGiSee2OHxo0ePZtq0aYwcOZLExMSDhpL+61//yvjx40lISGD8+PEtP/6XX3451113HU899VRLIzFAcHAwL730EpdeeikNDQ0ce+yx3HjjjUf0fnrqcNU+Mwx1s13lNRz30Of89YIsfn5c/y6MTKmeQ4eh7t10GOrD6BMZRFigg016L4FSSgE+mAhEhIGJOuaQUko187lEAPbgc1oiUEopwGcTQRg7yms4UHt0XcCUUqo38J1EkP8R/F8mlBe19BzaUqI3limllO8kguBoqNgJu1f/NG2lthMopZT7EoGIpInIAhFZKyJrROQ3bewjIvKUiGwUkZUiMtpd8dBnuPXvrpX0jwvFT9B2AqU86MEHH2T48OGMGDGCnJwcfvjhB8Aajrqq6siHip81axY7duxoc9uMGTPIyMggJyeHnJwcnnrqqS4ZfnrVqlUt54yNjW15jc6MZtre0NrdwZ03lDUAvzXG5IlIBLBURP5rjHEeOORMYLC9jAf+af/b9YIjISYddq0iyN9Bv9hQHXNIKQ/57rvv+OCDD8jLyyMoKIiSkpKWkUiffPJJrrzySkJDQ10+X2NjI7NmzSIrK4vk5OQ293n00UcPGWjuaGVnZ7N8+XLASjZtDWbnqvnz53dlaEfEbSUCY8xOY0ye/bgCWAektNrtfOAVY/keiBaRvu6KiaRs2GWN9qfTVirlOTt37iQ+Pr5l/J74+HiSk5N56qmn2LFjB5MmTWLSpEkA7Q5LnZ6ezl133cXo0aOZPXs2ubm5TJ8+nZycHKqrqw8bg/Pw0+0NM33gwAGuueYaxo0bx6hRo/jPf/7j0vtznkSnpKSE9PR0wCq1XHTRRUydOpXBgwdz5513HvR+SkpKKCgo4JhjjuG6665j+PDhTJkypeX9LFmypKUEdccdd5CVleVSPIfTLUNMiEg6MAr4odWmFGC70/NCe91OtwTSJxvWfQC1lQxMDGfRxhIamwwOPx18TvmuRxY/wvq9ro+v36ymwRoMLtj/0KFaMmMzuWvcXe0eO2XKFO6//36GDBnC5MmTmTZtGhMmTODWW2/l8ccfZ8GCBcTHxwN0OCx1XFwceXl5ADz//PM89thjjB3b5s2z3HHHHTzwwAOANY5Qa20NM/3ggw9y6qmn8uKLL1JWVsa4ceOYPHkyYWFhR/BJHWz58uUsW7aMoKAghg4dyi233EJaWtpB+2zYsIHZs2fz3HPPcdlllzF37lyuvPJKrr76ap577jmOP/547r777k7H0JrbG4tFJByYC9xmjNnfyXNcLyK5IpJbXFzc+WCSsgEDe9YyKCGcuoYmivYd/spBKdW1wsPDWbp0KTNnziQhIYFp06Yxa9asNvftaFjqadOmufyajz76KMuXL2f58uVkZ2cfsr2tYaY//fRTHn74YXJycpg4cSI1NTVs27bN9TfahtNOO42oqCiCg4MZNmwYW7duPWSf5rYG53jKysqoqKjg+OOPB+BnP/vZUcXhzK0lAhEJwEoCrxtj3mljlyLAORWm2usOYoyZCcwEa6yhTgeUZBejdq1kYOIgADYWV9AvzvW6SKV6m46u3DtytGMNORwOJk6cyMSJE8nOzubll19mxowZB7/GYYalPpor89baGmbaGMPcuXMZOnToEZ3L39+/ZUC51sNoN79O69fqaB9XqrqOhjt7DQnwArDOGPN4O7u9B/zC7j10HFBujHFPtRBAVBoER8Gu1QyI1/mLlfKU/Px8NmzY0PJ8+fLl9O9vDQLpPEz0kQxL3d7w0kfjjDPO4Omnn6Z5cM5ly5a5dFx6ejpLly4FOGiE06MRHR1NRERES++q1nM+Hw13lghOBH4OrBKR5fa6PwD9AIwx/wLmA2cBG4Eq4Go3xgMikDQCdq0iJiyQPpFBrNvZtV8cpdThVVZWcsstt1BWVoa/vz+DBg1i5syZAFx//fVMnTqV5ORkFixY4PKw1DNmzODGG28kJCSE7777jpCQNqbQPEJ/+tOfuO222xgxYgRNTU1kZGTwwQcfHPa43/3ud1x22WXMnDmTs88++6jjaPbCCy9w3XXX4efnx4QJE4iKiuqS8/rcMNR8dDfkvQy/L+TaV5exuaSSL347scviU6on0GGoe6bKykrCw63ajIcffpidO3fy97///ZD9dBjqw0nKhvoq2LuZkalRbC4+wP6aek9HpZRSh/Xhhx+Sk5NDVlYWixYt4p577umS8/rcDGXODcYj0k4BYHVhOScMivdgUEopdXjTpk07op5SrvK9EkFCJvj5w67VZKdY9Wsri8o9HJRS3a+nVQsr13Tm/9X3EoF/EMQPhV2riA0LJC02hJWFnhnfQylPCQ4OprS0VJNBL2OMobS0lODgI5uP3feqhsBqJ9jyFQAjUqNZvk0TgfItqampFBYWcjQ3aJZUlwBQE1JzmD1VdwoODiY1NfWIjvHRRJAFK+fAgRJGpkbx4cqdlFbWEhcedPhjleoFAgICyMg4ut4+V39s9fZ+aepLXRGS8iDfqxoCe6gJYNcqslOiAW0nUEr5Lt9MBH2cEkFqFCKwcrsmAqWUb/LNRBAWBxHJsHs14UH+DEwI1wZjpZTP8s1EAPbcBKsAGJESxcqicu1BoZTyST6cCLKg5Eeor2FEahTFFbXs2q+9H5RSvseHE0E2NDVA8XpGpFkNxiu0nUAp5YN8NxE4NRgP6xuJv59oO4FSyif5biKIHQCB4bBrJcEBDob0iWCVdiFVSvkg300Efn7QdyTssCaaGJkWxcpCbTBWSvke300EAMmjrJ5DjfWMSI2mvLqeraVVno5KKaW6lSaChhrYs5YRqdZIpCu0nUAp5WM0EQDsWMaQPhEE+fuxqlDbCZRSvsW3E0HsAGsy+6I8Ahx+DEuOZKUmAqWUj/HtRCBilQqaG4xTo1lVVE5DY5OHA1NKqe7j24kAIHk07FkL9TXkpEVTXd/Ihj2Vno5KKaW6jSaC5FHWHca7VzPSvsN4+XZtMFZK+Q5NBCmjrX+L8kiPCyUqJIAVmgiUUj5EE0FkCoQlwo48RISRadFaIlBK+RRNBK0ajHNSo/hxdwUHahs8HJhSSnUPTQRgVQ8V50NtBTn9omkysFrHHVJK+QhNBGDfWGZg50pGpmqDsVLKtxw2EYjILSIS0x3BeEzLHcZ5xIUHkRYbokNNKKV8hislgj7AEhF5U0Smioi4O6huF54IkakH3Vimk9QopXzFYROBMeYeYDDwAjAD2CAi/ysiA90cW/dKGQVFeQDkpEVTVFbNngqdulIp1fu51EZgrEH6d9lLAxADvC0if3NjbN0reRTs2wJVe8nRqSuVUj7ElTaC34jIUuBvwDdAtjHmJmAMcHEHx70oIntEZHU72yeKSLmILLeXP3fyPXSNZPvGsp3LGZ4chcNPWL59n0dDUkqp7uDvwj6xwEXGmK3OK40xTSJyTgfHzQL+AbzSwT6LjDEdnaP7JOdY/xblETLwVDKTIrREoJTyCa60EdwLxInIrXYPotFO29Z1cNxCYG/XhNkNQmKsYalbpq6MZkVhGU1NOnWlUqp3c6Vq6E/Ay0AcEA+8JCL3dNHrHy8iK0TkIxEZ3kEM14tIrojkFhcXd9FLtyF5NBTmgjHkpEZTUdPA5pID7ns9pZTyAq40Fl8JHGuMudcuHRwH/LwLXjsP6G+MGQk8Dcxrb0djzExjzFhjzNiEhIQueOl29D8BKnfB3s3k9GtuMNb7CZRSvZsriWAHEOz0PAgoOtoXNsbsN8ZU2o/nAwEiEn+05z0q6Sdb/xYsYmBCOGGBDr3DWCnV67mSCMqBNSIyS0ReAlYDZSLylIg81dkXFpGk5pvTRGScHUtpZ8/XJeIHQ3gfKPgah58wIjVa7zBWSvV6rvQaetdemn3pyolFZDYwEYgXkULgXiAAwBjzL+AS4CYRaQCqgcvt+xU8RwTST4KCr8EYRqZF88LXm6mpbyQ4wOHR0JRSyl0OmwiMMS+LSCAwxF6Vb4ypd+G4Kw6z/R9Y3Uu9S/pJsHqu1U6QFk19o2FVUTnHpsd6OjKllHILV3oNTQQ2AM8AzwI/isgpbo7Lc5zaCY4fGIfDT1iwfo9nY1JKKTdypY3g/4ApxpgJxphTgDOAJ9wblgfFDWppJ4gKCWBM/xgW5Luxy6pSSnmYK4kgwBiT3/zEGPMjdl1/r9SqneDUzETW7dzPzvJqT0emlFJu4UoiWCoiz9tjA00UkeeAXHcH5lHpJ0HFTti7mVMzEwFYsF5LBUqp3smVRHAjsBa41V7WAje5MyiPc2onGJwYTkp0CF9oO4FSqpfqsNeQiDiAFcaYTODx7gnJCzi1E8iYGZyamcjbSwu1G6lSqlfqsERgjGkE8kWkXzfF4x3aaCeorm/khy09Zww9pZRylStVQzFYdxZ/LiLvNS/uDszjmtsJSjdx/MA4ggP8tBupUqpXcuXO4j+5PQpvlG7fKlGwiOCxgzhhYDxfrN/DvecOozdO26yU8l2ulAjOMsZ85bwAZ7k7MI+LGwjhSVb1EDApM5Fte6vYVKzDUiulehdXEsHpbaw7s6sD8Tqt2gkmDbWGv9bqIaVUb9NuIhCRm0RkFTBURFY6LVuAVd0Xogeln2TNT1DyI6kxoQzpE67dSJVSvU5HJYJ/A+cC79n/Ni9jjDHTuyE2zxs8BRBYY82ZMykzkSUFe9lfc9gx95RSqsdoNxEYY8qNMQX2KKKFQD1ggHCf6U4alWKVCla9aXUjHZpIQ5Ph6w0lno5MKaW6jCujj/4a2A38F/jQXj5wc1zeY8RlULoRduQxpn8MUSEBfLx6l6ejUkqpLuNKY/FtwFBjzHBjTLa9jHB3YF7jmPPAEQgr38Lf4ce5I/vyyZpdWj2klOo1XEkE27Gmq/RNIdEw5AxrsprGBi4Zk0ZtQxPzV+70dGRKKdUlXEkEm4EvReT3IvI/zYu7A/MqI6bBgT2w5UtGpkYxMCGMt5cWejoqpZTqEq4kgm1Y7QOBQITT4jsGT4HgKFj5FiLCJWPSyN26j4ISvblMKdXzuTJn8V9arxMRV4am6D38g2DY+bD6Hair4sJRKTz6yXreySvkf6YM9XR0Sil1VDq6oexrp8evttq82G0Reavsy6CuEvLnkxQVzEmDE5ibV0RTk/F0ZEopdVQ6qhoKc3qc1Wqb74261v9EiEyBlW8CcPHoFIrKqvl+S6mHA1NKqaPTUSIw7Txu63nv5+cH2ZfAps/hQClnDE8iIshfG42VUj1eR4kgWkQuFJGL7ccX2cvFQFQ3xeddsi+DpgZYPZfgAAfnjOzLx6t3caC2wdORKaVUp3WUCL4CzgPOsR83jzV0DrDQ/aF5oaQsSB4F3z9j31OQSlVdI/NX6T0FSqmeq93eP8aYq7szkB7jlDtgzs9g1ZuMHnkFGfFhvLW0kEvHpnk6MqWU6hRX7iNQzoaeBX2yYeFjSFMj08f3Y/GWvXyzUQeiU0r1TJoIjpQITLgT9m6CNe9w5XH9SYkO4QgqXk8AACAASURBVMEP19GoXUmVUj2QJoLOyDwHEofBV38j2AF3nZnJ2p37eXdZkacjU0qpI+bKMNSXikiE/fgeEXlHREa7PzQv5udnlQpKN8Cadzl3RF9GpkXz2Cf5VNc1ejo6pZQ6Iq6UCP5kjKkQkZOAycALwD8Pd5CIvCgie0RkdTvbRUSeEpGN9hSYPSu5HHM+JGTCwkcRY7jn7GPYtb+G5xdt9nRkSil1RFxJBM2XuGcDM40xH2INQHc4s4CpHWw/ExhsL9fjQnLxKn5+Vg+i4vWw7j8cmx7L1OFJ/POrTeypqPF0dEop5TJXEkGRiPw/YBowX0SCXDnOGLMQ2NvBLucDrxjL91g3rfV1JWivMfxCiB8CXz4MDXXcdWYmdQ1NPPHfDZ6OTCmlXOZKIrgM+AQ4wxhTBsQCd3TBa6dgTXrTrNBedwgRuV5EckUkt7i4uAteuov4OeD0+61SwaLHyIgP48rj+vPGkm2s37Xf09EppZRLXEkEfYEPjTEbRGQicCndPPqoMWamMWasMWZsQkJCd7704Q09E0ZcDov+D3Ys5zenDSYqJIA/zVuNMdqdVCnl/VxJBHOBRhEZBMwE0oB/d8FrF9nnapZqr+t5znwYQuNh3q+ICYK7z8xkScE+5ub1zLejlPItriSCJmNMA3AR8LQx5g6sUsLReg/4hd176Dig3BjTMwftCYmBc/8Oe9bAwr9x6Zg0RveL5qH56yirqvN0dEop1SFXEkG9iFwB/AL4wF4XcLiDRGQ28B0wVEQKReSXInKjiNxo7zIfaz7kjcBzwK+OOHpvMnQqjPwZLHocv53LeOCCbPZV1fHoJ/mejkwppTrkypSTVwM3Ag8aY7aISAbQesayQxhjrjjMdgPc7FKUPcXUh2DzApj3K4Zd/yUzTsjgpW+3cNnYNEamRXs6OqWUapMr3UDXAr8DVolIFlBojHnE7ZH1RCHRcN7TULwO5lzB7RNTSAgP4p55q3UcIqWU13JliImJwAbgGeBZ4EcROcXNcfVcg0+H85+BTQuImDud+6b2Z1VROa98V+DpyJRSqk2uVA39HzDFGJMPICJDgNnAGHcG1qONuhIcQfDuDZzZ+GvOHHw3D320nmPTY8lK8c3J3ZRS3suVxuKA5iQAYIz5ERcai33eiEvhkheRolyebrif/iF13PzvPPbX1Hs6MqWUOogriWCpiDwvIhPt5Tkg192B9QrDL4Bpr+G/ZzXzIh+jbF8pd89dqTeaKaW8iiuJ4EZgLXCrvawFbnJnUL3K0DPhslcJ27eWjxP+wRertvLytwWejkoppVp02EYgIg5ghTEmE3i8e0LqhYZOhYtmkjT3Wt6OeYZp829lVL8Y7VKqlPIKHZYIjDGNQL6I9OumeHqvrIuRc58iqzqXZ4Ke5eZXF7OpuNLTUSmllEtVQzHAGhH5XETea17cHVivNPrnMPURJjZ9z731j3Pdsx+xbNs+T0ellPJxrnQf/ZPbo/Alx90IDTVM/vx+TjTLePn5M9l/8R+ZMHKwpyNTSvmodksEIjJIRE40xnzlvGDNWFbYfSH2Qifdhty8GMfQqdzk9y4570xg5ex7oaHW05EppXxQR1VDTwJtza5Sbm9TRyN+EEFXvEz1NV+yJSSLEflPsu1vx7Nh9RJPR6aU8jEdJYI+xphVrVfa69LdFpGPCek3iuF3fMz7w54gvK6YtLfO5LWn72HV9jJPh6aU8hEdJYKO+jaGdHUgvizA4ce5l11DwK+/Y3fssVxZ+jR7Zl7AE+985enQlFI+oKNEkCsi17VeKSLXAkvdF5LviohPpf+t86mZ/BCn+K/h5hUXUvDPS2Hzl9DU5OnwlFK9VEe9hm4D3hWR6fz0wz8WCAQudHdgPkuE4JN+RWPmGXz2yv8ybtfH8MqnEDsAhl8IYQkQFAFBkdbMaP2OA4cO/aSU6rx2E4ExZjdwgohMArLs1R8aY77olsh8nCN+ICf86l9c/uyXjKxYyJ+DfyB40f8dumPicDj7Meh/QvcHqZTqFQ57H4ExZgGwoBtiUa1EBAfwz6tO5LxnDIsrJ/PuneOIkBqo2Q+1FVC8Hj67D14605om8/T7ITzB02ErpVxlDBTlwdp5UF8Nw863Lur8HN0ahis3lCkP6hcXyrPTR/OLFxZz7avLufW0wYzPSMPf4QdJWdagdgsfg2+fhvwPIetiCO8DYfFWNVLsQGs/pVT3a2qCPWth10rwCwD/IAgIARHY/JWVAMq2WdscAbDkOYjoa1UDD78IUkZ3S1KQnjYk8tixY01uru+Ngv1m7nbue28NVXWNxIcHMjUribOzkzluQCwiAsU/wqd/hMIlUN1q2IohU2HyfZB4jCdCV73U1R9fDcBLU1/ycCReZt9W2LLQ6uSx5Ss4UNz2fn7+MPBUGHYBZJ4FjkD48WNY/Q5s+BQa66y2wLTxVimh/4mQPAr8AzsVlogsNcaMbXObJoKeo7qukS/z9/DBqp18sW4P1fWNnDIkgUcuzqZvlFOP3sZ6qCq1voAb/gtfPwl1FZDzM5j4B4hKsfZraoT6KvAP1gZndcQ0EWBV7ZRvh4JvoGCRtZRts7aF94GMCTBgIqSNAwQaqq0RBBpqoc8wq8NHW6rLYONnsPUb69wl9txg466Hsx7tVKiaCHqhqroG3lyynUc+zsffIfzlvOFcOCrFKh0csvNeq/poyXPW88AwqKuCRntIC0cQJGVbVxvJo6ySQ0ColRz8g6xEERpnFWeVsvlkImhsgKJc2L4YChdDYS5U7LS2hcRYV+0Zp0D6ydbfUVf9zVQWw7ZvIbo/JOd06hSaCHqxgpID3PH2CpYU7OP0YX144IIs+kQGt73zvq2weKZ1NRIYCgFhVn1l5W7YsRx2Loe6dobGTsiEkVfAiGkQ2dd9b0j1GD0+EVSXWR0uIpMhIhkcHTSZlm2DvFdh2WtQscNaF5MOqeMgdaxVdZM4HPxcGdDZMzQR9HKNTYaXvtnC3z7Jp6nJMGV4H64Y148TB8bj53cEVyRNTVC6EUo3WMmisc5aasph3fuw/QcQPxgwySo5VO+1ShtVpVYvpoAQewm1Sh0ZEyDrImud6nV6ZCJoqLOqXFbOgfyPfyoVi8OqMo3qB2FxVt18cJS1bF9sHQMwaDKMmg79T+pxPfQ0EfiIraUHeO37rby9tJB9VfWkxYbws3H9ueqE/oQGdkEHsdJNsGI2rHgD9hdaReHQOGsJDLf+qOqrrWqn6r1WkTkkBkZdCWOvsYq1u9fAtu+tYm7xjxDTHxKGQvxQSBhi3TjXXr2p8io9IhE0NUHJj9ZFzPbFkD/f+m6GxkHWJTBwktWWtm+rddVfvt3qbFFTbi31VVZpYfTPre9xdM+do0sTgY+pbWjkkzW7mf3DNr7bXEpSZDB3nDGUC0elHFkJoT3GWEtHxWBjoOBrq11i3QdgmqxkUVdhbY9MgcRhUF5olUKa6n86NijK+oOL7mdddTkC7SXAKmmknwypx3bcra65EW/7Ytizzqra6jceotK6p62jvtrqNRIUaVUb9ML2Fa9KBBW7rYuLit1WVWflbthfBDuWWT/oYF1gDJhkVW8OOs21DhINdVbvHi+u8nFVR4lA7yPohYL8HZw3MpnzRiazpGAvf/1gLb99awUvf1fAPWcPY1xG7NG9gMjhf9hEIONka9m/E/Jesf4408ZD/+MPvrJqrId9BVZ9bfOVWdlW2LfFapBrrIemhp+qqgBCYmHwFBhyhvUHXlUKB0qgqsRKLNt++Kku11lEspUQ+ubYJZEhVl1vc1Ixxmonqa2welWZpp+WwHDrSrK9uuSGOtj0Bayea115Nre39MmG426C7Eusxnd3qq+xYihaar2vxGOs9xkU8dM+xljvr77a+lybFz+HVTXi6R+94h9h9yqIGwRxg632rLY01FndLZe/bvWOM43Wej9/CEuEiCSrP37qOOt7FzfwyBNyJ7tq9jRaIvABTU2G/6wo4m8f57OzvIaBCWGcPDiBkwbFc9zAOMKDetD1QHUZbPocfvzE6mvd+p4J8YPIVKu7Xtp460c/IROK860qqe3fW0liv9PcSo4gCE+EWvuObdPRAH9iJYPwRCsx1FdD/QGoO2BdeTbUWInpmHOtH6HyIvj+WeumorAEyL7UKiX4+Vs/vI4AKykmZFrVYq2vUuuqrCvb3ath12rr3+L1VtfEPlnWzYJ9sqwkuOZdyP/op1KXs8hU67OpLe/4PYbEQNpx1ueWdpz1Xpvqf0oWtZVWVUrlHq4ueAtMIy+N+YPrV9h1VdZnEZli/VA3/zA3NVkJ7Ptnrf9f5887pr+VEAKCreciVjLb+o11ARDeB0ZebvXHj+5nXSR4Opl5Ia0aUoB1H8IbS7axIL+YH7aUUlPfhL+fMGV4H/58znCSotrpbeStGhtgR55VSghLgNB464fMlR+B6jKr7rg43+qjfaDkp8H8gqMgKNy621PE+gFFrCv8yj1wYI+1f22FVVUVGGY1kAdF/NRv3PlK0hirmuj7Z60fu6aGtmPyC7CuWgPDrB/bA6VWkmkmDqsEkzDUimP3ait5NQuOthPQBVb1WXmhlTT2rLPeKwLBze8v0mrEdwRYr+vnb/VxL8y1EmbphsN+hFf37QPix0s7dlo/vsMvtBJdwlA7XrFes7zQ+nHf+Dls+86pVBdj9bSJH2xVI5ZugPAkOPZaGHy6XUrMt97D3k1WydAYwK6aTMyEnOkw8LSOe/woQBOBakNtQyNLt+5jwfo9vPLdVgIcftw1dSjTx/fvmnYE1T5jrGqnpgarBLFvy08/eMX5VikjPNFKbGHx1pVz4jCr1BAQfPB5yrZZCSEgxPrx76obAw+UWHep1x2wk4W/tQSEWrGFJXD1wt+CMbw04HJY9Sasn28lk/YkDrPupE0bBxW7rJLB7rXWe44baFWfDbvAZ6pjupvHEoGITAX+DjiA540xD7faPgN4FCiyV/3DGPN8R+fURND1tpYe4I/vrubrjSWM7hfN/ednMTQpggCHFq9V+w5pLK6tsKrsDpTQctUOdiPtBKu/vvIYjzQWi4gDeAY4HWuy+yUi8p4xZm2rXd8wxvzaXXGow+sfF8arvxzHu8uK+OsHaznn6a8BiA4NIC4skISIIKaP7885I/q2feeyUmBVjWVf4ukoVCe4s2JtHLDRGLMZQETmAOcDrROB8gIiwkWjU5k4NJGPVu+kpKKO0gO1lFbWkb+7gltmL+PDlTv56wVZJES4ueeLUqpbuTMRpADbnZ4XAuPb2O9iETkF+BG43RizvfUOInI9cD1Av34994aOniA2LJDp4/sftK6hsYnnv97C4//9ke+f+Iq/nDec80Yma+lAqV7C003t7wOzjTG1InID8DJwauudjDEzgZlgtRF0b4jK3+HHjRMGMvmYRH731kp+M2c5zy7YRFpsCH0ig0mKDKZfXCinD+vTNXcwK6W6lTv/aouANKfnqfzUKAyAMabU6enzwN/cGI86SoMSI5h70wm8/G0BCzcUU7ivmqVb97GvyrorODLYn8vGpvHz4/vTPy7Mw9EqpVzlzkSwBBgsIhlYCeBy4GfOO4hIX2OMPYYr5wHr3BiP6gIOP+GakzK45qSMlnU19Y2sLCznle8KmPVtAS98s4UJQxLIiA+jvrGJ+gZDfWMT/eJCufqEDKJCde4DpbyJ2xKBMaZBRH4NfILVffRFY8waEbkfyDXGvAfcKiLnAQ3AXmCGu+JR7hMc4GBcRizjMmLZvb+Gf/+wjbdyt7N06z4CHX4EOPzwdwjvLCvixa+3cMOEgcw4IZ2wnnRHs1K9mN5QprrN2h37efy/+Xy2bg/x4YFcc1IG/WPDCA10EBLoICzQn8F9wgkO6N6Ju1XneNWgc+qwdNA55RWGJUfy/FXHkrdtH499ks/fPs4/ZJ+IIH/OyErivJHJnDAwDn+9qU0pt9NEoLrd6H4x/Pu649hRVk1FTQNVdQ1U1zVSXl3Pgvw9fLR6F28vLSQ+PJCzs/ty7shkRveL0aEvlHITTQTKY5KjD5257Mzsvtx/fhZf5hfzn+VFzFmynZe/20rfqGDOGdGXycf0AWB/TQP7q+vZX1OPv58QHuxPeFAA4UH+pMeH0jdKZ0VTylWaCJTXCQ5wMDUrialZSVTWNvDZ2t28v2IHs74t4LlFWw57fIBDuOGUgfz61EHa3qCUCzQRKK8WHuTPBaNSuGBUCuVV9eRu3UtwgIPI4AAiQ/yJCA6gsclQWdtAZU0DFTX1vL20kH8s2Mj7K3fwwAVZnDzYmlt2+94qFuTvYeGPJcSGBTA1K4kTB8UT5K/JQvk2TQSqx4gKDeA0u2qoNefxj04YFM8lY1L547zV/PyFxUwYksCOsmo27LFmDOsXG8q+A3W8mVtIeJA/kzITOX1YH8ZnxNInsofNyaBUF9BEoHqlEwbF89FvTuafX27i1e+3ckzfCKYdm8apmYkMSAinrqGJbzaV8MnqXXxqVz0BpMWGcGx6LOPSY5k8rA/x4TrAnur99D4C5fMaGptYs2M/Swr2kluwj9yteymprMPhJ5w8OJ4LR6W0jKPU2GQorqhlR3k1tfVNDEuOJCrEN++U1vsIeha9j0CpDvg7/BiZFs3ItGiuPRmMMeTvruC95TuYt6yI38xZTmigg5jQQHbvr6Gh6eCLp/S4UEakRjMiNYrslCiGp0T1rHmglc/Tb6tSrYgImUmRZE6N5HdThrK4YC/vrdhBVW0DydEh9I0OISU6GIefH6uLyllZWEauvY91PGTEhzEiJYqUmBBCAhwEBzgICnAQGuAgOjSA6NAAokICiA4NJC4sUIf0Vh6liUCpDvj5CccNiOO4AXFtbp8wJKHlcXFFLauLyllVVM7KwnK+37yXPRU1NB2m9jU9LpRJmYmcltmHcRmxBPrr3dSqe2kiUKqLJEQEMSkzkUmZiS3rjDHUNxpqGhqpqW+kqta6g7q8up6y6nr27K/hm40lvP7DNl76poDwIH8ykyIIC/InLMgafykk0GGfC5qMQQT6RATTPz6M9LhQ+seFtbRTGGNapgrWO7GVqzQRKOVGIkKgvxDo70dkcABEHLrPtScPoKqugW83lvL5+j1sLT1AWVUdhfsaqKprpLq+EQA/EQQrGTTPAdHM4Sc0OSWBQIcf4zJimTg0gQlDEhiUGN5u9VNjk2HvgToqauoJDfQnItif0ECHVlf5EE0ESnmB0EB/Jg/rw+Rhbd8n0Vp1XSPb9lZRUHqAgpID7K+pxyGCiOAnQll1HV9vKOGBD9fxwIfrSI4KJiEyGJx6CVbVNbL3QB17q+po3XnQT6yb+cYPiOPyY9OYODQRh5Ywei1NBEr1QCGBDoYmRTA0qY0ihpPCfVUs/LGEbzaWUFnbAFiN2QBJUVapIS48iPjwQCKC/amua6Kytp6KmgZKD9Tx6Zrd/HftbpIig7lsbCpj02PZUVbN1r1VbNhTSX1jE3fPXcnw5EiGJUdxTN8Ina60B9L7CJRS7apvbOLzdbuZvXg7CzcUt5QcAhxCePpzBDj8qCu8gTK7qspP4NyRydx37nBiwgI9GLlqTe8jUEp1SoDDj6lZfZma1Zeismq2lVaRFhtC36gQrv30LQBevPp0dpTXsKaonB+27OWV7wr4ZmMp/3thFlOGJ3n2DSiXaCJQSrkkJTqElDaGDheRlm1Thidx8ehUfvfWCq5/dSkX5CRz33nDiQ7V0oE30w7LSqkuNSw5knk3n8hvThvMByt3MuWJhSxYv8fTYakOaCJQSnW5QH8/bj99CPNuPpGY0ECunrWE37+zsqXBWnkXTQRKKbfJSonivVtO5MYJA3ljyXamPrmQ7zeXejos1YomAqWUWwX5O7j7zEzeuvF4/P2Ey2d+z7UvL+H7zaX0tF6LvZUmAqVUtxjTP5b5vzmZ2yYPJm9bGZfP/J7zn/mG91fsoK6hydPh+TTtNaSU6jahgf7cNnkIN04YyNy8Qp5ftIVbZi8j0OHH4D7h1o1pfSPJTo0mOyVKB+DrJpoIlFLdLjjAwfTx/bni2H58+eMeftiyl7U79vPZuj28mVsIQEiAg7HpMYzPiOW4AXGM6hejw1y4iSYCpZTH+PkJp2b24dRMa4wlYwy799eybNs+ftiyl+83l/LYpz8CEB8eyBnDkzg7uy/jMmLxd2hpoatoIlBKeQ0RISkqmDOz+3Jmdl8A9h6o49tNJXy0ehfv5BXx+g/biAsLZPyAWAYnRjCkTwSD+4STHhemVUmdpIlAKeXVYsMCOWdEMueMSKa6rpEv8/fw0epdrCgs46PVu1rGPwry9+O4AXFMGJLAhKEJDIgP06G0XaSJQCnVY4QEOg4qLdTUN7KpuJINuytZvr2MhRuKuf+DtfCBNSTGwMRwUqKD6RsVQrI9PEZxRa21VNayv7qeAIc1X0SAw49gfweD+4QzNj2WYX0jfaaEoYlAKdVjBQc4GJ4cxfDkKC4YlQLA9r1VLNxQzLebStm+t4q1O/ZTUll70HFhgQ4SIoKICgmgvtFQ39hEXWMTB2obeSN3O2CVMEamRTM4MZyY0MCWeaYjggNw+Al+YrVx+IkQFuggIjiAiGBrYp+wQP8eNUOcWxOBiEwF/g44gOeNMQ+32h4EvAKMAUqBacaYAnfGpJTq3dJiQ5k+vj/Tx/dvWVdT38iu8hrAmlI0LKj9n75d5TXkbdvH0q37yN26j49W76Ksqu6wc0+3FuTvR3CAg5AAB2FBDjLiwxiYGM7AhHAGxIdRVddI4b5qisqqKNpXjZ8IWSlRjEi1ElvzFKXdwW2JQEQcwDPA6UAhsERE3jPGrHXa7ZfAPmPMIBG5HHgEmOaumJRSvik4wEF6fJhL+yZFBXNWdl/OsqufAJqaDJV1DZRX1bO/ph5jrCk+m4y1HKhtpKKmgYoaa1KfytoGahoaqa1vorrOmqd6S8kBFv5YQl3jwTfPOfyEvlHB1DU08c6yIsCa16F/nBVvbX0jdY1N1NY3cfVJGfzP6UO66FP5iTtLBOOAjcaYzQAiMgc4H3BOBOcD99mP3wb+ISJi9L5zpZQX8fMTIoMDrHmnj0Jjk2H73iq2lB4gLNCflJgQ+kQEtXSF3b2/hlWF5awsLGNT8QEcflb7RZC/H4H+foxMjeqKt3MIdyaCFGC70/NCYHx7+xhjGkSkHIgDStwYl1JKeYTDT0iPD2u3dNInMpg+w4Jdnru6q/SIJnERuV5EckUkt7i42NPhKKVUr+LORFAEpDk9T7XXtbmPiPgDUViNxgcxxsw0xow1xoxNSEhwU7hKKeWb3JkIlgCDRSRDRAKBy4H3Wu3zHnCV/fgS4AttH1BKqe7ltjYCu87/18AnWN1HXzTGrBGR+4FcY8x7wAvAqyKyEdiLlSyUUkp1I7feR2CMmQ/Mb7Xuz06Pa4BL3RmDUkqpjvWIxmKllFLuo4lAKaV8nI41pJTqlMzYTE+HoLqIJgKlVKfcNe4uT4eguohWDSmllI/TRKCUUj5OE4FSSvk4TQRKKeXjNBEopZSP00SglFI+ThOBUkr5OE0ESinl46SnjfosIsXA1k4eHk/Pmv2sJ8Xbk2KFnhVvT4oVela8PSlWOLp4+xtj2pzQpcclgqMhIrnGmLGejsNVPSnenhQr9Kx4e1Ks0LPi7Umxgvvi1aohpZTycZoIlFLKx/laIpjp6QCOUE+KtyfFCj0r3p4UK/SseHtSrOCmeH2qjUAppdShfK1EoJRSqhVNBEop5eN8JhGIyFQRyReRjSJyt6fjaU1EXhSRPSKy2mldrIj8V0Q22P/GeDLGZiKSJiILRGStiKwRkd/Y670uXhEJFpHFIrLCjvUv9voMEfnB/j68ISKBno7VmYg4RGSZiHxgP/fKeEWkQERWichyEcm113nd96CZiESLyNsisl5E1onI8d4Yr4gMtT/T5mW/iNzmrlh9IhGIiAN4BjgTGAZcISLDPBvVIWYBU1utuxv43BgzGPjcfu4NGoDfGmOGAccBN9ufpzfGWwucaowZCeQAU0XkOOAR4AljzCBgH/BLD8bYlt8A65yee3O8k4wxOU79273xe9Ds78DHxphMYCTWZ+x18Rpj8u3PNAcYA1QB7+KuWI0xvX4Bjgc+cXr+e+D3no6rjTjTgdVOz/OBvvbjvkC+p2NsJ+7/AKd7e7xAKJAHjMe6O9O/re+Hpxcg1f4jPxX4ABBvjRcoAOJbrfPK7wEQBWzB7iTj7fE6xTcF+MadsfpEiQBIAbY7PS+013m7PsaYnfbjXUAfTwbTFhFJB0YBP+Cl8drVLMuBPcB/gU1AmTGmwd7F274PTwJ3Ak328zi8N14DfCoiS0XkenudV34PgAygGHjJrnZ7XkTC8N54m10OzLYfuyVWX0kEPZ6xLgG8qq+viIQDc4HbjDH7nbd5U7zGmEZjFbFTgXFApodDapeInAPsMcYs9XQsLjrJGDMaq9r1ZhE5xXmjN30PAH9gNPBPY8wo4ACtqla8LF7stqDzgLdab+vKWH0lERQBaU7PU+113m63iPQFsP/d4+F4WohIAFYSeN0Y84692mvjBTDGlAELsKpWokXE397kTd+HE4HzRKQAmINVPfR3vDReY0yR/e8erDrscXjv96AQKDTG/GA/fxsrMXhrvGAl2DxjzG77uVti9ZVEsAQYbPe8CMQqar3n4Zhc8R5wlf34Kqy6eI8TEQFeANYZYx532uR18YpIgohE249DsNoy1mElhEvs3bwiVgBjzO+NManGmHSs7+kXxpjpeGG8IhImIhHNj7Hqslfjhd8DAGPMLmC7iAy1V50GrMVL47VdwU/VQuCuWD3dENKNDS5nAT9i1Q//0dPxtBHfbGAnUI915fJLrLrhz4ENwGdArKfjtGM9CatIuhJYbi9neWO8wAhgmR3rauDP9voBwGJgI1axO8jTsbYR+0TgA2+N145phb2saf678sbvgVPMOUCu/X2YB8R4+rfwDwAAAhNJREFUa7xAGFAKRDmtc0usOsSEUkr5OF+pGlJKKdUOTQRKKeXjNBEopZSP00SglFI+ThOBUkr5OE0ESnUjEZnYPKKoUt5CE4FSSvk4TQRKtUFErrTnMVguIv/PHriuUkSesOc1+FxEEux9c0TkexFZKSLvNo8RLyKDROQzey6EPBEZaJ8+3GlM/NftO7WV+v/t3b8rRXEYx/H3IyVSTBaDskkZDWTyDxhIkcFssUmR8j8oRmKQ4i8w3LoTBqWMpjtZJAaG62P4fum6V7mJe4fzeU3nPvd7v93vcM5zfnSep22cCMzqRMQIMA9MKhWrqwKLpDc9rySNAiVgK//kAFiTNAbc1MSPgB2lXggTpDfHIVVrXSX1xhgm1Rcya5vOn4eYFc40qRnIZT5Z7yYV93oDjvOYQ+A0IvqAfkmlHN8HTnINnkFJZwCSXgDyfBeSKvnzNakPRfn/l2X2PScCs0YB7Eta/xKM2Kwb99v6LK8121W8H1qb+daQWaNzYDYiBuCzB+8QaX/5qAC6AJQlPQIPETGV40tASdITUImImTxHV0T0tHQVZk3ymYhZHUm3EbFB6rzVQaoIu0JqZDKev7snPUeAVA54Nx/o74DlHF8C9iJiO88x18JlmDXN1UfNmhQRz5J62/0/zP6abw2ZmRWcrwjMzArOVwRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF9w6S58TenfBbAQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}