{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-xception-modified-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIVLj7cjU9JfYNxaotolrh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc33dd89-fe95-4d80-9dca-0c5da67ec9dc"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6676cd1-e81a-4b5b-db60-c2e2bba59aef"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598809f7-159e-4454-92c2-6e20ee2786c1"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac40821-2248-4d71-fd81-10c86fce89b6"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.xception.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 115"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6859e9-13f7-4c2b-c467-af975ed24aa2"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.Xception(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 2.3566 - accuracy: 0.0700\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 2.2392 - accuracy: 0.1838 - val_loss: 2.0975 - val_accuracy: 0.3600\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 8s 167ms/step - loss: 1.9321 - accuracy: 0.4625 - val_loss: 1.7997 - val_accuracy: 0.5750\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 1.6254 - accuracy: 0.6137 - val_loss: 1.5243 - val_accuracy: 0.6550\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.3577 - accuracy: 0.6837 - val_loss: 1.3020 - val_accuracy: 0.7100\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.1720 - accuracy: 0.7200 - val_loss: 1.1540 - val_accuracy: 0.7350\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 178ms/step - loss: 0.9997 - accuracy: 0.7713 - val_loss: 1.0292 - val_accuracy: 0.7300\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 181ms/step - loss: 0.9254 - accuracy: 0.7825 - val_loss: 0.9512 - val_accuracy: 0.7550\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.8027 - accuracy: 0.8050 - val_loss: 0.8866 - val_accuracy: 0.7550\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.7507 - accuracy: 0.8037 - val_loss: 0.8265 - val_accuracy: 0.7900\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6957 - accuracy: 0.8300 - val_loss: 0.7921 - val_accuracy: 0.7800\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6664 - accuracy: 0.8250 - val_loss: 0.7349 - val_accuracy: 0.7950\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.5980 - accuracy: 0.8450 - val_loss: 0.7311 - val_accuracy: 0.7700\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.5578 - accuracy: 0.8450 - val_loss: 0.6944 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5592 - accuracy: 0.8438 - val_loss: 0.6678 - val_accuracy: 0.8050\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5128 - accuracy: 0.8775 - val_loss: 0.6534 - val_accuracy: 0.8100\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.4646 - accuracy: 0.8888 - val_loss: 0.6214 - val_accuracy: 0.8300\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4755 - accuracy: 0.8775 - val_loss: 0.6141 - val_accuracy: 0.8100\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4539 - accuracy: 0.8825 - val_loss: 0.6051 - val_accuracy: 0.8100\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4412 - accuracy: 0.8775 - val_loss: 0.5940 - val_accuracy: 0.8350\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4210 - accuracy: 0.8850 - val_loss: 0.5861 - val_accuracy: 0.8250\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3960 - accuracy: 0.8950 - val_loss: 0.5897 - val_accuracy: 0.8250\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3913 - accuracy: 0.9025 - val_loss: 0.5694 - val_accuracy: 0.8200\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3730 - accuracy: 0.8913 - val_loss: 0.5573 - val_accuracy: 0.8250\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3652 - accuracy: 0.9025 - val_loss: 0.5538 - val_accuracy: 0.8250\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3565 - accuracy: 0.9100 - val_loss: 0.5466 - val_accuracy: 0.8200\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3295 - accuracy: 0.9038 - val_loss: 0.5472 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3165 - accuracy: 0.9162 - val_loss: 0.5352 - val_accuracy: 0.8300\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3256 - accuracy: 0.9050 - val_loss: 0.5290 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3180 - accuracy: 0.9200 - val_loss: 0.5431 - val_accuracy: 0.8250\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3242 - accuracy: 0.9125 - val_loss: 0.5419 - val_accuracy: 0.8200\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2720 - accuracy: 0.9312 - val_loss: 0.5368 - val_accuracy: 0.8250\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2903 - accuracy: 0.9262 - val_loss: 0.5179 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3009 - accuracy: 0.9175 - val_loss: 0.5121 - val_accuracy: 0.8450\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2683 - accuracy: 0.9337 - val_loss: 0.5225 - val_accuracy: 0.8300\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2585 - accuracy: 0.9413 - val_loss: 0.4986 - val_accuracy: 0.8600\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2631 - accuracy: 0.9312 - val_loss: 0.5315 - val_accuracy: 0.8200\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2279 - accuracy: 0.9488 - val_loss: 0.5125 - val_accuracy: 0.8500\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2376 - accuracy: 0.9275 - val_loss: 0.4965 - val_accuracy: 0.8650\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2396 - accuracy: 0.9362 - val_loss: 0.5060 - val_accuracy: 0.8250\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2344 - accuracy: 0.9350 - val_loss: 0.4987 - val_accuracy: 0.8600\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2164 - accuracy: 0.9513 - val_loss: 0.4951 - val_accuracy: 0.8650\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2115 - accuracy: 0.9488 - val_loss: 0.5145 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2349 - accuracy: 0.9350 - val_loss: 0.4979 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2176 - accuracy: 0.9325 - val_loss: 0.5043 - val_accuracy: 0.8250\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2001 - accuracy: 0.9463 - val_loss: 0.4915 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2069 - accuracy: 0.9438 - val_loss: 0.4847 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2072 - accuracy: 0.9388 - val_loss: 0.5123 - val_accuracy: 0.8250\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2015 - accuracy: 0.9563 - val_loss: 0.4883 - val_accuracy: 0.8400\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1971 - accuracy: 0.9375 - val_loss: 0.4892 - val_accuracy: 0.8650\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1906 - accuracy: 0.9463 - val_loss: 0.4819 - val_accuracy: 0.8450\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.4819 - accuracy: 0.8450\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.1665 - accuracy: 0.9500 - val_loss: 0.4988 - val_accuracy: 0.8400\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.1301 - accuracy: 0.9625 - val_loss: 0.4922 - val_accuracy: 0.8500\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.1431 - accuracy: 0.9638 - val_loss: 0.5211 - val_accuracy: 0.8350\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.1289 - accuracy: 0.9575 - val_loss: 0.5332 - val_accuracy: 0.8550\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0977 - accuracy: 0.9712 - val_loss: 0.5281 - val_accuracy: 0.8500\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1133 - accuracy: 0.9563 - val_loss: 0.5139 - val_accuracy: 0.8500\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0849 - accuracy: 0.9812 - val_loss: 0.5349 - val_accuracy: 0.8450\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0804 - accuracy: 0.9800 - val_loss: 0.5679 - val_accuracy: 0.8400\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0794 - accuracy: 0.9712 - val_loss: 0.5747 - val_accuracy: 0.8500\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0701 - accuracy: 0.9762 - val_loss: 0.5650 - val_accuracy: 0.8400\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0798 - accuracy: 0.9712 - val_loss: 0.5777 - val_accuracy: 0.8500\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0766 - accuracy: 0.9800 - val_loss: 0.5556 - val_accuracy: 0.8550\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 0.5839 - val_accuracy: 0.8500\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0847 - accuracy: 0.9775 - val_loss: 0.5923 - val_accuracy: 0.8450\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0785 - accuracy: 0.9737 - val_loss: 0.5601 - val_accuracy: 0.8500\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0570 - accuracy: 0.9837 - val_loss: 0.6165 - val_accuracy: 0.8650\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 0.6044 - val_accuracy: 0.8450\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.6424 - val_accuracy: 0.8350\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.6472 - val_accuracy: 0.8400\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0564 - accuracy: 0.9812 - val_loss: 0.6180 - val_accuracy: 0.8300\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0504 - accuracy: 0.9887 - val_loss: 0.6032 - val_accuracy: 0.8500\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3055 - accuracy: 0.1100\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 2.2194 - accuracy: 0.1850 - val_loss: 2.0557 - val_accuracy: 0.3850\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.9477 - accuracy: 0.3913 - val_loss: 1.7868 - val_accuracy: 0.5700\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 1.6374 - accuracy: 0.5663 - val_loss: 1.5042 - val_accuracy: 0.6650\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.3849 - accuracy: 0.6463 - val_loss: 1.2824 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.1619 - accuracy: 0.7250 - val_loss: 1.0958 - val_accuracy: 0.7850\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0248 - accuracy: 0.7500 - val_loss: 0.9783 - val_accuracy: 0.7950\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.8788 - accuracy: 0.7925 - val_loss: 0.8995 - val_accuracy: 0.8000\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7904 - accuracy: 0.8200 - val_loss: 0.8212 - val_accuracy: 0.8250\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7413 - accuracy: 0.7987 - val_loss: 0.7736 - val_accuracy: 0.8300\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6736 - accuracy: 0.8200 - val_loss: 0.7230 - val_accuracy: 0.8300\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6280 - accuracy: 0.8512 - val_loss: 0.7039 - val_accuracy: 0.8300\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6009 - accuracy: 0.8375 - val_loss: 0.6628 - val_accuracy: 0.8300\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5506 - accuracy: 0.8562 - val_loss: 0.6534 - val_accuracy: 0.8200\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5368 - accuracy: 0.8562 - val_loss: 0.6318 - val_accuracy: 0.8300\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5258 - accuracy: 0.8650 - val_loss: 0.6281 - val_accuracy: 0.8250\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4964 - accuracy: 0.8562 - val_loss: 0.6018 - val_accuracy: 0.8350\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4391 - accuracy: 0.8850 - val_loss: 0.6010 - val_accuracy: 0.8300\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4449 - accuracy: 0.8875 - val_loss: 0.5869 - val_accuracy: 0.8300\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4416 - accuracy: 0.8788 - val_loss: 0.5805 - val_accuracy: 0.8400\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4233 - accuracy: 0.8788 - val_loss: 0.5722 - val_accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4102 - accuracy: 0.8875 - val_loss: 0.5577 - val_accuracy: 0.8400\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3914 - accuracy: 0.8938 - val_loss: 0.5542 - val_accuracy: 0.8400\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3374 - accuracy: 0.9250 - val_loss: 0.5573 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3622 - accuracy: 0.9025 - val_loss: 0.5401 - val_accuracy: 0.8350\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3648 - accuracy: 0.9038 - val_loss: 0.5477 - val_accuracy: 0.8200\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3322 - accuracy: 0.9162 - val_loss: 0.5234 - val_accuracy: 0.8350\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3338 - accuracy: 0.8988 - val_loss: 0.5318 - val_accuracy: 0.8250\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3153 - accuracy: 0.9225 - val_loss: 0.5229 - val_accuracy: 0.8350\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3077 - accuracy: 0.9262 - val_loss: 0.5273 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2993 - accuracy: 0.9300 - val_loss: 0.5166 - val_accuracy: 0.8350\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2716 - accuracy: 0.9287 - val_loss: 0.5039 - val_accuracy: 0.8400\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3017 - accuracy: 0.9225 - val_loss: 0.5152 - val_accuracy: 0.8350\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2718 - accuracy: 0.9275 - val_loss: 0.5062 - val_accuracy: 0.8450\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2576 - accuracy: 0.9325 - val_loss: 0.4989 - val_accuracy: 0.8400\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2509 - accuracy: 0.9388 - val_loss: 0.4939 - val_accuracy: 0.8400\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2725 - accuracy: 0.9275 - val_loss: 0.5096 - val_accuracy: 0.8300\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2493 - accuracy: 0.9362 - val_loss: 0.5135 - val_accuracy: 0.8300\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2613 - accuracy: 0.9262 - val_loss: 0.4994 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2383 - accuracy: 0.9438 - val_loss: 0.4914 - val_accuracy: 0.8400\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2371 - accuracy: 0.9362 - val_loss: 0.5043 - val_accuracy: 0.8300\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2317 - accuracy: 0.9350 - val_loss: 0.4979 - val_accuracy: 0.8300\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2266 - accuracy: 0.9425 - val_loss: 0.4907 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2259 - accuracy: 0.9413 - val_loss: 0.5017 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2283 - accuracy: 0.9400 - val_loss: 0.4835 - val_accuracy: 0.8400\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2126 - accuracy: 0.9463 - val_loss: 0.4934 - val_accuracy: 0.8250\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2005 - accuracy: 0.9475 - val_loss: 0.4941 - val_accuracy: 0.8350\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2009 - accuracy: 0.9488 - val_loss: 0.4907 - val_accuracy: 0.8350\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2038 - accuracy: 0.9413 - val_loss: 0.4877 - val_accuracy: 0.8400\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2043 - accuracy: 0.9463 - val_loss: 0.4937 - val_accuracy: 0.8350\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.1764 - accuracy: 0.9663 - val_loss: 0.4869 - val_accuracy: 0.8550\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.4869 - accuracy: 0.8550\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.1915 - accuracy: 0.9500 - val_loss: 0.4680 - val_accuracy: 0.8450\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.1537 - accuracy: 0.9538 - val_loss: 0.4862 - val_accuracy: 0.8450\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 214ms/step - loss: 0.1528 - accuracy: 0.9488 - val_loss: 0.4670 - val_accuracy: 0.8350\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.1302 - accuracy: 0.9613 - val_loss: 0.4995 - val_accuracy: 0.8400\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0942 - accuracy: 0.9712 - val_loss: 0.5025 - val_accuracy: 0.8650\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1212 - accuracy: 0.9650 - val_loss: 0.4987 - val_accuracy: 0.8400\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0989 - accuracy: 0.9712 - val_loss: 0.5010 - val_accuracy: 0.8600\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0936 - accuracy: 0.9750 - val_loss: 0.5243 - val_accuracy: 0.8550\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0741 - accuracy: 0.9737 - val_loss: 0.5394 - val_accuracy: 0.8500\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0783 - accuracy: 0.9775 - val_loss: 0.5060 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0704 - accuracy: 0.9725 - val_loss: 0.5074 - val_accuracy: 0.8550\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0857 - accuracy: 0.9675 - val_loss: 0.5273 - val_accuracy: 0.8550\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0705 - accuracy: 0.9787 - val_loss: 0.5080 - val_accuracy: 0.8600\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0593 - accuracy: 0.9837 - val_loss: 0.5270 - val_accuracy: 0.8500\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 0.5264 - val_accuracy: 0.8600\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.5282 - val_accuracy: 0.8550\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0516 - accuracy: 0.9887 - val_loss: 0.5229 - val_accuracy: 0.8650\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.5476 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.5633 - val_accuracy: 0.8650\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.5440 - val_accuracy: 0.8700\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0397 - accuracy: 0.9850 - val_loss: 0.5659 - val_accuracy: 0.8650\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3803 - accuracy: 0.1150\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 2.2559 - accuracy: 0.1688 - val_loss: 2.0593 - val_accuracy: 0.4350\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.9509 - accuracy: 0.4263 - val_loss: 1.7800 - val_accuracy: 0.5800\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 1.6534 - accuracy: 0.5888 - val_loss: 1.4916 - val_accuracy: 0.7350\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.4062 - accuracy: 0.6488 - val_loss: 1.2711 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.2003 - accuracy: 0.7312 - val_loss: 1.1058 - val_accuracy: 0.7650\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.0662 - accuracy: 0.7237 - val_loss: 0.9815 - val_accuracy: 0.7600\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9214 - accuracy: 0.7713 - val_loss: 0.9009 - val_accuracy: 0.7900\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8595 - accuracy: 0.7912 - val_loss: 0.8186 - val_accuracy: 0.8000\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7749 - accuracy: 0.7987 - val_loss: 0.7778 - val_accuracy: 0.7900\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7197 - accuracy: 0.8062 - val_loss: 0.7327 - val_accuracy: 0.8150\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6760 - accuracy: 0.8325 - val_loss: 0.6977 - val_accuracy: 0.7950\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6171 - accuracy: 0.8500 - val_loss: 0.6720 - val_accuracy: 0.8050\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5943 - accuracy: 0.8375 - val_loss: 0.6467 - val_accuracy: 0.8100\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5938 - accuracy: 0.8425 - val_loss: 0.6197 - val_accuracy: 0.8150\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5410 - accuracy: 0.8438 - val_loss: 0.5999 - val_accuracy: 0.8150\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5158 - accuracy: 0.8612 - val_loss: 0.5962 - val_accuracy: 0.8350\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4982 - accuracy: 0.8763 - val_loss: 0.5841 - val_accuracy: 0.8150\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4755 - accuracy: 0.8537 - val_loss: 0.5847 - val_accuracy: 0.8200\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4349 - accuracy: 0.8800 - val_loss: 0.5700 - val_accuracy: 0.8250\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4173 - accuracy: 0.8888 - val_loss: 0.5472 - val_accuracy: 0.8250\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4163 - accuracy: 0.8900 - val_loss: 0.5413 - val_accuracy: 0.8300\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4065 - accuracy: 0.8875 - val_loss: 0.5372 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4077 - accuracy: 0.8975 - val_loss: 0.5349 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3681 - accuracy: 0.9050 - val_loss: 0.5344 - val_accuracy: 0.8350\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3845 - accuracy: 0.8963 - val_loss: 0.5291 - val_accuracy: 0.8250\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.3770 - accuracy: 0.8900 - val_loss: 0.5361 - val_accuracy: 0.8200\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3351 - accuracy: 0.9137 - val_loss: 0.5229 - val_accuracy: 0.8250\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3521 - accuracy: 0.9013 - val_loss: 0.5136 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3240 - accuracy: 0.9075 - val_loss: 0.5145 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3208 - accuracy: 0.9062 - val_loss: 0.5247 - val_accuracy: 0.8150\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2942 - accuracy: 0.9350 - val_loss: 0.5103 - val_accuracy: 0.8400\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3024 - accuracy: 0.9337 - val_loss: 0.5057 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2846 - accuracy: 0.9337 - val_loss: 0.5014 - val_accuracy: 0.8350\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2575 - accuracy: 0.9438 - val_loss: 0.4949 - val_accuracy: 0.8350\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2865 - accuracy: 0.9287 - val_loss: 0.5043 - val_accuracy: 0.8300\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2640 - accuracy: 0.9375 - val_loss: 0.5044 - val_accuracy: 0.8300\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2744 - accuracy: 0.9300 - val_loss: 0.5077 - val_accuracy: 0.8350\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2292 - accuracy: 0.9475 - val_loss: 0.4902 - val_accuracy: 0.8350\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2585 - accuracy: 0.9350 - val_loss: 0.4823 - val_accuracy: 0.8350\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2364 - accuracy: 0.9375 - val_loss: 0.4741 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2146 - accuracy: 0.9500 - val_loss: 0.4793 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2228 - accuracy: 0.9525 - val_loss: 0.4788 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2241 - accuracy: 0.9475 - val_loss: 0.4913 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2108 - accuracy: 0.9525 - val_loss: 0.4905 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2159 - accuracy: 0.9525 - val_loss: 0.4863 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2064 - accuracy: 0.9550 - val_loss: 0.4779 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2098 - accuracy: 0.9463 - val_loss: 0.4981 - val_accuracy: 0.8350\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1851 - accuracy: 0.9525 - val_loss: 0.4780 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1989 - accuracy: 0.9525 - val_loss: 0.4929 - val_accuracy: 0.8350\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1860 - accuracy: 0.9525 - val_loss: 0.4870 - val_accuracy: 0.8400\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.4870 - accuracy: 0.8400\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.1936 - accuracy: 0.9438 - val_loss: 0.4767 - val_accuracy: 0.8450\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1500 - accuracy: 0.9625 - val_loss: 0.4843 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1385 - accuracy: 0.9538 - val_loss: 0.4956 - val_accuracy: 0.8500\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1256 - accuracy: 0.9538 - val_loss: 0.4965 - val_accuracy: 0.8450\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.1096 - accuracy: 0.9600 - val_loss: 0.5093 - val_accuracy: 0.8500\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.1141 - accuracy: 0.9712 - val_loss: 0.5412 - val_accuracy: 0.8400\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.1091 - accuracy: 0.9675 - val_loss: 0.5123 - val_accuracy: 0.8550\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0935 - accuracy: 0.9725 - val_loss: 0.5278 - val_accuracy: 0.8550\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0998 - accuracy: 0.9600 - val_loss: 0.5310 - val_accuracy: 0.8550\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0844 - accuracy: 0.9800 - val_loss: 0.5660 - val_accuracy: 0.8400\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0797 - accuracy: 0.9688 - val_loss: 0.5747 - val_accuracy: 0.8400\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 0.5940 - val_accuracy: 0.8550\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0766 - accuracy: 0.9812 - val_loss: 0.5963 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.6315 - val_accuracy: 0.8300\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0688 - accuracy: 0.9762 - val_loss: 0.6128 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0644 - accuracy: 0.9762 - val_loss: 0.6195 - val_accuracy: 0.8350\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0502 - accuracy: 0.9837 - val_loss: 0.6412 - val_accuracy: 0.8300\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0543 - accuracy: 0.9875 - val_loss: 0.6151 - val_accuracy: 0.8400\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.6075 - val_accuracy: 0.8300\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.6190 - val_accuracy: 0.8350\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0473 - accuracy: 0.9862 - val_loss: 0.6193 - val_accuracy: 0.8450\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 2.3849 - accuracy: 0.0400\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 2.2325 - accuracy: 0.1875 - val_loss: 2.1088 - val_accuracy: 0.3200\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.9419 - accuracy: 0.4263 - val_loss: 1.8303 - val_accuracy: 0.5850\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 1.6678 - accuracy: 0.5813 - val_loss: 1.5630 - val_accuracy: 0.6800\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.3969 - accuracy: 0.6700 - val_loss: 1.3239 - val_accuracy: 0.7600\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.1857 - accuracy: 0.7362 - val_loss: 1.1497 - val_accuracy: 0.7850\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.0271 - accuracy: 0.7513 - val_loss: 0.9987 - val_accuracy: 0.8150\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9499 - accuracy: 0.7738 - val_loss: 0.9048 - val_accuracy: 0.8200\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8325 - accuracy: 0.7900 - val_loss: 0.8331 - val_accuracy: 0.8200\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7633 - accuracy: 0.8112 - val_loss: 0.7903 - val_accuracy: 0.8250\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7097 - accuracy: 0.8125 - val_loss: 0.7332 - val_accuracy: 0.8200\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6381 - accuracy: 0.8475 - val_loss: 0.6987 - val_accuracy: 0.8350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5979 - accuracy: 0.8550 - val_loss: 0.6671 - val_accuracy: 0.8600\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5975 - accuracy: 0.8300 - val_loss: 0.6362 - val_accuracy: 0.8450\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5351 - accuracy: 0.8625 - val_loss: 0.6186 - val_accuracy: 0.8400\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5116 - accuracy: 0.8525 - val_loss: 0.6254 - val_accuracy: 0.8550\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5092 - accuracy: 0.8575 - val_loss: 0.6050 - val_accuracy: 0.8400\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4883 - accuracy: 0.8725 - val_loss: 0.6072 - val_accuracy: 0.8400\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4663 - accuracy: 0.8587 - val_loss: 0.5994 - val_accuracy: 0.8300\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4588 - accuracy: 0.8650 - val_loss: 0.5899 - val_accuracy: 0.8450\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4263 - accuracy: 0.8838 - val_loss: 0.5806 - val_accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4130 - accuracy: 0.8925 - val_loss: 0.5481 - val_accuracy: 0.8350\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4032 - accuracy: 0.8825 - val_loss: 0.5599 - val_accuracy: 0.8350\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3885 - accuracy: 0.9013 - val_loss: 0.5646 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3441 - accuracy: 0.9162 - val_loss: 0.5511 - val_accuracy: 0.8450\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3557 - accuracy: 0.9013 - val_loss: 0.5426 - val_accuracy: 0.8400\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3195 - accuracy: 0.9162 - val_loss: 0.5408 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3224 - accuracy: 0.9137 - val_loss: 0.5345 - val_accuracy: 0.8250\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3039 - accuracy: 0.9237 - val_loss: 0.5452 - val_accuracy: 0.8300\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3199 - accuracy: 0.9162 - val_loss: 0.5288 - val_accuracy: 0.8300\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3128 - accuracy: 0.9050 - val_loss: 0.5520 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2949 - accuracy: 0.9300 - val_loss: 0.5241 - val_accuracy: 0.8300\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2823 - accuracy: 0.9250 - val_loss: 0.5272 - val_accuracy: 0.8300\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2701 - accuracy: 0.9337 - val_loss: 0.5475 - val_accuracy: 0.8250\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2755 - accuracy: 0.9237 - val_loss: 0.5425 - val_accuracy: 0.8300\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2570 - accuracy: 0.9312 - val_loss: 0.5325 - val_accuracy: 0.8350\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.2693 - accuracy: 0.9300 - val_loss: 0.5497 - val_accuracy: 0.8300\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2274 - accuracy: 0.9613 - val_loss: 0.5309 - val_accuracy: 0.8400\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2302 - accuracy: 0.9450 - val_loss: 0.5448 - val_accuracy: 0.8300\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2344 - accuracy: 0.9488 - val_loss: 0.5336 - val_accuracy: 0.8300\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2391 - accuracy: 0.9425 - val_loss: 0.5420 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2362 - accuracy: 0.9413 - val_loss: 0.5338 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2274 - accuracy: 0.9475 - val_loss: 0.5466 - val_accuracy: 0.8350\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2132 - accuracy: 0.9588 - val_loss: 0.5431 - val_accuracy: 0.8350\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2029 - accuracy: 0.9500 - val_loss: 0.5393 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2043 - accuracy: 0.9513 - val_loss: 0.5551 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1944 - accuracy: 0.9500 - val_loss: 0.5415 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2102 - accuracy: 0.9388 - val_loss: 0.5547 - val_accuracy: 0.8450\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1704 - accuracy: 0.9650 - val_loss: 0.5433 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1783 - accuracy: 0.9450 - val_loss: 0.5518 - val_accuracy: 0.8350\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.1669 - accuracy: 0.9650 - val_loss: 0.5629 - val_accuracy: 0.8300\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.5629 - accuracy: 0.8300\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 222ms/step - loss: 0.1618 - accuracy: 0.9563 - val_loss: 0.5640 - val_accuracy: 0.8300\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1422 - accuracy: 0.9600 - val_loss: 0.5962 - val_accuracy: 0.8400\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.1228 - accuracy: 0.9613 - val_loss: 0.5938 - val_accuracy: 0.8350\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0920 - accuracy: 0.9787 - val_loss: 0.5658 - val_accuracy: 0.8450\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0890 - accuracy: 0.9737 - val_loss: 0.5719 - val_accuracy: 0.8450\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1079 - accuracy: 0.9638 - val_loss: 0.5822 - val_accuracy: 0.8400\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0892 - accuracy: 0.9725 - val_loss: 0.6462 - val_accuracy: 0.8400\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0730 - accuracy: 0.9725 - val_loss: 0.6393 - val_accuracy: 0.8350\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0843 - accuracy: 0.9712 - val_loss: 0.5944 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0965 - accuracy: 0.9737 - val_loss: 0.6095 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0661 - accuracy: 0.9812 - val_loss: 0.6547 - val_accuracy: 0.8550\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0738 - accuracy: 0.9737 - val_loss: 0.6274 - val_accuracy: 0.8450\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0669 - accuracy: 0.9775 - val_loss: 0.6286 - val_accuracy: 0.8450\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.6754 - val_accuracy: 0.8400\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0634 - accuracy: 0.9762 - val_loss: 0.6046 - val_accuracy: 0.8500\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0504 - accuracy: 0.9825 - val_loss: 0.6208 - val_accuracy: 0.8650\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.6627 - val_accuracy: 0.8600\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0602 - accuracy: 0.9762 - val_loss: 0.6219 - val_accuracy: 0.8450\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0484 - accuracy: 0.9862 - val_loss: 0.6631 - val_accuracy: 0.8600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.6177 - val_accuracy: 0.8650\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 0.6472 - val_accuracy: 0.8650\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 2.3672 - accuracy: 0.1200\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.2520 - accuracy: 0.1750 - val_loss: 2.1201 - val_accuracy: 0.3400\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.9640 - accuracy: 0.4075 - val_loss: 1.8600 - val_accuracy: 0.5600\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 1.6715 - accuracy: 0.5663 - val_loss: 1.5608 - val_accuracy: 0.6700\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 179ms/step - loss: 1.3911 - accuracy: 0.6700 - val_loss: 1.3240 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.1674 - accuracy: 0.7375 - val_loss: 1.1354 - val_accuracy: 0.7850\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.0222 - accuracy: 0.7550 - val_loss: 0.9977 - val_accuracy: 0.7950\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.8971 - accuracy: 0.7875 - val_loss: 0.9068 - val_accuracy: 0.8100\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8137 - accuracy: 0.7987 - val_loss: 0.8255 - val_accuracy: 0.8300\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7381 - accuracy: 0.8188 - val_loss: 0.7669 - val_accuracy: 0.8350\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6844 - accuracy: 0.8263 - val_loss: 0.7362 - val_accuracy: 0.8300\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.6503 - accuracy: 0.8238 - val_loss: 0.7031 - val_accuracy: 0.8250\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.5880 - accuracy: 0.8438 - val_loss: 0.6783 - val_accuracy: 0.8450\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.5691 - accuracy: 0.8487 - val_loss: 0.6337 - val_accuracy: 0.8450\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.5271 - accuracy: 0.8537 - val_loss: 0.6158 - val_accuracy: 0.8300\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.5061 - accuracy: 0.8712 - val_loss: 0.5898 - val_accuracy: 0.8500\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4681 - accuracy: 0.8838 - val_loss: 0.5702 - val_accuracy: 0.8550\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.4954 - accuracy: 0.8525 - val_loss: 0.5653 - val_accuracy: 0.8600\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4439 - accuracy: 0.8800 - val_loss: 0.5366 - val_accuracy: 0.8550\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4477 - accuracy: 0.8750 - val_loss: 0.5381 - val_accuracy: 0.8550\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4066 - accuracy: 0.9050 - val_loss: 0.5347 - val_accuracy: 0.8650\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3923 - accuracy: 0.9025 - val_loss: 0.5212 - val_accuracy: 0.8550\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3861 - accuracy: 0.9000 - val_loss: 0.5095 - val_accuracy: 0.8550\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3870 - accuracy: 0.8938 - val_loss: 0.4991 - val_accuracy: 0.8450\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3410 - accuracy: 0.9062 - val_loss: 0.4876 - val_accuracy: 0.8600\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3320 - accuracy: 0.9200 - val_loss: 0.4959 - val_accuracy: 0.8550\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3104 - accuracy: 0.9275 - val_loss: 0.4943 - val_accuracy: 0.8600\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.3151 - accuracy: 0.9250 - val_loss: 0.4827 - val_accuracy: 0.8500\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.3011 - accuracy: 0.9125 - val_loss: 0.4833 - val_accuracy: 0.8500\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2944 - accuracy: 0.9337 - val_loss: 0.4719 - val_accuracy: 0.8450\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2965 - accuracy: 0.9200 - val_loss: 0.4603 - val_accuracy: 0.8600\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2790 - accuracy: 0.9250 - val_loss: 0.4598 - val_accuracy: 0.8500\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2679 - accuracy: 0.9325 - val_loss: 0.4527 - val_accuracy: 0.8650\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2545 - accuracy: 0.9388 - val_loss: 0.4621 - val_accuracy: 0.8550\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2784 - accuracy: 0.9225 - val_loss: 0.4665 - val_accuracy: 0.8600\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2555 - accuracy: 0.9350 - val_loss: 0.4663 - val_accuracy: 0.8500\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2667 - accuracy: 0.9337 - val_loss: 0.4530 - val_accuracy: 0.8550\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2203 - accuracy: 0.9513 - val_loss: 0.4544 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2563 - accuracy: 0.9375 - val_loss: 0.4531 - val_accuracy: 0.8550\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2277 - accuracy: 0.9463 - val_loss: 0.4444 - val_accuracy: 0.8550\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2290 - accuracy: 0.9413 - val_loss: 0.4406 - val_accuracy: 0.8650\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2258 - accuracy: 0.9450 - val_loss: 0.4360 - val_accuracy: 0.8600\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2206 - accuracy: 0.9488 - val_loss: 0.4206 - val_accuracy: 0.8600\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.2208 - accuracy: 0.9400 - val_loss: 0.4428 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1998 - accuracy: 0.9513 - val_loss: 0.4376 - val_accuracy: 0.8550\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2168 - accuracy: 0.9488 - val_loss: 0.4513 - val_accuracy: 0.8500\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1890 - accuracy: 0.9575 - val_loss: 0.4489 - val_accuracy: 0.8550\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1946 - accuracy: 0.9475 - val_loss: 0.4316 - val_accuracy: 0.8550\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 0.1863 - accuracy: 0.9588 - val_loss: 0.4244 - val_accuracy: 0.8500\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1859 - accuracy: 0.9538 - val_loss: 0.4284 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 0.1873 - accuracy: 0.9538 - val_loss: 0.4173 - val_accuracy: 0.8550\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.4173 - accuracy: 0.8550\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,125,042\n",
            "Trainable params: 7,051,946\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.1632 - accuracy: 0.9600 - val_loss: 0.4158 - val_accuracy: 0.8600\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.1386 - accuracy: 0.9550 - val_loss: 0.4013 - val_accuracy: 0.8550\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 11s 214ms/step - loss: 0.1363 - accuracy: 0.9563 - val_loss: 0.4000 - val_accuracy: 0.8700\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 11s 214ms/step - loss: 0.1126 - accuracy: 0.9675 - val_loss: 0.4272 - val_accuracy: 0.8650\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0988 - accuracy: 0.9700 - val_loss: 0.4039 - val_accuracy: 0.8850\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0975 - accuracy: 0.9700 - val_loss: 0.4116 - val_accuracy: 0.8650\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0994 - accuracy: 0.9725 - val_loss: 0.4142 - val_accuracy: 0.8600\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1064 - accuracy: 0.9613 - val_loss: 0.4127 - val_accuracy: 0.8550\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.0907 - accuracy: 0.9700 - val_loss: 0.4218 - val_accuracy: 0.8800\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0927 - accuracy: 0.9725 - val_loss: 0.4263 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.4390 - val_accuracy: 0.8600\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0861 - accuracy: 0.9700 - val_loss: 0.4404 - val_accuracy: 0.8600\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.0608 - accuracy: 0.9837 - val_loss: 0.4504 - val_accuracy: 0.8700\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0745 - accuracy: 0.9775 - val_loss: 0.4211 - val_accuracy: 0.8800\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0659 - accuracy: 0.9712 - val_loss: 0.4353 - val_accuracy: 0.8650\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0555 - accuracy: 0.9787 - val_loss: 0.4255 - val_accuracy: 0.8700\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0438 - accuracy: 0.9875 - val_loss: 0.4492 - val_accuracy: 0.8700\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.4619 - val_accuracy: 0.8800\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0643 - accuracy: 0.9787 - val_loss: 0.4353 - val_accuracy: 0.8750\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.4701 - val_accuracy: 0.8750\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0406 - accuracy: 0.9912 - val_loss: 0.4486 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8462a1e8-b869-4ba3-a7d4-302be766489c"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.09099999964237213\n",
            "Accuracy before fine-tuning: 0.8450000047683716\n",
            "Final accuracy: 0.8680000066757202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3ae447f3-e15c-4862-d5f3-822040bb3702"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fe06f4f0-0043-4cff-c849-d4ee32be67a8"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}