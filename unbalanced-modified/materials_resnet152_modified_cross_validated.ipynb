{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials_resnet152_modified_cross_validated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8a5216-443f-4df4-d9e2-50194f98c3f4"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create dataset from the image directory\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'), shuffle=False)\n",
        "# shuffle the 1,000 images with the random seed value of 123 before training\n",
        "list_ds = list_ds.shuffle(image_count, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbc11d8-c4d7-4abd-d43d-991ea8905a2b"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split dataset into 5 equal sized parts for 5-fold cross validation\n",
        "A = list_ds.shard(num_shards=5, index=0)\n",
        "B = list_ds.shard(num_shards=5, index=1)\n",
        "C = list_ds.shard(num_shards=5, index=2)\n",
        "D = list_ds.shard(num_shards=5, index=3)\n",
        "E = list_ds.shard(num_shards=5, index=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba2e550-631d-4b68-e266-0ec80dc3300f"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e77116-a2e8-495f-fe8d-8bccbd727ca7"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVOP5fIPwEx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e2375d-2554-4ddd-be08-04c93fe4facf"
      },
      "source": [
        "# get pre-trained model\n",
        "base_model = keras.applications.ResNet152V2(include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS2kAceGVW0e"
      },
      "source": [
        "# don't train base model weights\n",
        "base_model.trainable = False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGkReMX60ScJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "tags": [
          "outputPrepend"
        ],
        "outputId": "9808d500-9019-461b-deea-3d467c0ed9f5"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet152v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 305, 305, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 150, 150, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 152, 152, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 75, 75, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 75, 75, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 75, 75, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 75, 75, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 75, 75, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 75, 75, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 75, 75, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 75, 75, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 75, 75, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 75, 75, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 75, 75, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 75, 75, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 75, 75, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 75, 75, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 75, 75, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 75, 75, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 75, 75, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 75, 75, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 75, 75, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 75, 75, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 75, 75, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 77, 77, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 38, 38, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 38, 38, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 38, 38, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 38, 38, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 38, 38, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 38, 38, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 38, 38, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 38, 38, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 38, 38, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 38, 38, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 38, 38, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 38, 38, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 38, 38, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 38, 38, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 38, 38, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 38, 38, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 38, 38, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 38, 38, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 38, 38, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_relu (Activation (None, 38, 38, 128)  0           conv3_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_out (Add)          (None, 38, 38, 512)  0           conv3_block4_out[0][0]           \n",
            "                                                                 conv3_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 38, 38, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_relu (Activation (None, 38, 38, 128)  0           conv3_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_out (Add)          (None, 38, 38, 512)  0           conv3_block5_out[0][0]           \n",
            "                                                                 conv3_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 38, 38, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 38, 38, 128)  147456      conv3_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_relu (Activation (None, 38, 38, 128)  0           conv3_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_3_conv (Conv2D)    (None, 38, 38, 512)  66048       conv3_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_out (Add)          (None, 38, 38, 512)  0           conv3_block6_out[0][0]           \n",
            "                                                                 conv3_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_bn (BatchNo (None, 38, 38, 512)  2048        conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_preact_relu (Activ (None, 38, 38, 512)  0           conv3_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 38, 38, 128)  65536       conv3_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 38, 38, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 38, 38, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_pad (ZeroPadding (None, 40, 40, 128)  0           conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_relu (Activation (None, 19, 19, 128)  0           conv3_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 512)  0           conv3_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_out (Add)          (None, 19, 19, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 19, 19, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 19, 19, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 19, 19, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 19, 19, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 19, 19, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 19, 19, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 19, 19, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 19, 19, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 19, 19, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 19, 19, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 19, 19, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 19, 19, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 19, 19, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 19, 19, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 19, 19, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 19, 19, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 19, 19, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 19, 19, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 19, 19, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 19, 19, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 19, 19, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 19, 19, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 19, 19, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Add)          (None, 19, 19, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 19, 19, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 19, 19, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Add)          (None, 19, 19, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_bn (BatchNo (None, 19, 19, 1024) 4096        conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_relu (Activ (None, 19, 19, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 19, 19, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 19, 19, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_pad (ZeroPadding (None, 21, 21, 256)  0           conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 19, 19, 256)  589824      conv4_block9_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 19, 19, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 19, 19, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 19, 19, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Add)          (None, 19, 19, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block10_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Add)         (None, 19, 19, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block11_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Add)         (None, 19, 19, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block12_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Add)         (None, 19, 19, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block13_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Add)         (None, 19, 19, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block14_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Add)         (None, 19, 19, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block15_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Add)         (None, 19, 19, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block16_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Add)         (None, 19, 19, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block17_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Add)         (None, 19, 19, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block18_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Add)         (None, 19, 19, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block19_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Add)         (None, 19, 19, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block20_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Add)         (None, 19, 19, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block21_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Add)         (None, 19, 19, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block22_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Add)         (None, 19, 19, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block23_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Add)         (None, 19, 19, 1024) 0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block24_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block24_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block24_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block24_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_out (Add)         (None, 19, 19, 1024) 0           conv4_block23_out[0][0]          \n",
            "                                                                 conv4_block24_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block24_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block25_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block25_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block25_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block25_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block25_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block25_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block25_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block25_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block25_out (Add)         (None, 19, 19, 1024) 0           conv4_block24_out[0][0]          \n",
            "                                                                 conv4_block25_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block25_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block26_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block26_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block26_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block26_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block26_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block26_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block26_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block26_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block26_out (Add)         (None, 19, 19, 1024) 0           conv4_block25_out[0][0]          \n",
            "                                                                 conv4_block26_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block26_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block27_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block27_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block27_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block27_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block27_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block27_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block27_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block27_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block27_out (Add)         (None, 19, 19, 1024) 0           conv4_block26_out[0][0]          \n",
            "                                                                 conv4_block27_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block27_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block28_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block28_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block28_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block28_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block28_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block28_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block28_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block28_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block28_out (Add)         (None, 19, 19, 1024) 0           conv4_block27_out[0][0]          \n",
            "                                                                 conv4_block28_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block28_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block29_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block29_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block29_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block29_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block29_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block29_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block29_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block29_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block29_out (Add)         (None, 19, 19, 1024) 0           conv4_block28_out[0][0]          \n",
            "                                                                 conv4_block29_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block29_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block30_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block30_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block30_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block30_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block30_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block30_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block30_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block30_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block30_out (Add)         (None, 19, 19, 1024) 0           conv4_block29_out[0][0]          \n",
            "                                                                 conv4_block30_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block30_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block31_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block31_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block31_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block31_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block31_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block31_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block31_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block31_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block31_out (Add)         (None, 19, 19, 1024) 0           conv4_block30_out[0][0]          \n",
            "                                                                 conv4_block31_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block31_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block32_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block32_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block32_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block32_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block32_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block32_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block32_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block32_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block32_out (Add)         (None, 19, 19, 1024) 0           conv4_block31_out[0][0]          \n",
            "                                                                 conv4_block32_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block32_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block33_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block33_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block33_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block33_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block33_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block33_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block33_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block33_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block33_out (Add)         (None, 19, 19, 1024) 0           conv4_block32_out[0][0]          \n",
            "                                                                 conv4_block33_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block33_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block34_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block34_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block34_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block34_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block34_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block34_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block34_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block34_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block34_out (Add)         (None, 19, 19, 1024) 0           conv4_block33_out[0][0]          \n",
            "                                                                 conv4_block34_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block34_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block35_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block35_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block35_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block35_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block35_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_conv (Conv2D)   (None, 19, 19, 256)  589824      conv4_block35_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block35_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_2_relu (Activatio (None, 19, 19, 256)  0           conv4_block35_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_3_conv (Conv2D)   (None, 19, 19, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block35_out (Add)         (None, 19, 19, 1024) 0           conv4_block34_out[0][0]          \n",
            "                                                                 conv4_block35_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_bn (BatchN (None, 19, 19, 1024) 4096        conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_preact_relu (Acti (None, 19, 19, 1024) 0           conv4_block36_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_conv (Conv2D)   (None, 19, 19, 256)  262144      conv4_block36_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_bn (BatchNormal (None, 19, 19, 256)  1024        conv4_block36_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_1_relu (Activatio (None, 19, 19, 256)  0           conv4_block36_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_pad (ZeroPaddin (None, 21, 21, 256)  0           conv4_block36_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_conv (Conv2D)   (None, 10, 10, 256)  589824      conv4_block36_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_bn (BatchNormal (None, 10, 10, 256)  1024        conv4_block36_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_2_relu (Activatio (None, 10, 10, 256)  0           conv4_block36_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 1024) 0           conv4_block35_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_3_conv (Conv2D)   (None, 10, 10, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block36_out (Add)         (None, 10, 10, 1024) 0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block36_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block36_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 10, 10, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 10, 10, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 10, 10, 512)  0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 10, 10, 512)  0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 10, 10, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 10, 10, 2048) 0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 10, 10, 2048) 8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 10, 10, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 10, 10, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 10, 10, 512)  0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 10, 10, 512)  0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 10, 10, 2048) 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 10, 10, 2048) 8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 10, 10, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 10, 10, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 10, 10, 512)  0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 12, 12, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 10, 10, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 10, 10, 512)  2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 10, 10, 512)  0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 10, 10, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 10, 10, 2048) 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 10, 10, 2048) 8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 10, 10, 2048) 0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 58,331,648\n",
            "Trainable params: 0\n",
            "Non-trainable params: 58,331,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model():\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # increase network depth by adding additional fully connected layer of size 128 with ReLU activation\n",
        "  fully_connected_layer = keras.layers.Dense(128, activation='relu')\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  x = fully_connected_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 100"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "tags": [
          "outputPrepend"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1717e6c0-b74b-4ff7-f1f4-cb6875b937b3"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model()\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy']))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet152v2 (Functional)     (None, 10, 10, 2048)      58331648  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 58,595,210\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 2.6140 - accuracy: 0.0600\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 13s 268ms/step - loss: 2.4102 - accuracy: 0.1775 - val_loss: 1.9514 - val_accuracy: 0.3700\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 1.7934 - accuracy: 0.3887 - val_loss: 1.5875 - val_accuracy: 0.4950\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 1.4011 - accuracy: 0.5550 - val_loss: 1.3074 - val_accuracy: 0.5950\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 15s 290ms/step - loss: 1.2053 - accuracy: 0.6112 - val_loss: 1.1197 - val_accuracy: 0.6750\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 14s 286ms/step - loss: 1.0111 - accuracy: 0.6825 - val_loss: 0.9736 - val_accuracy: 0.7150\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.8637 - accuracy: 0.7387 - val_loss: 0.8740 - val_accuracy: 0.7100\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.7836 - accuracy: 0.7487 - val_loss: 0.8211 - val_accuracy: 0.7150\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.7287 - accuracy: 0.7700 - val_loss: 0.7593 - val_accuracy: 0.7200\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.6590 - accuracy: 0.7900 - val_loss: 0.7290 - val_accuracy: 0.7550\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.5759 - accuracy: 0.8275 - val_loss: 0.6870 - val_accuracy: 0.7500\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.5555 - accuracy: 0.8325 - val_loss: 0.6619 - val_accuracy: 0.7800\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.5579 - accuracy: 0.8275 - val_loss: 0.6452 - val_accuracy: 0.7850\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.4538 - accuracy: 0.8625 - val_loss: 0.6344 - val_accuracy: 0.7850\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.4427 - accuracy: 0.8763 - val_loss: 0.6162 - val_accuracy: 0.7950\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.4532 - accuracy: 0.8612 - val_loss: 0.6173 - val_accuracy: 0.7700\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.4181 - accuracy: 0.8700 - val_loss: 0.5980 - val_accuracy: 0.7750\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3564 - accuracy: 0.8925 - val_loss: 0.6076 - val_accuracy: 0.7700\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3697 - accuracy: 0.8775 - val_loss: 0.5730 - val_accuracy: 0.7900\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3269 - accuracy: 0.9050 - val_loss: 0.5714 - val_accuracy: 0.7900\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3266 - accuracy: 0.8988 - val_loss: 0.5844 - val_accuracy: 0.7850\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3422 - accuracy: 0.8938 - val_loss: 0.5493 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2963 - accuracy: 0.9062 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2764 - accuracy: 0.9187 - val_loss: 0.5301 - val_accuracy: 0.8200\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3151 - accuracy: 0.9013 - val_loss: 0.5325 - val_accuracy: 0.8150\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2739 - accuracy: 0.9212 - val_loss: 0.5458 - val_accuracy: 0.8250\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2622 - accuracy: 0.9275 - val_loss: 0.5118 - val_accuracy: 0.8350\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2392 - accuracy: 0.9275 - val_loss: 0.5118 - val_accuracy: 0.8450\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2170 - accuracy: 0.9413 - val_loss: 0.5185 - val_accuracy: 0.8250\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2287 - accuracy: 0.9337 - val_loss: 0.5242 - val_accuracy: 0.8250\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2039 - accuracy: 0.9463 - val_loss: 0.5250 - val_accuracy: 0.8200\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2386 - accuracy: 0.9237 - val_loss: 0.5275 - val_accuracy: 0.8150\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2137 - accuracy: 0.9413 - val_loss: 0.5166 - val_accuracy: 0.8300\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1797 - accuracy: 0.9563 - val_loss: 0.5144 - val_accuracy: 0.8300\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1845 - accuracy: 0.9488 - val_loss: 0.5065 - val_accuracy: 0.8250\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1906 - accuracy: 0.9375 - val_loss: 0.5222 - val_accuracy: 0.8200\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1874 - accuracy: 0.9438 - val_loss: 0.5016 - val_accuracy: 0.8250\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1745 - accuracy: 0.9450 - val_loss: 0.5018 - val_accuracy: 0.8200\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1927 - accuracy: 0.9362 - val_loss: 0.5097 - val_accuracy: 0.8200\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1690 - accuracy: 0.9475 - val_loss: 0.4941 - val_accuracy: 0.8300\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1548 - accuracy: 0.9588 - val_loss: 0.5045 - val_accuracy: 0.8200\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1507 - accuracy: 0.9575 - val_loss: 0.4886 - val_accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1523 - accuracy: 0.9525 - val_loss: 0.4977 - val_accuracy: 0.8200\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1547 - accuracy: 0.9575 - val_loss: 0.5229 - val_accuracy: 0.8200\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1406 - accuracy: 0.9588 - val_loss: 0.4961 - val_accuracy: 0.8200\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1259 - accuracy: 0.9700 - val_loss: 0.5002 - val_accuracy: 0.8250\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1447 - accuracy: 0.9550 - val_loss: 0.5033 - val_accuracy: 0.8200\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1374 - accuracy: 0.9600 - val_loss: 0.4986 - val_accuracy: 0.8250\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1283 - accuracy: 0.9663 - val_loss: 0.5060 - val_accuracy: 0.8200\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1387 - accuracy: 0.9588 - val_loss: 0.4942 - val_accuracy: 0.8250\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1233 - accuracy: 0.9675 - val_loss: 0.4851 - val_accuracy: 0.8350\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1130 - accuracy: 0.9712 - val_loss: 0.5056 - val_accuracy: 0.8200\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1369 - accuracy: 0.9625 - val_loss: 0.4907 - val_accuracy: 0.8300\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1268 - accuracy: 0.9650 - val_loss: 0.4894 - val_accuracy: 0.8350\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1190 - accuracy: 0.9688 - val_loss: 0.4983 - val_accuracy: 0.8200\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1109 - accuracy: 0.9712 - val_loss: 0.5030 - val_accuracy: 0.8300\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1343 - accuracy: 0.9575 - val_loss: 0.5225 - val_accuracy: 0.8100\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1177 - accuracy: 0.9762 - val_loss: 0.5232 - val_accuracy: 0.8150\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1108 - accuracy: 0.9638 - val_loss: 0.5087 - val_accuracy: 0.8200\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1264 - accuracy: 0.9663 - val_loss: 0.5394 - val_accuracy: 0.8100\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0896 - accuracy: 0.9800 - val_loss: 0.5131 - val_accuracy: 0.8150\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1072 - accuracy: 0.9700 - val_loss: 0.5117 - val_accuracy: 0.8150\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1119 - accuracy: 0.9675 - val_loss: 0.5239 - val_accuracy: 0.8050\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1003 - accuracy: 0.9737 - val_loss: 0.5291 - val_accuracy: 0.8150\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1202 - accuracy: 0.9613 - val_loss: 0.5253 - val_accuracy: 0.8250\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0817 - accuracy: 0.9787 - val_loss: 0.5389 - val_accuracy: 0.8250\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0838 - accuracy: 0.9775 - val_loss: 0.5268 - val_accuracy: 0.8250\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1179 - accuracy: 0.9625 - val_loss: 0.5366 - val_accuracy: 0.8250\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0742 - accuracy: 0.9850 - val_loss: 0.5369 - val_accuracy: 0.8200\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0841 - accuracy: 0.9787 - val_loss: 0.5257 - val_accuracy: 0.8250\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0851 - accuracy: 0.9862 - val_loss: 0.5383 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0737 - accuracy: 0.9862 - val_loss: 0.5462 - val_accuracy: 0.8300\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0926 - accuracy: 0.9700 - val_loss: 0.5492 - val_accuracy: 0.8150\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0711 - accuracy: 0.9875 - val_loss: 0.5430 - val_accuracy: 0.8350\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0753 - accuracy: 0.9787 - val_loss: 0.5431 - val_accuracy: 0.8300\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0752 - accuracy: 0.9862 - val_loss: 0.5572 - val_accuracy: 0.8150\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0762 - accuracy: 0.9762 - val_loss: 0.5858 - val_accuracy: 0.8050\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0800 - accuracy: 0.9800 - val_loss: 0.5472 - val_accuracy: 0.8200\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0762 - accuracy: 0.9812 - val_loss: 0.5404 - val_accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0568 - accuracy: 0.9875 - val_loss: 0.5405 - val_accuracy: 0.8200\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0706 - accuracy: 0.9862 - val_loss: 0.5589 - val_accuracy: 0.8150\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0633 - accuracy: 0.9887 - val_loss: 0.5907 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0715 - accuracy: 0.9787 - val_loss: 0.5580 - val_accuracy: 0.8200\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0849 - accuracy: 0.9762 - val_loss: 0.5796 - val_accuracy: 0.8000\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0655 - accuracy: 0.9875 - val_loss: 0.5698 - val_accuracy: 0.8050\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0533 - accuracy: 0.9925 - val_loss: 0.5842 - val_accuracy: 0.8050\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0674 - accuracy: 0.9800 - val_loss: 0.5706 - val_accuracy: 0.8050\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0637 - accuracy: 0.9825 - val_loss: 0.5771 - val_accuracy: 0.8100\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0723 - accuracy: 0.9775 - val_loss: 0.5771 - val_accuracy: 0.8250\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0595 - accuracy: 0.9862 - val_loss: 0.5690 - val_accuracy: 0.8050\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.5397 - val_accuracy: 0.8350\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0643 - accuracy: 0.9837 - val_loss: 0.5731 - val_accuracy: 0.8100\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.5552 - val_accuracy: 0.8150\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.5672 - val_accuracy: 0.8150\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0661 - accuracy: 0.9837 - val_loss: 0.5526 - val_accuracy: 0.8150\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.5558 - val_accuracy: 0.8150\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0500 - accuracy: 0.9862 - val_loss: 0.5522 - val_accuracy: 0.8300\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0473 - accuracy: 0.9887 - val_loss: 0.5526 - val_accuracy: 0.8200\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0401 - accuracy: 0.9900 - val_loss: 0.5826 - val_accuracy: 0.8350\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0619 - accuracy: 0.9812 - val_loss: 0.5677 - val_accuracy: 0.8300\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet152v2 (Functional)     (None, 10, 10, 2048)      58331648  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 58,595,210\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 195ms/step - loss: 2.6438 - accuracy: 0.0750\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 2.4182 - accuracy: 0.1863 - val_loss: 1.8767 - val_accuracy: 0.3700\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 1.8521 - accuracy: 0.3537 - val_loss: 1.4660 - val_accuracy: 0.5600\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 14s 287ms/step - loss: 1.4845 - accuracy: 0.5362 - val_loss: 1.1882 - val_accuracy: 0.6850\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 1.2191 - accuracy: 0.6275 - val_loss: 1.0134 - val_accuracy: 0.7100\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 1.0267 - accuracy: 0.6875 - val_loss: 0.8690 - val_accuracy: 0.7400\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.9069 - accuracy: 0.7050 - val_loss: 0.7973 - val_accuracy: 0.7600\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.8238 - accuracy: 0.7400 - val_loss: 0.7245 - val_accuracy: 0.7800\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.7096 - accuracy: 0.7800 - val_loss: 0.6821 - val_accuracy: 0.7950\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.6277 - accuracy: 0.8313 - val_loss: 0.6547 - val_accuracy: 0.7900\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.5913 - accuracy: 0.8150 - val_loss: 0.6432 - val_accuracy: 0.7850\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.5467 - accuracy: 0.8263 - val_loss: 0.6113 - val_accuracy: 0.7900\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.5154 - accuracy: 0.8537 - val_loss: 0.6182 - val_accuracy: 0.8050\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.4573 - accuracy: 0.8637 - val_loss: 0.6090 - val_accuracy: 0.7900\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.4218 - accuracy: 0.8675 - val_loss: 0.6000 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.4453 - accuracy: 0.8600 - val_loss: 0.5777 - val_accuracy: 0.8050\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.4201 - accuracy: 0.8575 - val_loss: 0.5688 - val_accuracy: 0.8050\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3911 - accuracy: 0.8863 - val_loss: 0.5837 - val_accuracy: 0.8100\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3490 - accuracy: 0.9025 - val_loss: 0.5709 - val_accuracy: 0.7900\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.3329 - accuracy: 0.8938 - val_loss: 0.5696 - val_accuracy: 0.8100\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3021 - accuracy: 0.8988 - val_loss: 0.5432 - val_accuracy: 0.7950\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3131 - accuracy: 0.9000 - val_loss: 0.5456 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.2852 - accuracy: 0.9262 - val_loss: 0.5361 - val_accuracy: 0.8150\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2801 - accuracy: 0.9262 - val_loss: 0.5265 - val_accuracy: 0.7900\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2508 - accuracy: 0.9200 - val_loss: 0.5604 - val_accuracy: 0.7950\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2685 - accuracy: 0.9212 - val_loss: 0.5510 - val_accuracy: 0.7950\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2073 - accuracy: 0.9513 - val_loss: 0.5393 - val_accuracy: 0.8050\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2612 - accuracy: 0.9175 - val_loss: 0.5440 - val_accuracy: 0.8300\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2335 - accuracy: 0.9287 - val_loss: 0.5467 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2298 - accuracy: 0.9312 - val_loss: 0.5599 - val_accuracy: 0.7950\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2086 - accuracy: 0.9388 - val_loss: 0.5518 - val_accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1904 - accuracy: 0.9400 - val_loss: 0.5689 - val_accuracy: 0.7950\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2114 - accuracy: 0.9350 - val_loss: 0.5310 - val_accuracy: 0.8050\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2023 - accuracy: 0.9463 - val_loss: 0.5277 - val_accuracy: 0.8000\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1911 - accuracy: 0.9550 - val_loss: 0.5400 - val_accuracy: 0.8050\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1973 - accuracy: 0.9450 - val_loss: 0.5347 - val_accuracy: 0.8150\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1679 - accuracy: 0.9513 - val_loss: 0.5534 - val_accuracy: 0.8050\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1768 - accuracy: 0.9513 - val_loss: 0.5623 - val_accuracy: 0.8050\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1746 - accuracy: 0.9463 - val_loss: 0.5583 - val_accuracy: 0.8050\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1584 - accuracy: 0.9588 - val_loss: 0.5591 - val_accuracy: 0.8000\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1693 - accuracy: 0.9588 - val_loss: 0.5418 - val_accuracy: 0.8100\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1490 - accuracy: 0.9563 - val_loss: 0.5352 - val_accuracy: 0.8200\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1452 - accuracy: 0.9663 - val_loss: 0.5478 - val_accuracy: 0.8100\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1523 - accuracy: 0.9563 - val_loss: 0.5706 - val_accuracy: 0.8050\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1488 - accuracy: 0.9563 - val_loss: 0.5589 - val_accuracy: 0.8100\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1586 - accuracy: 0.9463 - val_loss: 0.5436 - val_accuracy: 0.8300\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1278 - accuracy: 0.9650 - val_loss: 0.5516 - val_accuracy: 0.8200\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1426 - accuracy: 0.9625 - val_loss: 0.5580 - val_accuracy: 0.8050\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1341 - accuracy: 0.9538 - val_loss: 0.5661 - val_accuracy: 0.8100\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1428 - accuracy: 0.9600 - val_loss: 0.5631 - val_accuracy: 0.8050\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1068 - accuracy: 0.9737 - val_loss: 0.5431 - val_accuracy: 0.8100\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.1176 - accuracy: 0.9663 - val_loss: 0.5471 - val_accuracy: 0.8150\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1035 - accuracy: 0.9712 - val_loss: 0.5762 - val_accuracy: 0.8150\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1177 - accuracy: 0.9712 - val_loss: 0.5406 - val_accuracy: 0.8150\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1116 - accuracy: 0.9688 - val_loss: 0.5498 - val_accuracy: 0.8250\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1075 - accuracy: 0.9737 - val_loss: 0.5478 - val_accuracy: 0.8150\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1061 - accuracy: 0.9725 - val_loss: 0.5585 - val_accuracy: 0.8200\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1093 - accuracy: 0.9725 - val_loss: 0.5697 - val_accuracy: 0.8100\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0904 - accuracy: 0.9787 - val_loss: 0.5635 - val_accuracy: 0.8100\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0957 - accuracy: 0.9737 - val_loss: 0.5614 - val_accuracy: 0.8200\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0927 - accuracy: 0.9737 - val_loss: 0.5605 - val_accuracy: 0.8150\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0932 - accuracy: 0.9825 - val_loss: 0.5680 - val_accuracy: 0.8200\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0972 - accuracy: 0.9750 - val_loss: 0.5453 - val_accuracy: 0.8150\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1095 - accuracy: 0.9638 - val_loss: 0.5582 - val_accuracy: 0.8100\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0868 - accuracy: 0.9812 - val_loss: 0.5747 - val_accuracy: 0.8050\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.5561 - val_accuracy: 0.8200\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0917 - accuracy: 0.9725 - val_loss: 0.5833 - val_accuracy: 0.8050\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0771 - accuracy: 0.9862 - val_loss: 0.5633 - val_accuracy: 0.8100\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0862 - accuracy: 0.9750 - val_loss: 0.5581 - val_accuracy: 0.8100\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0836 - accuracy: 0.9787 - val_loss: 0.5780 - val_accuracy: 0.8050\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.5842 - val_accuracy: 0.8100\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0754 - accuracy: 0.9862 - val_loss: 0.5741 - val_accuracy: 0.8100\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0848 - accuracy: 0.9800 - val_loss: 0.5772 - val_accuracy: 0.8150\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0910 - accuracy: 0.9800 - val_loss: 0.5792 - val_accuracy: 0.8150\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0755 - accuracy: 0.9800 - val_loss: 0.5741 - val_accuracy: 0.8150\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0722 - accuracy: 0.9800 - val_loss: 0.5584 - val_accuracy: 0.8100\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0728 - accuracy: 0.9812 - val_loss: 0.5874 - val_accuracy: 0.8050\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0849 - accuracy: 0.9812 - val_loss: 0.5532 - val_accuracy: 0.8250\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0728 - accuracy: 0.9762 - val_loss: 0.5638 - val_accuracy: 0.8250\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0685 - accuracy: 0.9850 - val_loss: 0.5892 - val_accuracy: 0.8150\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0712 - accuracy: 0.9812 - val_loss: 0.5744 - val_accuracy: 0.8200\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0793 - accuracy: 0.9750 - val_loss: 0.5580 - val_accuracy: 0.8150\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0760 - accuracy: 0.9750 - val_loss: 0.5626 - val_accuracy: 0.8100\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0710 - accuracy: 0.9800 - val_loss: 0.5881 - val_accuracy: 0.8150\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0733 - accuracy: 0.9775 - val_loss: 0.5859 - val_accuracy: 0.8150\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0642 - accuracy: 0.9875 - val_loss: 0.5533 - val_accuracy: 0.8200\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0508 - accuracy: 0.9912 - val_loss: 0.5665 - val_accuracy: 0.8200\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0577 - accuracy: 0.9837 - val_loss: 0.5786 - val_accuracy: 0.8250\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0567 - accuracy: 0.9875 - val_loss: 0.5692 - val_accuracy: 0.8200\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0702 - accuracy: 0.9812 - val_loss: 0.5782 - val_accuracy: 0.8100\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.5838 - val_accuracy: 0.8250\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0536 - accuracy: 0.9912 - val_loss: 0.5719 - val_accuracy: 0.8150\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0650 - accuracy: 0.9850 - val_loss: 0.5728 - val_accuracy: 0.8350\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0502 - accuracy: 0.9837 - val_loss: 0.5830 - val_accuracy: 0.8250\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.5691 - val_accuracy: 0.8300\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0529 - accuracy: 0.9825 - val_loss: 0.5735 - val_accuracy: 0.8150\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0500 - accuracy: 0.9862 - val_loss: 0.5719 - val_accuracy: 0.8150\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0587 - accuracy: 0.9850 - val_loss: 0.5728 - val_accuracy: 0.8200\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0574 - accuracy: 0.9850 - val_loss: 0.5842 - val_accuracy: 0.8200\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0489 - accuracy: 0.9850 - val_loss: 0.5731 - val_accuracy: 0.8250\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0526 - accuracy: 0.9862 - val_loss: 0.5960 - val_accuracy: 0.8300\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet152v2 (Functional)     (None, 10, 10, 2048)      58331648  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 58,595,210\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 195ms/step - loss: 2.5656 - accuracy: 0.1150\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 2.4288 - accuracy: 0.1887 - val_loss: 1.9138 - val_accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 15s 291ms/step - loss: 1.8781 - accuracy: 0.3600 - val_loss: 1.5167 - val_accuracy: 0.5500\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 1.5154 - accuracy: 0.5175 - val_loss: 1.2148 - val_accuracy: 0.6950\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 1.2344 - accuracy: 0.6100 - val_loss: 0.9892 - val_accuracy: 0.7600\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 1.0657 - accuracy: 0.6862 - val_loss: 0.8354 - val_accuracy: 0.7900\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.9411 - accuracy: 0.6913 - val_loss: 0.7428 - val_accuracy: 0.8050\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.7972 - accuracy: 0.7500 - val_loss: 0.6906 - val_accuracy: 0.8150\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.7083 - accuracy: 0.7962 - val_loss: 0.6293 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.6790 - accuracy: 0.7788 - val_loss: 0.6033 - val_accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.6200 - accuracy: 0.8000 - val_loss: 0.5711 - val_accuracy: 0.8250\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.5743 - accuracy: 0.8188 - val_loss: 0.5474 - val_accuracy: 0.8300\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.5092 - accuracy: 0.8525 - val_loss: 0.5297 - val_accuracy: 0.8350\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.5524 - accuracy: 0.8250 - val_loss: 0.5176 - val_accuracy: 0.8250\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.4926 - accuracy: 0.8512 - val_loss: 0.5031 - val_accuracy: 0.8300\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4265 - accuracy: 0.8662 - val_loss: 0.4861 - val_accuracy: 0.8350\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4483 - accuracy: 0.8600 - val_loss: 0.4891 - val_accuracy: 0.8300\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4088 - accuracy: 0.8650 - val_loss: 0.4767 - val_accuracy: 0.8250\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3711 - accuracy: 0.8800 - val_loss: 0.4678 - val_accuracy: 0.8200\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3544 - accuracy: 0.8813 - val_loss: 0.4616 - val_accuracy: 0.8400\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.3754 - accuracy: 0.8825 - val_loss: 0.4615 - val_accuracy: 0.8250\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3433 - accuracy: 0.9025 - val_loss: 0.4579 - val_accuracy: 0.8350\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3341 - accuracy: 0.8863 - val_loss: 0.4592 - val_accuracy: 0.8350\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3009 - accuracy: 0.9062 - val_loss: 0.4568 - val_accuracy: 0.8250\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2902 - accuracy: 0.9200 - val_loss: 0.4572 - val_accuracy: 0.8350\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2828 - accuracy: 0.9100 - val_loss: 0.4410 - val_accuracy: 0.8400\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2763 - accuracy: 0.9137 - val_loss: 0.4538 - val_accuracy: 0.8350\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2408 - accuracy: 0.9413 - val_loss: 0.4405 - val_accuracy: 0.8350\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2509 - accuracy: 0.9225 - val_loss: 0.4405 - val_accuracy: 0.8350\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2331 - accuracy: 0.9312 - val_loss: 0.4413 - val_accuracy: 0.8400\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2410 - accuracy: 0.9225 - val_loss: 0.4461 - val_accuracy: 0.8400\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2285 - accuracy: 0.9375 - val_loss: 0.4308 - val_accuracy: 0.8450\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2038 - accuracy: 0.9513 - val_loss: 0.4429 - val_accuracy: 0.8350\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1980 - accuracy: 0.9438 - val_loss: 0.4342 - val_accuracy: 0.8350\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2142 - accuracy: 0.9350 - val_loss: 0.4460 - val_accuracy: 0.8550\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2061 - accuracy: 0.9475 - val_loss: 0.4319 - val_accuracy: 0.8400\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1821 - accuracy: 0.9550 - val_loss: 0.4331 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1818 - accuracy: 0.9488 - val_loss: 0.4449 - val_accuracy: 0.8450\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1754 - accuracy: 0.9550 - val_loss: 0.4365 - val_accuracy: 0.8450\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1625 - accuracy: 0.9513 - val_loss: 0.4333 - val_accuracy: 0.8450\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1844 - accuracy: 0.9450 - val_loss: 0.4401 - val_accuracy: 0.8500\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1756 - accuracy: 0.9513 - val_loss: 0.4355 - val_accuracy: 0.8350\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1891 - accuracy: 0.9362 - val_loss: 0.4533 - val_accuracy: 0.8300\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1633 - accuracy: 0.9538 - val_loss: 0.4522 - val_accuracy: 0.8350\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1584 - accuracy: 0.9538 - val_loss: 0.4424 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.4464 - val_accuracy: 0.8300\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1438 - accuracy: 0.9625 - val_loss: 0.4299 - val_accuracy: 0.8500\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1512 - accuracy: 0.9613 - val_loss: 0.4445 - val_accuracy: 0.8300\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1313 - accuracy: 0.9675 - val_loss: 0.4650 - val_accuracy: 0.8300\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1383 - accuracy: 0.9588 - val_loss: 0.4415 - val_accuracy: 0.8350\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1213 - accuracy: 0.9625 - val_loss: 0.4523 - val_accuracy: 0.8400\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1283 - accuracy: 0.9600 - val_loss: 0.4377 - val_accuracy: 0.8350\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1360 - accuracy: 0.9638 - val_loss: 0.4377 - val_accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1382 - accuracy: 0.9625 - val_loss: 0.4258 - val_accuracy: 0.8500\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1382 - accuracy: 0.9663 - val_loss: 0.4330 - val_accuracy: 0.8400\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1362 - accuracy: 0.9513 - val_loss: 0.4233 - val_accuracy: 0.8400\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1203 - accuracy: 0.9663 - val_loss: 0.4371 - val_accuracy: 0.8250\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1234 - accuracy: 0.9650 - val_loss: 0.4251 - val_accuracy: 0.8350\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1180 - accuracy: 0.9638 - val_loss: 0.4375 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1057 - accuracy: 0.9725 - val_loss: 0.4352 - val_accuracy: 0.8300\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1062 - accuracy: 0.9762 - val_loss: 0.4278 - val_accuracy: 0.8350\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1075 - accuracy: 0.9675 - val_loss: 0.4590 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1155 - accuracy: 0.9737 - val_loss: 0.4405 - val_accuracy: 0.8450\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1164 - accuracy: 0.9700 - val_loss: 0.4460 - val_accuracy: 0.8450\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0986 - accuracy: 0.9762 - val_loss: 0.4467 - val_accuracy: 0.8500\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0903 - accuracy: 0.9737 - val_loss: 0.4366 - val_accuracy: 0.8400\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1208 - accuracy: 0.9600 - val_loss: 0.4502 - val_accuracy: 0.8250\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0996 - accuracy: 0.9775 - val_loss: 0.4436 - val_accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0830 - accuracy: 0.9812 - val_loss: 0.4322 - val_accuracy: 0.8500\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1099 - accuracy: 0.9700 - val_loss: 0.4454 - val_accuracy: 0.8450\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0819 - accuracy: 0.9825 - val_loss: 0.4546 - val_accuracy: 0.8350\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0962 - accuracy: 0.9775 - val_loss: 0.4376 - val_accuracy: 0.8450\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0910 - accuracy: 0.9775 - val_loss: 0.4607 - val_accuracy: 0.8150\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0873 - accuracy: 0.9762 - val_loss: 0.4422 - val_accuracy: 0.8200\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0941 - accuracy: 0.9787 - val_loss: 0.4584 - val_accuracy: 0.8250\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0849 - accuracy: 0.9800 - val_loss: 0.4669 - val_accuracy: 0.8200\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1027 - accuracy: 0.9737 - val_loss: 0.4526 - val_accuracy: 0.8400\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 0.4664 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0703 - accuracy: 0.9837 - val_loss: 0.4458 - val_accuracy: 0.8350\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0775 - accuracy: 0.9812 - val_loss: 0.4488 - val_accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0736 - accuracy: 0.9800 - val_loss: 0.4479 - val_accuracy: 0.8400\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0729 - accuracy: 0.9812 - val_loss: 0.4555 - val_accuracy: 0.8300\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0716 - accuracy: 0.9850 - val_loss: 0.4382 - val_accuracy: 0.8300\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0876 - accuracy: 0.9725 - val_loss: 0.4433 - val_accuracy: 0.8400\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0755 - accuracy: 0.9875 - val_loss: 0.4426 - val_accuracy: 0.8400\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0524 - accuracy: 0.9900 - val_loss: 0.4488 - val_accuracy: 0.8400\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0771 - accuracy: 0.9787 - val_loss: 0.4410 - val_accuracy: 0.8400\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0760 - accuracy: 0.9812 - val_loss: 0.4530 - val_accuracy: 0.8450\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0689 - accuracy: 0.9787 - val_loss: 0.4566 - val_accuracy: 0.8400\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 0.4569 - val_accuracy: 0.8450\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0668 - accuracy: 0.9837 - val_loss: 0.4652 - val_accuracy: 0.8400\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0691 - accuracy: 0.9837 - val_loss: 0.4594 - val_accuracy: 0.8350\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0636 - accuracy: 0.9825 - val_loss: 0.4609 - val_accuracy: 0.8350\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0654 - accuracy: 0.9825 - val_loss: 0.4657 - val_accuracy: 0.8300\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0623 - accuracy: 0.9850 - val_loss: 0.4673 - val_accuracy: 0.8400\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0602 - accuracy: 0.9837 - val_loss: 0.4600 - val_accuracy: 0.8450\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0594 - accuracy: 0.9862 - val_loss: 0.4601 - val_accuracy: 0.8450\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0585 - accuracy: 0.9825 - val_loss: 0.4475 - val_accuracy: 0.8500\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0596 - accuracy: 0.9850 - val_loss: 0.4569 - val_accuracy: 0.8350\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0508 - accuracy: 0.9887 - val_loss: 0.4572 - val_accuracy: 0.8550\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0500 - accuracy: 0.9862 - val_loss: 0.4678 - val_accuracy: 0.8250\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet152v2 (Functional)     (None, 10, 10, 2048)      58331648  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 58,595,210\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 194ms/step - loss: 2.6437 - accuracy: 0.1100\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 2.3755 - accuracy: 0.1800 - val_loss: 1.9273 - val_accuracy: 0.3400\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 15s 290ms/step - loss: 1.8530 - accuracy: 0.3487 - val_loss: 1.5058 - val_accuracy: 0.5600\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 1.4754 - accuracy: 0.5525 - val_loss: 1.2333 - val_accuracy: 0.6800\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 1.2488 - accuracy: 0.6150 - val_loss: 1.0353 - val_accuracy: 0.7300\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 1.0143 - accuracy: 0.6812 - val_loss: 0.8858 - val_accuracy: 0.7650\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.9124 - accuracy: 0.7150 - val_loss: 0.7900 - val_accuracy: 0.7800\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.7991 - accuracy: 0.7487 - val_loss: 0.7343 - val_accuracy: 0.7850\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 0.7330 - accuracy: 0.7625 - val_loss: 0.6859 - val_accuracy: 0.8050\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.6538 - accuracy: 0.8087 - val_loss: 0.6471 - val_accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.6142 - accuracy: 0.8100 - val_loss: 0.6298 - val_accuracy: 0.8150\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.5481 - accuracy: 0.8487 - val_loss: 0.6098 - val_accuracy: 0.8250\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.5254 - accuracy: 0.8325 - val_loss: 0.5857 - val_accuracy: 0.8250\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.4937 - accuracy: 0.8400 - val_loss: 0.5733 - val_accuracy: 0.8300\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4568 - accuracy: 0.8575 - val_loss: 0.5651 - val_accuracy: 0.8500\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4380 - accuracy: 0.8650 - val_loss: 0.5540 - val_accuracy: 0.8400\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.4621 - accuracy: 0.8550 - val_loss: 0.5475 - val_accuracy: 0.8500\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4115 - accuracy: 0.8675 - val_loss: 0.5453 - val_accuracy: 0.8550\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.3567 - accuracy: 0.8925 - val_loss: 0.5345 - val_accuracy: 0.8400\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.3528 - accuracy: 0.8988 - val_loss: 0.5130 - val_accuracy: 0.8500\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.3557 - accuracy: 0.8963 - val_loss: 0.5260 - val_accuracy: 0.8500\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.3301 - accuracy: 0.9000 - val_loss: 0.5329 - val_accuracy: 0.8500\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.3017 - accuracy: 0.9013 - val_loss: 0.5239 - val_accuracy: 0.8400\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2954 - accuracy: 0.9150 - val_loss: 0.5389 - val_accuracy: 0.8300\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2851 - accuracy: 0.9087 - val_loss: 0.5321 - val_accuracy: 0.8500\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2966 - accuracy: 0.9062 - val_loss: 0.5400 - val_accuracy: 0.8450\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2735 - accuracy: 0.9225 - val_loss: 0.5450 - val_accuracy: 0.8400\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2412 - accuracy: 0.9262 - val_loss: 0.5184 - val_accuracy: 0.8400\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2573 - accuracy: 0.9187 - val_loss: 0.5182 - val_accuracy: 0.8300\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2453 - accuracy: 0.9275 - val_loss: 0.5163 - val_accuracy: 0.8450\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2287 - accuracy: 0.9275 - val_loss: 0.5291 - val_accuracy: 0.8550\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2153 - accuracy: 0.9413 - val_loss: 0.5295 - val_accuracy: 0.8550\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2224 - accuracy: 0.9300 - val_loss: 0.5248 - val_accuracy: 0.8500\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2132 - accuracy: 0.9375 - val_loss: 0.5409 - val_accuracy: 0.8550\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1869 - accuracy: 0.9413 - val_loss: 0.5262 - val_accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2211 - accuracy: 0.9375 - val_loss: 0.5227 - val_accuracy: 0.8450\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.2107 - accuracy: 0.9375 - val_loss: 0.5196 - val_accuracy: 0.8350\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1844 - accuracy: 0.9400 - val_loss: 0.5376 - val_accuracy: 0.8400\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1628 - accuracy: 0.9538 - val_loss: 0.5241 - val_accuracy: 0.8500\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1553 - accuracy: 0.9663 - val_loss: 0.5274 - val_accuracy: 0.8350\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1682 - accuracy: 0.9500 - val_loss: 0.5462 - val_accuracy: 0.8400\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1536 - accuracy: 0.9563 - val_loss: 0.5334 - val_accuracy: 0.8500\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1540 - accuracy: 0.9488 - val_loss: 0.5307 - val_accuracy: 0.8450\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1485 - accuracy: 0.9563 - val_loss: 0.5306 - val_accuracy: 0.8500\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1541 - accuracy: 0.9513 - val_loss: 0.5311 - val_accuracy: 0.8600\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1709 - accuracy: 0.9513 - val_loss: 0.5353 - val_accuracy: 0.8450\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1372 - accuracy: 0.9600 - val_loss: 0.5406 - val_accuracy: 0.8500\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1321 - accuracy: 0.9613 - val_loss: 0.5538 - val_accuracy: 0.8500\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1366 - accuracy: 0.9538 - val_loss: 0.5332 - val_accuracy: 0.8550\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1264 - accuracy: 0.9725 - val_loss: 0.5353 - val_accuracy: 0.8450\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1335 - accuracy: 0.9625 - val_loss: 0.5544 - val_accuracy: 0.8450\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1229 - accuracy: 0.9737 - val_loss: 0.5436 - val_accuracy: 0.8500\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1146 - accuracy: 0.9675 - val_loss: 0.5497 - val_accuracy: 0.8500\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1146 - accuracy: 0.9712 - val_loss: 0.5501 - val_accuracy: 0.8500\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.1218 - accuracy: 0.9700 - val_loss: 0.5573 - val_accuracy: 0.8400\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1550 - accuracy: 0.9488 - val_loss: 0.5430 - val_accuracy: 0.8450\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0976 - accuracy: 0.9700 - val_loss: 0.5406 - val_accuracy: 0.8600\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1248 - accuracy: 0.9663 - val_loss: 0.5409 - val_accuracy: 0.8500\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1139 - accuracy: 0.9700 - val_loss: 0.5644 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0914 - accuracy: 0.9812 - val_loss: 0.5690 - val_accuracy: 0.8450\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1177 - accuracy: 0.9688 - val_loss: 0.5482 - val_accuracy: 0.8500\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0993 - accuracy: 0.9800 - val_loss: 0.5556 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1115 - accuracy: 0.9638 - val_loss: 0.5735 - val_accuracy: 0.8350\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0927 - accuracy: 0.9775 - val_loss: 0.5880 - val_accuracy: 0.8350\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0821 - accuracy: 0.9812 - val_loss: 0.5533 - val_accuracy: 0.8400\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0977 - accuracy: 0.9762 - val_loss: 0.5686 - val_accuracy: 0.8300\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0951 - accuracy: 0.9737 - val_loss: 0.5641 - val_accuracy: 0.8550\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0844 - accuracy: 0.9775 - val_loss: 0.5534 - val_accuracy: 0.8500\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0871 - accuracy: 0.9787 - val_loss: 0.5609 - val_accuracy: 0.8450\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 0.5644 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0901 - accuracy: 0.9750 - val_loss: 0.5659 - val_accuracy: 0.8500\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0999 - accuracy: 0.9712 - val_loss: 0.5722 - val_accuracy: 0.8350\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0845 - accuracy: 0.9825 - val_loss: 0.5872 - val_accuracy: 0.8400\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0885 - accuracy: 0.9737 - val_loss: 0.5904 - val_accuracy: 0.8300\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0941 - accuracy: 0.9712 - val_loss: 0.6114 - val_accuracy: 0.8350\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0832 - accuracy: 0.9800 - val_loss: 0.5864 - val_accuracy: 0.8300\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0850 - accuracy: 0.9812 - val_loss: 0.5973 - val_accuracy: 0.8350\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0815 - accuracy: 0.9737 - val_loss: 0.5975 - val_accuracy: 0.8350\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0773 - accuracy: 0.9812 - val_loss: 0.5887 - val_accuracy: 0.8150\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.5817 - val_accuracy: 0.8350\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0637 - accuracy: 0.9862 - val_loss: 0.5866 - val_accuracy: 0.8250\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0937 - accuracy: 0.9700 - val_loss: 0.5668 - val_accuracy: 0.8350\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0752 - accuracy: 0.9800 - val_loss: 0.5753 - val_accuracy: 0.8350\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0702 - accuracy: 0.9787 - val_loss: 0.5863 - val_accuracy: 0.8350\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0676 - accuracy: 0.9800 - val_loss: 0.6072 - val_accuracy: 0.8300\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0645 - accuracy: 0.9837 - val_loss: 0.5864 - val_accuracy: 0.8200\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0738 - accuracy: 0.9825 - val_loss: 0.5940 - val_accuracy: 0.8400\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0548 - accuracy: 0.9887 - val_loss: 0.6187 - val_accuracy: 0.8300\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0707 - accuracy: 0.9837 - val_loss: 0.6009 - val_accuracy: 0.8400\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0780 - accuracy: 0.9837 - val_loss: 0.6108 - val_accuracy: 0.8300\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.0516 - accuracy: 0.9887 - val_loss: 0.6018 - val_accuracy: 0.8350\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0717 - accuracy: 0.9837 - val_loss: 0.5886 - val_accuracy: 0.8450\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0621 - accuracy: 0.9837 - val_loss: 0.5833 - val_accuracy: 0.8400\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0569 - accuracy: 0.9900 - val_loss: 0.5705 - val_accuracy: 0.8550\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0535 - accuracy: 0.9912 - val_loss: 0.6126 - val_accuracy: 0.8350\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0666 - accuracy: 0.9825 - val_loss: 0.6027 - val_accuracy: 0.8450\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0580 - accuracy: 0.9875 - val_loss: 0.6125 - val_accuracy: 0.8450\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0508 - accuracy: 0.9887 - val_loss: 0.6145 - val_accuracy: 0.8350\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0750 - accuracy: 0.9800 - val_loss: 0.6099 - val_accuracy: 0.8500\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0551 - accuracy: 0.9850 - val_loss: 0.6111 - val_accuracy: 0.8200\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0465 - accuracy: 0.9912 - val_loss: 0.6009 - val_accuracy: 0.8450\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet152v2 (Functional)     (None, 10, 10, 2048)      58331648  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 58,595,210\n",
            "Trainable params: 263,562\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 196ms/step - loss: 2.5787 - accuracy: 0.0850\n",
            "Epoch 1/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 2.3798 - accuracy: 0.1675 - val_loss: 1.8712 - val_accuracy: 0.3950\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 15s 291ms/step - loss: 1.8350 - accuracy: 0.3750 - val_loss: 1.4795 - val_accuracy: 0.6200\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 1.4791 - accuracy: 0.5512 - val_loss: 1.1911 - val_accuracy: 0.6900\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 1.1977 - accuracy: 0.6375 - val_loss: 0.9956 - val_accuracy: 0.7100\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 1.0138 - accuracy: 0.6850 - val_loss: 0.8628 - val_accuracy: 0.7350\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.8740 - accuracy: 0.7350 - val_loss: 0.7806 - val_accuracy: 0.7300\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.7960 - accuracy: 0.7638 - val_loss: 0.7185 - val_accuracy: 0.7800\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.7022 - accuracy: 0.7763 - val_loss: 0.6665 - val_accuracy: 0.7750\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.6707 - accuracy: 0.7875 - val_loss: 0.6443 - val_accuracy: 0.7850\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.5885 - accuracy: 0.8138 - val_loss: 0.6149 - val_accuracy: 0.7950\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.5308 - accuracy: 0.8300 - val_loss: 0.5881 - val_accuracy: 0.7950\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.5415 - accuracy: 0.8325 - val_loss: 0.5721 - val_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.5009 - accuracy: 0.8425 - val_loss: 0.5548 - val_accuracy: 0.7900\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.4290 - accuracy: 0.8687 - val_loss: 0.5500 - val_accuracy: 0.7900\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.4398 - accuracy: 0.8662 - val_loss: 0.5403 - val_accuracy: 0.8050\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3994 - accuracy: 0.8675 - val_loss: 0.5312 - val_accuracy: 0.8050\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3725 - accuracy: 0.9000 - val_loss: 0.5228 - val_accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3570 - accuracy: 0.8900 - val_loss: 0.5105 - val_accuracy: 0.8150\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3589 - accuracy: 0.8875 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3387 - accuracy: 0.8963 - val_loss: 0.5066 - val_accuracy: 0.8150\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3269 - accuracy: 0.8975 - val_loss: 0.5016 - val_accuracy: 0.8050\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.3113 - accuracy: 0.8975 - val_loss: 0.4967 - val_accuracy: 0.8100\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.3059 - accuracy: 0.8925 - val_loss: 0.4843 - val_accuracy: 0.8100\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2788 - accuracy: 0.9175 - val_loss: 0.4937 - val_accuracy: 0.8150\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.2680 - accuracy: 0.9162 - val_loss: 0.4837 - val_accuracy: 0.8250\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.2736 - accuracy: 0.9062 - val_loss: 0.4770 - val_accuracy: 0.8250\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2561 - accuracy: 0.9225 - val_loss: 0.4916 - val_accuracy: 0.8100\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2407 - accuracy: 0.9275 - val_loss: 0.4834 - val_accuracy: 0.8250\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2211 - accuracy: 0.9413 - val_loss: 0.4798 - val_accuracy: 0.8100\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2151 - accuracy: 0.9413 - val_loss: 0.4822 - val_accuracy: 0.8200\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1852 - accuracy: 0.9550 - val_loss: 0.5014 - val_accuracy: 0.8150\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.2198 - accuracy: 0.9312 - val_loss: 0.4896 - val_accuracy: 0.8100\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2262 - accuracy: 0.9225 - val_loss: 0.4812 - val_accuracy: 0.8200\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2306 - accuracy: 0.9312 - val_loss: 0.4873 - val_accuracy: 0.8250\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1643 - accuracy: 0.9575 - val_loss: 0.4889 - val_accuracy: 0.8200\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2075 - accuracy: 0.9362 - val_loss: 0.4873 - val_accuracy: 0.8000\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.2011 - accuracy: 0.9375 - val_loss: 0.4720 - val_accuracy: 0.8200\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1857 - accuracy: 0.9400 - val_loss: 0.4687 - val_accuracy: 0.8250\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1701 - accuracy: 0.9550 - val_loss: 0.4856 - val_accuracy: 0.8150\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1870 - accuracy: 0.9550 - val_loss: 0.4730 - val_accuracy: 0.8150\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1664 - accuracy: 0.9500 - val_loss: 0.4621 - val_accuracy: 0.8150\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1542 - accuracy: 0.9613 - val_loss: 0.4688 - val_accuracy: 0.8200\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1568 - accuracy: 0.9488 - val_loss: 0.4669 - val_accuracy: 0.8050\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1521 - accuracy: 0.9525 - val_loss: 0.4496 - val_accuracy: 0.8250\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.1593 - accuracy: 0.9563 - val_loss: 0.4769 - val_accuracy: 0.8100\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1371 - accuracy: 0.9663 - val_loss: 0.4671 - val_accuracy: 0.8100\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1492 - accuracy: 0.9575 - val_loss: 0.4693 - val_accuracy: 0.8100\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1333 - accuracy: 0.9600 - val_loss: 0.4686 - val_accuracy: 0.8050\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1456 - accuracy: 0.9625 - val_loss: 0.4657 - val_accuracy: 0.8100\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1420 - accuracy: 0.9638 - val_loss: 0.4649 - val_accuracy: 0.8200\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1426 - accuracy: 0.9625 - val_loss: 0.4662 - val_accuracy: 0.8150\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1283 - accuracy: 0.9613 - val_loss: 0.4632 - val_accuracy: 0.8250\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1252 - accuracy: 0.9712 - val_loss: 0.4639 - val_accuracy: 0.8200\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1316 - accuracy: 0.9600 - val_loss: 0.4623 - val_accuracy: 0.8250\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1129 - accuracy: 0.9675 - val_loss: 0.4592 - val_accuracy: 0.8250\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1208 - accuracy: 0.9712 - val_loss: 0.4560 - val_accuracy: 0.8300\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1014 - accuracy: 0.9837 - val_loss: 0.4732 - val_accuracy: 0.8250\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1167 - accuracy: 0.9700 - val_loss: 0.4659 - val_accuracy: 0.8200\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.1121 - accuracy: 0.9737 - val_loss: 0.4623 - val_accuracy: 0.8200\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0973 - accuracy: 0.9762 - val_loss: 0.4755 - val_accuracy: 0.8250\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1097 - accuracy: 0.9663 - val_loss: 0.4672 - val_accuracy: 0.8100\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1014 - accuracy: 0.9725 - val_loss: 0.4859 - val_accuracy: 0.8200\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0959 - accuracy: 0.9750 - val_loss: 0.4871 - val_accuracy: 0.8250\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1113 - accuracy: 0.9737 - val_loss: 0.4728 - val_accuracy: 0.8200\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.1175 - accuracy: 0.9575 - val_loss: 0.4720 - val_accuracy: 0.8150\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0950 - accuracy: 0.9762 - val_loss: 0.4752 - val_accuracy: 0.8200\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.4678 - val_accuracy: 0.8300\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0951 - accuracy: 0.9737 - val_loss: 0.4652 - val_accuracy: 0.8250\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0930 - accuracy: 0.9700 - val_loss: 0.4647 - val_accuracy: 0.8350\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0957 - accuracy: 0.9712 - val_loss: 0.4683 - val_accuracy: 0.8200\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0919 - accuracy: 0.9775 - val_loss: 0.4731 - val_accuracy: 0.8300\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0795 - accuracy: 0.9787 - val_loss: 0.4836 - val_accuracy: 0.8350\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0803 - accuracy: 0.9825 - val_loss: 0.4778 - val_accuracy: 0.8150\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0875 - accuracy: 0.9762 - val_loss: 0.4733 - val_accuracy: 0.8150\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0709 - accuracy: 0.9812 - val_loss: 0.4834 - val_accuracy: 0.8300\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0643 - accuracy: 0.9912 - val_loss: 0.4781 - val_accuracy: 0.8300\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0850 - accuracy: 0.9762 - val_loss: 0.4768 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0783 - accuracy: 0.9737 - val_loss: 0.4806 - val_accuracy: 0.8050\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0731 - accuracy: 0.9787 - val_loss: 0.4860 - val_accuracy: 0.8400\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0714 - accuracy: 0.9787 - val_loss: 0.4908 - val_accuracy: 0.8300\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0666 - accuracy: 0.9812 - val_loss: 0.5025 - val_accuracy: 0.8250\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0605 - accuracy: 0.9887 - val_loss: 0.4969 - val_accuracy: 0.8300\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0632 - accuracy: 0.9800 - val_loss: 0.4968 - val_accuracy: 0.8300\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0801 - accuracy: 0.9737 - val_loss: 0.4921 - val_accuracy: 0.8350\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0628 - accuracy: 0.9825 - val_loss: 0.4940 - val_accuracy: 0.8350\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0581 - accuracy: 0.9850 - val_loss: 0.4911 - val_accuracy: 0.8350\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0827 - accuracy: 0.9750 - val_loss: 0.4891 - val_accuracy: 0.8300\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0694 - accuracy: 0.9850 - val_loss: 0.4856 - val_accuracy: 0.8450\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.0542 - accuracy: 0.9850 - val_loss: 0.4905 - val_accuracy: 0.8400\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0545 - accuracy: 0.9875 - val_loss: 0.4994 - val_accuracy: 0.8300\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0486 - accuracy: 0.9900 - val_loss: 0.4838 - val_accuracy: 0.8350\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0594 - accuracy: 0.9837 - val_loss: 0.4752 - val_accuracy: 0.8450\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0662 - accuracy: 0.9787 - val_loss: 0.4796 - val_accuracy: 0.8350\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.0668 - accuracy: 0.9825 - val_loss: 0.4799 - val_accuracy: 0.8400\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 0.4939 - val_accuracy: 0.8350\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.5016 - val_accuracy: 0.8350\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.4915 - val_accuracy: 0.8350\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 14s 282ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.5023 - val_accuracy: 0.8350\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0476 - accuracy: 0.9912 - val_loss: 0.4917 - val_accuracy: 0.8450\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0462 - accuracy: 0.9900 - val_loss: 0.5063 - val_accuracy: 0.8350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf32dd9-8c58-4896-b93c-83538acca30a"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy after training\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.08900000080466271\n",
            "Final accuracy: 0.8480000138282776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a17c23ef-69b1-40f1-9cfd-58401ad86b4e"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7bf71ace-d247-44bf-a2ac-d6ab79d7337a"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}