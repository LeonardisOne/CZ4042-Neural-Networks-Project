{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials_xception_balanced_cross_validated_fine_tuned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6be429-621b-4697-f746-209b6694bb8c"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672b5d2c-0c43-4a38-eee9-05b34075bebe"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create list containing the dataset for each class\n",
        "ds_each_class = [tf.data.Dataset.list_files(str(data_dir/f'{class_name}/*.jpg'), shuffle=False) for class_name in class_names]\n",
        "\n",
        "# shuffle the 100 images in each class with the random seed value of 123 before training\n",
        "for index, ds in enumerate(ds_each_class):\n",
        "  ds_each_class[index] = ds.shuffle(image_count//10, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_LijJpqbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e52ec4-ec3a-4840-d689-422f2caf6e0a"
      },
      "source": [
        "# display some samples from a class to verify each class dataset contains only the class images\n",
        "for f in ds_each_class[0].take(10):\n",
        "  print(f.numpy())\n",
        "\n",
        "for f in ds_each_class[1].take(10):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'FMD/image/fabric/fabric_moderate_037_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_004_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_008_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_003_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_017_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_001_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_032_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_030_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_038_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_009_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_037_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_004_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_008_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_053_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_067_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_051_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_032_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_030_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_038_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_059_new.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split first class dataset into 5 equal sized partitions\n",
        "# then for remaining classes' datasets do the same and add to corresponding partition\n",
        "# for 5-fold cross validation\n",
        "A = ds_each_class[0].shard(num_shards=5, index=0)\n",
        "B = ds_each_class[0].shard(num_shards=5, index=1)\n",
        "C = ds_each_class[0].shard(num_shards=5, index=2)\n",
        "D = ds_each_class[0].shard(num_shards=5, index=3)\n",
        "E = ds_each_class[0].shard(num_shards=5, index=4)\n",
        "for i in range(1, 10):\n",
        "  A = A.concatenate(ds_each_class[i].shard(num_shards=5, index=0))\n",
        "  B = B.concatenate(ds_each_class[i].shard(num_shards=5, index=1))\n",
        "  C = C.concatenate(ds_each_class[i].shard(num_shards=5, index=2))\n",
        "  D = D.concatenate(ds_each_class[i].shard(num_shards=5, index=3))\n",
        "  E = E.concatenate(ds_each_class[i].shard(num_shards=5, index=4))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35609a1-9750-40ac-b380-c330e4145ab0"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c547ed4c-cff8-4c9b-9e00-46ac5cde136a"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.xception.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 115"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1853143b-2fc1-4dff-e60d-88a76cb15dce"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.Xception(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 124ms/step - loss: 2.3721 - accuracy: 0.0800\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 8s 158ms/step - loss: 2.2828 - accuracy: 0.1462 - val_loss: 2.2291 - val_accuracy: 0.1850\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 2.1372 - accuracy: 0.2562 - val_loss: 2.1026 - val_accuracy: 0.2900\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 1.9976 - accuracy: 0.4225 - val_loss: 1.9821 - val_accuracy: 0.4700\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 8s 166ms/step - loss: 1.8803 - accuracy: 0.5375 - val_loss: 1.8709 - val_accuracy: 0.5400\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 1.7504 - accuracy: 0.6025 - val_loss: 1.7709 - val_accuracy: 0.6150\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.6596 - accuracy: 0.6950 - val_loss: 1.6765 - val_accuracy: 0.6600\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.5678 - accuracy: 0.7138 - val_loss: 1.5903 - val_accuracy: 0.7200\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.4819 - accuracy: 0.7425 - val_loss: 1.5147 - val_accuracy: 0.7150\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.4127 - accuracy: 0.7462 - val_loss: 1.4465 - val_accuracy: 0.7550\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.3410 - accuracy: 0.7575 - val_loss: 1.3788 - val_accuracy: 0.7800\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.2698 - accuracy: 0.7850 - val_loss: 1.3223 - val_accuracy: 0.7900\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 1.2111 - accuracy: 0.8012 - val_loss: 1.2690 - val_accuracy: 0.8100\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 170ms/step - loss: 1.1729 - accuracy: 0.7812 - val_loss: 1.2227 - val_accuracy: 0.8050\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.1236 - accuracy: 0.7900 - val_loss: 1.1799 - val_accuracy: 0.8200\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0719 - accuracy: 0.8150 - val_loss: 1.1384 - val_accuracy: 0.8150\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0255 - accuracy: 0.8250 - val_loss: 1.1020 - val_accuracy: 0.8200\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9822 - accuracy: 0.8350 - val_loss: 1.0706 - val_accuracy: 0.8300\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9516 - accuracy: 0.8462 - val_loss: 1.0371 - val_accuracy: 0.8350\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.9260 - accuracy: 0.8225 - val_loss: 1.0099 - val_accuracy: 0.8350\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.8997 - accuracy: 0.8338 - val_loss: 0.9829 - val_accuracy: 0.8400\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.8667 - accuracy: 0.8525 - val_loss: 0.9597 - val_accuracy: 0.8400\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8326 - accuracy: 0.8413 - val_loss: 0.9353 - val_accuracy: 0.8450\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8101 - accuracy: 0.8512 - val_loss: 0.9134 - val_accuracy: 0.8350\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7764 - accuracy: 0.8575 - val_loss: 0.8958 - val_accuracy: 0.8350\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7770 - accuracy: 0.8562 - val_loss: 0.8775 - val_accuracy: 0.8400\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7487 - accuracy: 0.8625 - val_loss: 0.8595 - val_accuracy: 0.8450\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7640 - accuracy: 0.8462 - val_loss: 0.8443 - val_accuracy: 0.8400\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7044 - accuracy: 0.8675 - val_loss: 0.8287 - val_accuracy: 0.8400\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6999 - accuracy: 0.8712 - val_loss: 0.8141 - val_accuracy: 0.8550\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.6770 - accuracy: 0.8788 - val_loss: 0.8038 - val_accuracy: 0.8450\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6755 - accuracy: 0.8637 - val_loss: 0.7884 - val_accuracy: 0.8400\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6575 - accuracy: 0.8650 - val_loss: 0.7766 - val_accuracy: 0.8350\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.6403 - accuracy: 0.8625 - val_loss: 0.7654 - val_accuracy: 0.8350\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.6361 - accuracy: 0.8650 - val_loss: 0.7572 - val_accuracy: 0.8350\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6240 - accuracy: 0.8763 - val_loss: 0.7487 - val_accuracy: 0.8450\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6100 - accuracy: 0.8825 - val_loss: 0.7391 - val_accuracy: 0.8300\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6150 - accuracy: 0.8712 - val_loss: 0.7266 - val_accuracy: 0.8400\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5880 - accuracy: 0.8750 - val_loss: 0.7183 - val_accuracy: 0.8450\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5781 - accuracy: 0.8863 - val_loss: 0.7101 - val_accuracy: 0.8450\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5742 - accuracy: 0.8775 - val_loss: 0.7041 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5523 - accuracy: 0.8863 - val_loss: 0.6988 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5532 - accuracy: 0.8888 - val_loss: 0.6905 - val_accuracy: 0.8450\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5348 - accuracy: 0.8913 - val_loss: 0.6835 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5448 - accuracy: 0.8775 - val_loss: 0.6754 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5180 - accuracy: 0.8963 - val_loss: 0.6717 - val_accuracy: 0.8450\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5167 - accuracy: 0.8950 - val_loss: 0.6652 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4977 - accuracy: 0.8875 - val_loss: 0.6578 - val_accuracy: 0.8450\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4975 - accuracy: 0.8863 - val_loss: 0.6560 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4978 - accuracy: 0.8950 - val_loss: 0.6482 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4930 - accuracy: 0.9000 - val_loss: 0.6427 - val_accuracy: 0.8400\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.6427 - accuracy: 0.8400\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 6,808,874\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.3799 - accuracy: 0.8975 - val_loss: 0.5298 - val_accuracy: 0.8450\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.3092 - accuracy: 0.8975 - val_loss: 0.5034 - val_accuracy: 0.8550\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2533 - accuracy: 0.9100 - val_loss: 0.4786 - val_accuracy: 0.8600\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2638 - accuracy: 0.9050 - val_loss: 0.4793 - val_accuracy: 0.8600\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2169 - accuracy: 0.9262 - val_loss: 0.4688 - val_accuracy: 0.8650\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.2026 - accuracy: 0.9287 - val_loss: 0.4698 - val_accuracy: 0.8650\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1950 - accuracy: 0.9400 - val_loss: 0.4834 - val_accuracy: 0.8600\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1916 - accuracy: 0.9350 - val_loss: 0.4882 - val_accuracy: 0.8650\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1586 - accuracy: 0.9425 - val_loss: 0.4744 - val_accuracy: 0.8600\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1583 - accuracy: 0.9475 - val_loss: 0.4869 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1421 - accuracy: 0.9488 - val_loss: 0.4918 - val_accuracy: 0.8750\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1243 - accuracy: 0.9663 - val_loss: 0.4934 - val_accuracy: 0.8600\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1132 - accuracy: 0.9688 - val_loss: 0.5178 - val_accuracy: 0.8550\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1067 - accuracy: 0.9650 - val_loss: 0.5305 - val_accuracy: 0.8600\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1214 - accuracy: 0.9538 - val_loss: 0.5232 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.0829 - accuracy: 0.9800 - val_loss: 0.5189 - val_accuracy: 0.8700\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.0827 - accuracy: 0.9800 - val_loss: 0.4962 - val_accuracy: 0.8650\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.0892 - accuracy: 0.9712 - val_loss: 0.5493 - val_accuracy: 0.8500\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.5223 - val_accuracy: 0.8550\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 0.5353 - val_accuracy: 0.8450\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.0669 - accuracy: 0.9825 - val_loss: 0.5674 - val_accuracy: 0.8400\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 2.3416 - accuracy: 0.0800\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 2.3071 - accuracy: 0.1125 - val_loss: 2.2003 - val_accuracy: 0.1950\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.1473 - accuracy: 0.2438 - val_loss: 2.0713 - val_accuracy: 0.3450\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 2.0182 - accuracy: 0.3913 - val_loss: 1.9523 - val_accuracy: 0.4450\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 1.9210 - accuracy: 0.4600 - val_loss: 1.8417 - val_accuracy: 0.5650\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.7909 - accuracy: 0.5500 - val_loss: 1.7400 - val_accuracy: 0.6450\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.7022 - accuracy: 0.6375 - val_loss: 1.6479 - val_accuracy: 0.6650\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.6005 - accuracy: 0.6787 - val_loss: 1.5630 - val_accuracy: 0.7150\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.5144 - accuracy: 0.7262 - val_loss: 1.4837 - val_accuracy: 0.7300\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.4298 - accuracy: 0.7525 - val_loss: 1.4132 - val_accuracy: 0.7450\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.3613 - accuracy: 0.7700 - val_loss: 1.3494 - val_accuracy: 0.7400\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.3129 - accuracy: 0.7563 - val_loss: 1.2922 - val_accuracy: 0.7600\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.2392 - accuracy: 0.7950 - val_loss: 1.2380 - val_accuracy: 0.7750\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.1837 - accuracy: 0.7925 - val_loss: 1.1912 - val_accuracy: 0.7800\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.1535 - accuracy: 0.7862 - val_loss: 1.1461 - val_accuracy: 0.7800\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0906 - accuracy: 0.8112 - val_loss: 1.1057 - val_accuracy: 0.7800\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0550 - accuracy: 0.8138 - val_loss: 1.0688 - val_accuracy: 0.7750\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0291 - accuracy: 0.8138 - val_loss: 1.0354 - val_accuracy: 0.7800\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.9784 - accuracy: 0.8275 - val_loss: 1.0051 - val_accuracy: 0.7800\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9395 - accuracy: 0.8400 - val_loss: 0.9761 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9234 - accuracy: 0.8300 - val_loss: 0.9491 - val_accuracy: 0.7900\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8770 - accuracy: 0.8487 - val_loss: 0.9252 - val_accuracy: 0.7800\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8470 - accuracy: 0.8425 - val_loss: 0.9028 - val_accuracy: 0.7950\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8470 - accuracy: 0.8325 - val_loss: 0.8822 - val_accuracy: 0.7900\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8012 - accuracy: 0.8537 - val_loss: 0.8638 - val_accuracy: 0.7900\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7862 - accuracy: 0.8625 - val_loss: 0.8455 - val_accuracy: 0.8000\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7578 - accuracy: 0.8687 - val_loss: 0.8275 - val_accuracy: 0.7950\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7533 - accuracy: 0.8600 - val_loss: 0.8110 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.7315 - accuracy: 0.8600 - val_loss: 0.7968 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.7229 - accuracy: 0.8687 - val_loss: 0.7827 - val_accuracy: 0.7950\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6957 - accuracy: 0.8625 - val_loss: 0.7683 - val_accuracy: 0.8000\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6757 - accuracy: 0.8700 - val_loss: 0.7573 - val_accuracy: 0.8000\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6579 - accuracy: 0.8650 - val_loss: 0.7458 - val_accuracy: 0.7950\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6454 - accuracy: 0.8888 - val_loss: 0.7342 - val_accuracy: 0.7950\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6511 - accuracy: 0.8712 - val_loss: 0.7239 - val_accuracy: 0.7950\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6348 - accuracy: 0.8763 - val_loss: 0.7124 - val_accuracy: 0.8000\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6099 - accuracy: 0.8875 - val_loss: 0.7027 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5927 - accuracy: 0.8788 - val_loss: 0.6958 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6010 - accuracy: 0.8913 - val_loss: 0.6841 - val_accuracy: 0.8000\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6001 - accuracy: 0.8813 - val_loss: 0.6752 - val_accuracy: 0.8000\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5789 - accuracy: 0.8913 - val_loss: 0.6699 - val_accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5654 - accuracy: 0.8975 - val_loss: 0.6630 - val_accuracy: 0.8050\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5715 - accuracy: 0.8763 - val_loss: 0.6568 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5526 - accuracy: 0.8788 - val_loss: 0.6498 - val_accuracy: 0.8000\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5234 - accuracy: 0.9025 - val_loss: 0.6422 - val_accuracy: 0.7950\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.5079 - accuracy: 0.8963 - val_loss: 0.6339 - val_accuracy: 0.8050\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5123 - accuracy: 0.9038 - val_loss: 0.6283 - val_accuracy: 0.8000\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5280 - accuracy: 0.8825 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4990 - accuracy: 0.9112 - val_loss: 0.6192 - val_accuracy: 0.8000\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5116 - accuracy: 0.8875 - val_loss: 0.6135 - val_accuracy: 0.8000\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5014 - accuracy: 0.8950 - val_loss: 0.6084 - val_accuracy: 0.8050\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.6084 - accuracy: 0.8050\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 6,808,874\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.4105 - accuracy: 0.8938 - val_loss: 0.4920 - val_accuracy: 0.8050\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.3055 - accuracy: 0.9013 - val_loss: 0.4700 - val_accuracy: 0.8100\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.2744 - accuracy: 0.9075 - val_loss: 0.4488 - val_accuracy: 0.8150\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2480 - accuracy: 0.9250 - val_loss: 0.4325 - val_accuracy: 0.8250\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2598 - accuracy: 0.9212 - val_loss: 0.4437 - val_accuracy: 0.8150\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.2127 - accuracy: 0.9425 - val_loss: 0.4416 - val_accuracy: 0.8300\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1679 - accuracy: 0.9538 - val_loss: 0.4430 - val_accuracy: 0.8450\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1921 - accuracy: 0.9275 - val_loss: 0.4321 - val_accuracy: 0.8550\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1698 - accuracy: 0.9450 - val_loss: 0.4275 - val_accuracy: 0.8600\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1576 - accuracy: 0.9463 - val_loss: 0.4186 - val_accuracy: 0.8650\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1400 - accuracy: 0.9538 - val_loss: 0.4525 - val_accuracy: 0.8550\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1281 - accuracy: 0.9588 - val_loss: 0.4262 - val_accuracy: 0.8550\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1205 - accuracy: 0.9650 - val_loss: 0.4206 - val_accuracy: 0.8550\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0912 - accuracy: 0.9762 - val_loss: 0.4505 - val_accuracy: 0.8700\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1197 - accuracy: 0.9550 - val_loss: 0.4382 - val_accuracy: 0.8750\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0888 - accuracy: 0.9725 - val_loss: 0.4393 - val_accuracy: 0.8650\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0981 - accuracy: 0.9675 - val_loss: 0.4515 - val_accuracy: 0.8700\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0885 - accuracy: 0.9613 - val_loss: 0.4593 - val_accuracy: 0.8550\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0899 - accuracy: 0.9675 - val_loss: 0.4437 - val_accuracy: 0.8650\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0802 - accuracy: 0.9700 - val_loss: 0.4468 - val_accuracy: 0.8600\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.4844 - val_accuracy: 0.8550\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 2.3281 - accuracy: 0.1200\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 2.2895 - accuracy: 0.1462 - val_loss: 2.1913 - val_accuracy: 0.2350\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.1513 - accuracy: 0.2500 - val_loss: 2.0704 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 1.9953 - accuracy: 0.3825 - val_loss: 1.9583 - val_accuracy: 0.5100\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.8931 - accuracy: 0.4850 - val_loss: 1.8560 - val_accuracy: 0.5850\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.7828 - accuracy: 0.5562 - val_loss: 1.7598 - val_accuracy: 0.6350\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.6780 - accuracy: 0.6425 - val_loss: 1.6734 - val_accuracy: 0.6750\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.5763 - accuracy: 0.6762 - val_loss: 1.5929 - val_accuracy: 0.7000\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.4785 - accuracy: 0.7325 - val_loss: 1.5190 - val_accuracy: 0.7150\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.3956 - accuracy: 0.7437 - val_loss: 1.4533 - val_accuracy: 0.7350\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.3247 - accuracy: 0.7887 - val_loss: 1.3917 - val_accuracy: 0.7450\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.2872 - accuracy: 0.7600 - val_loss: 1.3370 - val_accuracy: 0.7450\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.2077 - accuracy: 0.8087 - val_loss: 1.2869 - val_accuracy: 0.7550\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.1712 - accuracy: 0.7975 - val_loss: 1.2415 - val_accuracy: 0.7550\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.1188 - accuracy: 0.8125 - val_loss: 1.1974 - val_accuracy: 0.7650\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.0623 - accuracy: 0.7950 - val_loss: 1.1576 - val_accuracy: 0.7700\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0377 - accuracy: 0.8275 - val_loss: 1.1223 - val_accuracy: 0.7750\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9997 - accuracy: 0.8087 - val_loss: 1.0906 - val_accuracy: 0.7850\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9676 - accuracy: 0.8263 - val_loss: 1.0585 - val_accuracy: 0.7800\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9213 - accuracy: 0.8325 - val_loss: 1.0302 - val_accuracy: 0.8000\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9047 - accuracy: 0.8375 - val_loss: 1.0050 - val_accuracy: 0.7900\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8698 - accuracy: 0.8338 - val_loss: 0.9811 - val_accuracy: 0.8000\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8502 - accuracy: 0.8313 - val_loss: 0.9568 - val_accuracy: 0.7900\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8245 - accuracy: 0.8288 - val_loss: 0.9367 - val_accuracy: 0.7850\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7892 - accuracy: 0.8438 - val_loss: 0.9215 - val_accuracy: 0.7950\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7856 - accuracy: 0.8475 - val_loss: 0.9004 - val_accuracy: 0.7950\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7703 - accuracy: 0.8388 - val_loss: 0.8826 - val_accuracy: 0.8000\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7392 - accuracy: 0.8575 - val_loss: 0.8674 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7141 - accuracy: 0.8850 - val_loss: 0.8511 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7047 - accuracy: 0.8500 - val_loss: 0.8373 - val_accuracy: 0.8000\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6860 - accuracy: 0.8600 - val_loss: 0.8238 - val_accuracy: 0.8000\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6895 - accuracy: 0.8487 - val_loss: 0.8115 - val_accuracy: 0.8050\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6622 - accuracy: 0.8737 - val_loss: 0.7979 - val_accuracy: 0.8050\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6366 - accuracy: 0.8687 - val_loss: 0.7859 - val_accuracy: 0.8100\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6259 - accuracy: 0.8712 - val_loss: 0.7776 - val_accuracy: 0.8100\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6188 - accuracy: 0.8775 - val_loss: 0.7655 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5960 - accuracy: 0.8712 - val_loss: 0.7559 - val_accuracy: 0.8200\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5951 - accuracy: 0.8662 - val_loss: 0.7495 - val_accuracy: 0.8100\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5940 - accuracy: 0.8712 - val_loss: 0.7396 - val_accuracy: 0.8150\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5757 - accuracy: 0.8775 - val_loss: 0.7331 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5624 - accuracy: 0.8763 - val_loss: 0.7233 - val_accuracy: 0.8150\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5562 - accuracy: 0.8863 - val_loss: 0.7154 - val_accuracy: 0.8200\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5437 - accuracy: 0.8875 - val_loss: 0.7075 - val_accuracy: 0.8250\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5400 - accuracy: 0.8963 - val_loss: 0.6997 - val_accuracy: 0.8150\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5437 - accuracy: 0.8838 - val_loss: 0.6938 - val_accuracy: 0.8250\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5336 - accuracy: 0.8825 - val_loss: 0.6883 - val_accuracy: 0.8200\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5152 - accuracy: 0.8900 - val_loss: 0.6853 - val_accuracy: 0.8150\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5211 - accuracy: 0.8975 - val_loss: 0.6778 - val_accuracy: 0.8300\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5056 - accuracy: 0.8913 - val_loss: 0.6698 - val_accuracy: 0.8250\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4940 - accuracy: 0.8900 - val_loss: 0.6661 - val_accuracy: 0.8250\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.4999 - accuracy: 0.8988 - val_loss: 0.6594 - val_accuracy: 0.8250\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.6594 - accuracy: 0.8250\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 6,808,874\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.4073 - accuracy: 0.8800 - val_loss: 0.5334 - val_accuracy: 0.8300\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.3322 - accuracy: 0.8888 - val_loss: 0.4949 - val_accuracy: 0.8500\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.2881 - accuracy: 0.9062 - val_loss: 0.4869 - val_accuracy: 0.8300\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.2476 - accuracy: 0.9187 - val_loss: 0.4818 - val_accuracy: 0.8400\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2338 - accuracy: 0.9212 - val_loss: 0.4773 - val_accuracy: 0.8350\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2077 - accuracy: 0.9350 - val_loss: 0.4585 - val_accuracy: 0.8550\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.2200 - accuracy: 0.9237 - val_loss: 0.4691 - val_accuracy: 0.8450\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1587 - accuracy: 0.9525 - val_loss: 0.4819 - val_accuracy: 0.8500\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1688 - accuracy: 0.9475 - val_loss: 0.4684 - val_accuracy: 0.8300\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1459 - accuracy: 0.9563 - val_loss: 0.4662 - val_accuracy: 0.8450\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1458 - accuracy: 0.9550 - val_loss: 0.4771 - val_accuracy: 0.8400\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1303 - accuracy: 0.9588 - val_loss: 0.4598 - val_accuracy: 0.8300\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1443 - accuracy: 0.9513 - val_loss: 0.4604 - val_accuracy: 0.8350\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1138 - accuracy: 0.9675 - val_loss: 0.4561 - val_accuracy: 0.8350\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0920 - accuracy: 0.9737 - val_loss: 0.4930 - val_accuracy: 0.8400\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1049 - accuracy: 0.9725 - val_loss: 0.4824 - val_accuracy: 0.8250\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0943 - accuracy: 0.9638 - val_loss: 0.4939 - val_accuracy: 0.8250\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0865 - accuracy: 0.9712 - val_loss: 0.4928 - val_accuracy: 0.8300\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.5143 - val_accuracy: 0.8400\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.0616 - accuracy: 0.9812 - val_loss: 0.5498 - val_accuracy: 0.8100\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0600 - accuracy: 0.9875 - val_loss: 0.4979 - val_accuracy: 0.8200\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 2.3820 - accuracy: 0.1050\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 2.3331 - accuracy: 0.1037 - val_loss: 2.2347 - val_accuracy: 0.2200\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 2.1727 - accuracy: 0.2488 - val_loss: 2.1071 - val_accuracy: 0.3550\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 176ms/step - loss: 2.0503 - accuracy: 0.3675 - val_loss: 1.9897 - val_accuracy: 0.4850\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.9232 - accuracy: 0.4688 - val_loss: 1.8808 - val_accuracy: 0.5800\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.8149 - accuracy: 0.5300 - val_loss: 1.7794 - val_accuracy: 0.6500\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.7046 - accuracy: 0.6137 - val_loss: 1.6910 - val_accuracy: 0.6700\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.6020 - accuracy: 0.6862 - val_loss: 1.6051 - val_accuracy: 0.7050\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.5316 - accuracy: 0.7013 - val_loss: 1.5283 - val_accuracy: 0.6950\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.4483 - accuracy: 0.7337 - val_loss: 1.4597 - val_accuracy: 0.7150\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.3750 - accuracy: 0.7750 - val_loss: 1.3977 - val_accuracy: 0.7200\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.3178 - accuracy: 0.7625 - val_loss: 1.3394 - val_accuracy: 0.7350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.2530 - accuracy: 0.7588 - val_loss: 1.2885 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.1998 - accuracy: 0.7850 - val_loss: 1.2419 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 1.1405 - accuracy: 0.7937 - val_loss: 1.1990 - val_accuracy: 0.7550\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.1018 - accuracy: 0.8037 - val_loss: 1.1605 - val_accuracy: 0.7700\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.0661 - accuracy: 0.7987 - val_loss: 1.1247 - val_accuracy: 0.7700\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0184 - accuracy: 0.8175 - val_loss: 1.0896 - val_accuracy: 0.7650\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9818 - accuracy: 0.8200 - val_loss: 1.0612 - val_accuracy: 0.7750\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.9494 - accuracy: 0.8325 - val_loss: 1.0349 - val_accuracy: 0.7700\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9163 - accuracy: 0.8350 - val_loss: 1.0080 - val_accuracy: 0.7650\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8948 - accuracy: 0.8525 - val_loss: 0.9850 - val_accuracy: 0.7750\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8685 - accuracy: 0.8388 - val_loss: 0.9633 - val_accuracy: 0.7700\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.8398 - accuracy: 0.8313 - val_loss: 0.9447 - val_accuracy: 0.7750\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8192 - accuracy: 0.8288 - val_loss: 0.9236 - val_accuracy: 0.7650\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7919 - accuracy: 0.8425 - val_loss: 0.9059 - val_accuracy: 0.7750\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7749 - accuracy: 0.8500 - val_loss: 0.8894 - val_accuracy: 0.7700\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7533 - accuracy: 0.8500 - val_loss: 0.8740 - val_accuracy: 0.7850\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7382 - accuracy: 0.8587 - val_loss: 0.8597 - val_accuracy: 0.7850\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.7035 - accuracy: 0.8637 - val_loss: 0.8459 - val_accuracy: 0.7800\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7097 - accuracy: 0.8525 - val_loss: 0.8322 - val_accuracy: 0.7800\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6836 - accuracy: 0.8712 - val_loss: 0.8192 - val_accuracy: 0.7850\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6770 - accuracy: 0.8537 - val_loss: 0.8080 - val_accuracy: 0.7900\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6522 - accuracy: 0.8838 - val_loss: 0.7963 - val_accuracy: 0.7900\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6733 - accuracy: 0.8575 - val_loss: 0.7846 - val_accuracy: 0.7950\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6443 - accuracy: 0.8562 - val_loss: 0.7758 - val_accuracy: 0.7950\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6086 - accuracy: 0.8775 - val_loss: 0.7647 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6180 - accuracy: 0.8750 - val_loss: 0.7572 - val_accuracy: 0.8050\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5939 - accuracy: 0.8813 - val_loss: 0.7486 - val_accuracy: 0.8050\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5911 - accuracy: 0.8737 - val_loss: 0.7389 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5680 - accuracy: 0.8863 - val_loss: 0.7336 - val_accuracy: 0.8100\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5722 - accuracy: 0.8825 - val_loss: 0.7243 - val_accuracy: 0.8150\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5686 - accuracy: 0.8763 - val_loss: 0.7183 - val_accuracy: 0.8050\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5528 - accuracy: 0.8788 - val_loss: 0.7102 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5551 - accuracy: 0.8737 - val_loss: 0.7050 - val_accuracy: 0.8100\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5341 - accuracy: 0.9013 - val_loss: 0.6962 - val_accuracy: 0.8150\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5344 - accuracy: 0.8850 - val_loss: 0.6931 - val_accuracy: 0.8050\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5123 - accuracy: 0.8938 - val_loss: 0.6864 - val_accuracy: 0.8100\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5097 - accuracy: 0.8838 - val_loss: 0.6809 - val_accuracy: 0.8200\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5109 - accuracy: 0.8863 - val_loss: 0.6757 - val_accuracy: 0.8150\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.4744 - accuracy: 0.9050 - val_loss: 0.6702 - val_accuracy: 0.8100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.6702 - accuracy: 0.8100\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 6,808,874\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.4109 - accuracy: 0.8900 - val_loss: 0.5656 - val_accuracy: 0.8350\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.3001 - accuracy: 0.9062 - val_loss: 0.5394 - val_accuracy: 0.8400\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.2995 - accuracy: 0.9000 - val_loss: 0.5408 - val_accuracy: 0.8350\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.2446 - accuracy: 0.9137 - val_loss: 0.5331 - val_accuracy: 0.8500\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2570 - accuracy: 0.9137 - val_loss: 0.5258 - val_accuracy: 0.8600\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.2029 - accuracy: 0.9250 - val_loss: 0.5288 - val_accuracy: 0.8500\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1925 - accuracy: 0.9325 - val_loss: 0.5475 - val_accuracy: 0.8600\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 207ms/step - loss: 0.1918 - accuracy: 0.9375 - val_loss: 0.5226 - val_accuracy: 0.8600\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1834 - accuracy: 0.9413 - val_loss: 0.5270 - val_accuracy: 0.8600\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1544 - accuracy: 0.9525 - val_loss: 0.5208 - val_accuracy: 0.8700\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1570 - accuracy: 0.9513 - val_loss: 0.5161 - val_accuracy: 0.8650\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1486 - accuracy: 0.9513 - val_loss: 0.5192 - val_accuracy: 0.8700\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1429 - accuracy: 0.9525 - val_loss: 0.5355 - val_accuracy: 0.8700\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1222 - accuracy: 0.9625 - val_loss: 0.5428 - val_accuracy: 0.8750\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1006 - accuracy: 0.9800 - val_loss: 0.5518 - val_accuracy: 0.8800\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0821 - accuracy: 0.9775 - val_loss: 0.5585 - val_accuracy: 0.8900\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0966 - accuracy: 0.9650 - val_loss: 0.5427 - val_accuracy: 0.8850\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1056 - accuracy: 0.9613 - val_loss: 0.5437 - val_accuracy: 0.8700\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 0.5567 - val_accuracy: 0.8750\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0737 - accuracy: 0.9787 - val_loss: 0.5497 - val_accuracy: 0.8800\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.0714 - accuracy: 0.9775 - val_loss: 0.5674 - val_accuracy: 0.8900\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 2.3579 - accuracy: 0.0950\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 2.3233 - accuracy: 0.1213 - val_loss: 2.2126 - val_accuracy: 0.2300\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 2.1776 - accuracy: 0.2338 - val_loss: 2.0870 - val_accuracy: 0.3350\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 2.0275 - accuracy: 0.3913 - val_loss: 1.9692 - val_accuracy: 0.4950\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 9s 175ms/step - loss: 1.9096 - accuracy: 0.4988 - val_loss: 1.8608 - val_accuracy: 0.5550\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.7804 - accuracy: 0.5913 - val_loss: 1.7584 - val_accuracy: 0.6150\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.6961 - accuracy: 0.6425 - val_loss: 1.6679 - val_accuracy: 0.6450\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.5989 - accuracy: 0.6800 - val_loss: 1.5810 - val_accuracy: 0.6800\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.4977 - accuracy: 0.7225 - val_loss: 1.5042 - val_accuracy: 0.7100\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.4105 - accuracy: 0.7638 - val_loss: 1.4346 - val_accuracy: 0.7250\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.3724 - accuracy: 0.7475 - val_loss: 1.3714 - val_accuracy: 0.7400\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.2885 - accuracy: 0.7775 - val_loss: 1.3157 - val_accuracy: 0.7350\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.2421 - accuracy: 0.7962 - val_loss: 1.2627 - val_accuracy: 0.7450\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.1806 - accuracy: 0.7912 - val_loss: 1.2175 - val_accuracy: 0.7550\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.1323 - accuracy: 0.7837 - val_loss: 1.1724 - val_accuracy: 0.7550\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0802 - accuracy: 0.8025 - val_loss: 1.1341 - val_accuracy: 0.7750\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 1.0390 - accuracy: 0.8388 - val_loss: 1.0975 - val_accuracy: 0.7700\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 1.0024 - accuracy: 0.8188 - val_loss: 1.0643 - val_accuracy: 0.7850\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9671 - accuracy: 0.8275 - val_loss: 1.0311 - val_accuracy: 0.7900\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9381 - accuracy: 0.8263 - val_loss: 1.0049 - val_accuracy: 0.7850\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.9159 - accuracy: 0.8325 - val_loss: 0.9802 - val_accuracy: 0.7950\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8890 - accuracy: 0.8163 - val_loss: 0.9579 - val_accuracy: 0.8050\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.8435 - accuracy: 0.8425 - val_loss: 0.9310 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.8353 - accuracy: 0.8313 - val_loss: 0.9105 - val_accuracy: 0.8100\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.8102 - accuracy: 0.8350 - val_loss: 0.8901 - val_accuracy: 0.8150\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7939 - accuracy: 0.8575 - val_loss: 0.8713 - val_accuracy: 0.8150\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7523 - accuracy: 0.8537 - val_loss: 0.8569 - val_accuracy: 0.8200\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7433 - accuracy: 0.8525 - val_loss: 0.8380 - val_accuracy: 0.8150\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7392 - accuracy: 0.8487 - val_loss: 0.8240 - val_accuracy: 0.8200\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.7164 - accuracy: 0.8587 - val_loss: 0.8121 - val_accuracy: 0.8200\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6892 - accuracy: 0.8625 - val_loss: 0.7983 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6784 - accuracy: 0.8625 - val_loss: 0.7851 - val_accuracy: 0.8200\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6667 - accuracy: 0.8675 - val_loss: 0.7752 - val_accuracy: 0.8250\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6638 - accuracy: 0.8687 - val_loss: 0.7658 - val_accuracy: 0.8250\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6399 - accuracy: 0.8700 - val_loss: 0.7517 - val_accuracy: 0.8300\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.6456 - accuracy: 0.8612 - val_loss: 0.7432 - val_accuracy: 0.8350\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6089 - accuracy: 0.8737 - val_loss: 0.7324 - val_accuracy: 0.8350\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.6069 - accuracy: 0.8737 - val_loss: 0.7233 - val_accuracy: 0.8250\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5968 - accuracy: 0.8737 - val_loss: 0.7148 - val_accuracy: 0.8250\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5831 - accuracy: 0.8775 - val_loss: 0.7082 - val_accuracy: 0.8300\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5628 - accuracy: 0.8850 - val_loss: 0.7007 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5507 - accuracy: 0.8888 - val_loss: 0.6934 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5448 - accuracy: 0.8825 - val_loss: 0.6862 - val_accuracy: 0.8450\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5419 - accuracy: 0.8838 - val_loss: 0.6777 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5222 - accuracy: 0.9000 - val_loss: 0.6711 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5305 - accuracy: 0.8875 - val_loss: 0.6670 - val_accuracy: 0.8450\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5145 - accuracy: 0.8925 - val_loss: 0.6621 - val_accuracy: 0.8450\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5218 - accuracy: 0.8800 - val_loss: 0.6568 - val_accuracy: 0.8450\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 9s 173ms/step - loss: 0.5070 - accuracy: 0.8888 - val_loss: 0.6550 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5042 - accuracy: 0.8838 - val_loss: 0.6465 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5110 - accuracy: 0.8900 - val_loss: 0.6403 - val_accuracy: 0.8500\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.6403 - accuracy: 0.8500\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 6,808,874\n",
            "Non-trainable params: 14,073,096\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.3940 - accuracy: 0.9000 - val_loss: 0.5077 - val_accuracy: 0.8700\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.3107 - accuracy: 0.8988 - val_loss: 0.4833 - val_accuracy: 0.8750\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.2806 - accuracy: 0.9112 - val_loss: 0.4828 - val_accuracy: 0.8750\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.2815 - accuracy: 0.9087 - val_loss: 0.4741 - val_accuracy: 0.8800\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.2570 - accuracy: 0.9175 - val_loss: 0.4736 - val_accuracy: 0.8700\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1937 - accuracy: 0.9400 - val_loss: 0.4526 - val_accuracy: 0.8800\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1914 - accuracy: 0.9325 - val_loss: 0.4578 - val_accuracy: 0.8750\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.2020 - accuracy: 0.9325 - val_loss: 0.4470 - val_accuracy: 0.8850\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1699 - accuracy: 0.9350 - val_loss: 0.4760 - val_accuracy: 0.8750\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1498 - accuracy: 0.9463 - val_loss: 0.4906 - val_accuracy: 0.8500\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1455 - accuracy: 0.9513 - val_loss: 0.4413 - val_accuracy: 0.8800\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1440 - accuracy: 0.9638 - val_loss: 0.4426 - val_accuracy: 0.8750\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1610 - accuracy: 0.9450 - val_loss: 0.4584 - val_accuracy: 0.8850\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1297 - accuracy: 0.9600 - val_loss: 0.4506 - val_accuracy: 0.8800\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1173 - accuracy: 0.9650 - val_loss: 0.4463 - val_accuracy: 0.8750\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1047 - accuracy: 0.9650 - val_loss: 0.4699 - val_accuracy: 0.8700\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1249 - accuracy: 0.9625 - val_loss: 0.4508 - val_accuracy: 0.8750\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 10s 210ms/step - loss: 0.0839 - accuracy: 0.9800 - val_loss: 0.4663 - val_accuracy: 0.8800\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1021 - accuracy: 0.9750 - val_loss: 0.4727 - val_accuracy: 0.8750\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0909 - accuracy: 0.9762 - val_loss: 0.4854 - val_accuracy: 0.8750\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0815 - accuracy: 0.9737 - val_loss: 0.4868 - val_accuracy: 0.8800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08d9c68-66dd-44ae-a0b7-34de8e292824"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.09599999785423279\n",
            "Accuracy before fine-tuning: 0.8259999990463257\n",
            "Final accuracy: 0.8759999990463256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "093e9d25-e0a8-49f7-961c-2ca441c789c7"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6e9421b2-3111-4ae5-c4c1-aeb73afd09dc"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}