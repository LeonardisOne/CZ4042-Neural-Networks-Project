{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "materials-resnet-balanced-cross-validated-fine-tuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBj3HYFG2g3aoXhXG7acpN"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKJLyg2z-Uq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIbsvD01EQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a59d13-1f2b-452d-ddc4-c5a00a6b99c5"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "# set path to FMD image directory\n",
        "data_dir = pathlib.Path(\"image\")\n",
        "\n",
        "# total no. of images in FMD dataset\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL3rBqoe3sK5"
      },
      "source": [
        "# set batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# set dimensions to change images into for training\n",
        "# 299x299 images is used to train for consistency between different pre-trained models\n",
        "img_height = 299\n",
        "img_width = 299"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFKuhNRxqxcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31273fca-6766-471e-e265-90ff30d1dc28"
      },
      "source": [
        "# get class names from the folder names in data_dir\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fabric' 'foliage' 'glass' 'leather' 'metal' 'paper' 'plastic' 'stone'\n",
            " 'water' 'wood']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_FpvbEqWrS"
      },
      "source": [
        "# create list containing the dataset for each class\n",
        "ds_each_class = [tf.data.Dataset.list_files(str(data_dir/f'{class_name}/*.jpg'), shuffle=False) for class_name in class_names]\n",
        "\n",
        "# shuffle the 100 images in each class with the random seed value of 123 before training\n",
        "for index, ds in enumerate(ds_each_class):\n",
        "  ds_each_class[index] = ds.shuffle(image_count//10, seed=123, reshuffle_each_iteration=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_LijJpqbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7882742f-d8e8-4a83-d495-e3a4181995e6"
      },
      "source": [
        "# display some samples from a class to verify each class dataset contains only the class images\n",
        "for f in ds_each_class[0].take(10):\n",
        "  print(f.numpy())\n",
        "\n",
        "for f in ds_each_class[1].take(10):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'FMD/image/fabric/fabric_moderate_037_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_004_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_008_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_003_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_017_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_001_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_032_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_030_new.jpg'\n",
            "b'FMD/image/fabric/fabric_moderate_038_new.jpg'\n",
            "b'FMD/image/fabric/fabric_object_009_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_037_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_004_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_008_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_053_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_067_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_051_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_032_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_030_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_038_new.jpg'\n",
            "b'FMD/image/foliage/foliage_final_059_new.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACILObxurdXN"
      },
      "source": [
        "# split first class dataset into 5 equal sized partitions\n",
        "# then for remaining classes' datasets do the same and add to corresponding partition\n",
        "# for 5-fold cross validation\n",
        "A = ds_each_class[0].shard(num_shards=5, index=0)\n",
        "B = ds_each_class[0].shard(num_shards=5, index=1)\n",
        "C = ds_each_class[0].shard(num_shards=5, index=2)\n",
        "D = ds_each_class[0].shard(num_shards=5, index=3)\n",
        "E = ds_each_class[0].shard(num_shards=5, index=4)\n",
        "for i in range(1, 10):\n",
        "  A = A.concatenate(ds_each_class[i].shard(num_shards=5, index=0))\n",
        "  B = B.concatenate(ds_each_class[i].shard(num_shards=5, index=1))\n",
        "  C = C.concatenate(ds_each_class[i].shard(num_shards=5, index=2))\n",
        "  D = D.concatenate(ds_each_class[i].shard(num_shards=5, index=3))\n",
        "  E = E.concatenate(ds_each_class[i].shard(num_shards=5, index=4))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9oYdHkhrwdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea53468e-b76c-4500-9873-6ce3aa3a00c8"
      },
      "source": [
        "# check no. of samples in each partition is the same\n",
        "print(A.cardinality().numpy())\n",
        "print(B.cardinality().numpy())\n",
        "print(C.cardinality().numpy())\n",
        "print(D.cardinality().numpy())\n",
        "print(E.cardinality().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdD3FMHtGRV"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfWduaL4tKDV"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bGGe0KltMTC"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyZLwRxt1dy"
      },
      "source": [
        "# prompt the tf.data runtime to tune the number of elements to prefetch dynamically at runtime\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkBqAQlHtblh"
      },
      "source": [
        "# use the path of image to load the image into each partition of the dataset\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "A = A.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "B = B.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "C = C.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "D = D.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "E = E.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc9pmaQ5t9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b0a3d2-eb61-42e5-8871-f544bef2c104"
      },
      "source": [
        "for image, label in A.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (299, 299, 3)\n",
            "Label:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_T2KNdGub1X"
      },
      "source": [
        "# shuffle, batch, and prefetch the dataset\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcojoVRuok5"
      },
      "source": [
        "# map the dataset partitions to integers for building training/test sets during cross-validation\n",
        "ds_fold_dict = {0:A, 1:B, 2:C, 3:D, 4:E}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3xKoMZU9Yv"
      },
      "source": [
        "# normalise the input values to the pre-trained model's required range of values\n",
        "preprocess_input = keras.applications.resnet_v2.preprocess_input"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzhaWb2aX2if"
      },
      "source": [
        "# set a low learning rate to avoid overfitting too quickly\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# create the model to train using the pre-trained model as base model\n",
        "def create_model(base_model):\n",
        "  # generate additional training data from input training data by augmenting them using random flip, rotation & zoom\n",
        "  data_augmentation = keras.Sequential(\n",
        "    [\n",
        "      layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                  input_shape=(img_height, \n",
        "                                                                img_width,\n",
        "                                                                3)),\n",
        "      layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "      layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # average over the spatial locations to convert the features to a single vector per image\n",
        "  global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
        "  # convert these features into a single prediction per image\n",
        "  prediction_layer = keras.layers.Dense(10)\n",
        "\n",
        "  # Build a model by chaining together the layers using the Keras Functional API.\n",
        "  inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False) # use training=False as the base model contains a BatchNormalization layer\n",
        "  x = global_average_layer(x)\n",
        "  x = keras.layers.Dropout(0.2)(x) # add dropout to fully connected layer to reduce overfitting\n",
        "  outputs = prediction_layer(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  optimizer = keras.optimizers.Adam(lr=base_learning_rate)\n",
        "  loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  # compile model with Adam optimizer with specified learning rate\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5TEZRgY2l_"
      },
      "source": [
        "no_epochs = 50\n",
        "fine_tune_epochs = 20\n",
        "total_epochs =  no_epochs + fine_tune_epochs\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = -27"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya698zRbu7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b426e44-afeb-4395-f00c-2aa12c329fb2"
      },
      "source": [
        "# store results to plot graphs and get cross-validated accuracies\n",
        "history_map = {}\n",
        "base_model_acc_list = []\n",
        "pre_trained_acc_list = []\n",
        "final_acc_list = []\n",
        "\n",
        "# do 5-fold cross-validation\n",
        "for i in range(5):\n",
        "  print('fold', i + 1)\n",
        "  temp_dict = ds_fold_dict.copy()\n",
        "  # get test set for this iteration\n",
        "  current_val_ds = temp_dict[i]\n",
        "\n",
        "  # get training set for this iteration from remaining data samples\n",
        "  del temp_dict[i]\n",
        "  current_train_ds = None\n",
        "  for ds_shard in temp_dict.values():\n",
        "    if current_train_ds is None:\n",
        "      current_train_ds = ds_shard\n",
        "    else:\n",
        "      current_train_ds = current_train_ds.concatenate(ds_shard)\n",
        "  \n",
        "  # configure both training and test sets to improve performance\n",
        "  current_train_ds = configure_for_performance(current_train_ds)\n",
        "  current_val_ds = configure_for_performance(current_val_ds)\n",
        "\n",
        "  # get pre-trained model\n",
        "  base_model = keras.applications.ResNet50V2(include_top=False, input_shape=(img_height, img_width, 3))\n",
        "  # don't train base model weights\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # create a new model\n",
        "  model = create_model(base_model)\n",
        "  # get initial test accuracy\n",
        "  base_model_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "  # train for specified epochs\n",
        "  history = model.fit(current_train_ds,\n",
        "                    epochs=no_epochs,\n",
        "                    validation_data=current_val_ds)\n",
        "  \n",
        "  # get test accuracy before fine-tuning\n",
        "  pre_trained_acc_list.append(model.evaluate(current_val_ds)[1])\n",
        "\n",
        "  # start fine-tuning by setting base model to be trainable\n",
        "  base_model.trainable = True\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer to only fine-tune top layer(s)\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  # compile model again with RMSProp optimizer with even smaller learning rate to reduce overfitting\n",
        "  optimizer = keras.optimizers.RMSprop(lr=base_learning_rate/10)\n",
        "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  print('Fine-tuned model:')\n",
        "  model.summary()\n",
        "\n",
        "  # train fine-tuned model\n",
        "  history_fine = model.fit(current_train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=current_val_ds)\n",
        "\n",
        "  # save results\n",
        "  if i == 0:\n",
        "    history_map['accuracy'] = [history.history['accuracy'] + history_fine.history['accuracy']]\n",
        "    history_map['val_accuracy'] = [history.history['val_accuracy'] + history_fine.history['val_accuracy']]\n",
        "    history_map['loss'] = [history.history['loss'] + history_fine.history['loss']]\n",
        "    history_map['val_loss'] = [history.history['val_loss'] + history_fine.history['val_loss']]\n",
        "  else:\n",
        "    history_map['accuracy'].append(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "    history_map['val_accuracy'].append(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "    history_map['loss'].append(history.history['loss'] + history_fine.history['loss'])\n",
        "    history_map['val_loss'].append(history.history['val_loss'] + history_fine.history['val_loss'])\n",
        "  \n",
        "  # get final test accuracy by taking the max accuracy over the whole training due to potential overfitting at end of fine-tuning\n",
        "  final_acc_list.append(np.amax(history.history['val_accuracy'] + history_fine.history['val_accuracy']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 5s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 3s 252ms/step - loss: 2.5840 - accuracy: 0.1050\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 2.6142 - accuracy: 0.1275 - val_loss: 2.2792 - val_accuracy: 0.1700\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.2029 - accuracy: 0.2200 - val_loss: 2.0278 - val_accuracy: 0.2650\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.0148 - accuracy: 0.2950 - val_loss: 1.8071 - val_accuracy: 0.3950\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.7986 - accuracy: 0.3925 - val_loss: 1.6220 - val_accuracy: 0.4850\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.6225 - accuracy: 0.4538 - val_loss: 1.4693 - val_accuracy: 0.5550\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 1.4679 - accuracy: 0.5263 - val_loss: 1.3416 - val_accuracy: 0.6200\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 1.3609 - accuracy: 0.5575 - val_loss: 1.2356 - val_accuracy: 0.6700\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.3045 - accuracy: 0.5675 - val_loss: 1.1509 - val_accuracy: 0.7000\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.1704 - accuracy: 0.6338 - val_loss: 1.0764 - val_accuracy: 0.7300\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.1141 - accuracy: 0.6662 - val_loss: 1.0166 - val_accuracy: 0.7400\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.0195 - accuracy: 0.7125 - val_loss: 0.9667 - val_accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.9417 - accuracy: 0.7188 - val_loss: 0.9212 - val_accuracy: 0.7600\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.9228 - accuracy: 0.7287 - val_loss: 0.8899 - val_accuracy: 0.7600\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.8684 - accuracy: 0.7525 - val_loss: 0.8555 - val_accuracy: 0.7650\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.8323 - accuracy: 0.7675 - val_loss: 0.8254 - val_accuracy: 0.7750\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.8048 - accuracy: 0.7638 - val_loss: 0.8028 - val_accuracy: 0.7700\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.7668 - accuracy: 0.7775 - val_loss: 0.7817 - val_accuracy: 0.7700\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.7481 - accuracy: 0.7812 - val_loss: 0.7648 - val_accuracy: 0.7800\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.7241 - accuracy: 0.7962 - val_loss: 0.7504 - val_accuracy: 0.7800\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6998 - accuracy: 0.8025 - val_loss: 0.7321 - val_accuracy: 0.7800\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.6621 - accuracy: 0.8062 - val_loss: 0.7188 - val_accuracy: 0.7800\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6276 - accuracy: 0.8338 - val_loss: 0.7088 - val_accuracy: 0.7800\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5880 - accuracy: 0.8537 - val_loss: 0.6947 - val_accuracy: 0.7850\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5857 - accuracy: 0.8288 - val_loss: 0.6844 - val_accuracy: 0.7850\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5930 - accuracy: 0.8338 - val_loss: 0.6738 - val_accuracy: 0.7850\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5861 - accuracy: 0.8325 - val_loss: 0.6602 - val_accuracy: 0.7850\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5541 - accuracy: 0.8363 - val_loss: 0.6574 - val_accuracy: 0.7850\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5477 - accuracy: 0.8487 - val_loss: 0.6501 - val_accuracy: 0.7900\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.5286 - accuracy: 0.8600 - val_loss: 0.6429 - val_accuracy: 0.7850\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5044 - accuracy: 0.8575 - val_loss: 0.6360 - val_accuracy: 0.7900\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4955 - accuracy: 0.8612 - val_loss: 0.6289 - val_accuracy: 0.7800\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4935 - accuracy: 0.8512 - val_loss: 0.6236 - val_accuracy: 0.7850\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4895 - accuracy: 0.8525 - val_loss: 0.6165 - val_accuracy: 0.7900\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4707 - accuracy: 0.8788 - val_loss: 0.6160 - val_accuracy: 0.7850\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4511 - accuracy: 0.8888 - val_loss: 0.6135 - val_accuracy: 0.7900\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4416 - accuracy: 0.8913 - val_loss: 0.6083 - val_accuracy: 0.7900\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4614 - accuracy: 0.8612 - val_loss: 0.6014 - val_accuracy: 0.8000\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4213 - accuracy: 0.8913 - val_loss: 0.6004 - val_accuracy: 0.7900\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4146 - accuracy: 0.8950 - val_loss: 0.5993 - val_accuracy: 0.7900\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4204 - accuracy: 0.8863 - val_loss: 0.5935 - val_accuracy: 0.7950\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 259ms/step - loss: 0.4150 - accuracy: 0.8900 - val_loss: 0.5907 - val_accuracy: 0.7950\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3845 - accuracy: 0.9013 - val_loss: 0.5877 - val_accuracy: 0.7900\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3968 - accuracy: 0.8975 - val_loss: 0.5842 - val_accuracy: 0.7950\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3928 - accuracy: 0.8938 - val_loss: 0.5832 - val_accuracy: 0.8000\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3856 - accuracy: 0.8925 - val_loss: 0.5770 - val_accuracy: 0.8000\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3729 - accuracy: 0.8988 - val_loss: 0.5769 - val_accuracy: 0.7950\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3546 - accuracy: 0.9087 - val_loss: 0.5738 - val_accuracy: 0.8000\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3601 - accuracy: 0.8963 - val_loss: 0.5715 - val_accuracy: 0.8050\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3459 - accuracy: 0.9162 - val_loss: 0.5659 - val_accuracy: 0.8050\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3215 - accuracy: 0.9175 - val_loss: 0.5679 - val_accuracy: 0.8050\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 0.5679 - accuracy: 0.8050\n",
            "Fine-tuned model:\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 17s 338ms/step - loss: 0.3058 - accuracy: 0.9038 - val_loss: 0.5775 - val_accuracy: 0.8100\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.2233 - accuracy: 0.9225 - val_loss: 0.5664 - val_accuracy: 0.8150\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.1783 - accuracy: 0.9350 - val_loss: 0.6178 - val_accuracy: 0.8050\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.1266 - accuracy: 0.9588 - val_loss: 0.6288 - val_accuracy: 0.8200\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1137 - accuracy: 0.9588 - val_loss: 0.6628 - val_accuracy: 0.8300\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.1279 - accuracy: 0.9563 - val_loss: 0.5931 - val_accuracy: 0.8350\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0895 - accuracy: 0.9675 - val_loss: 0.6266 - val_accuracy: 0.8400\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.6443 - val_accuracy: 0.8200\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0883 - accuracy: 0.9825 - val_loss: 0.6435 - val_accuracy: 0.8250\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0578 - accuracy: 0.9800 - val_loss: 0.6262 - val_accuracy: 0.8300\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 0.7077 - val_accuracy: 0.8400\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0605 - accuracy: 0.9800 - val_loss: 0.6445 - val_accuracy: 0.8350\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.7164 - val_accuracy: 0.8400\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.7321 - val_accuracy: 0.8250\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.7624 - val_accuracy: 0.8200\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0307 - accuracy: 0.9925 - val_loss: 0.7324 - val_accuracy: 0.8400\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0223 - accuracy: 0.9912 - val_loss: 0.8435 - val_accuracy: 0.8300\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.7239 - val_accuracy: 0.8350\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.7193 - val_accuracy: 0.8350\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 0.8948 - val_accuracy: 0.8400\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.7897 - val_accuracy: 0.8300\n",
            "fold 2\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 181ms/step - loss: 2.8462 - accuracy: 0.0800\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.6778 - accuracy: 0.1000 - val_loss: 2.4567 - val_accuracy: 0.1250\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.3288 - accuracy: 0.1900 - val_loss: 2.1753 - val_accuracy: 0.1850\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.0752 - accuracy: 0.2550 - val_loss: 1.9396 - val_accuracy: 0.3100\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.8073 - accuracy: 0.3875 - val_loss: 1.7420 - val_accuracy: 0.3650\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.6350 - accuracy: 0.4725 - val_loss: 1.5808 - val_accuracy: 0.4650\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.5027 - accuracy: 0.5437 - val_loss: 1.4423 - val_accuracy: 0.5800\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.3774 - accuracy: 0.5900 - val_loss: 1.3300 - val_accuracy: 0.6500\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.2465 - accuracy: 0.6100 - val_loss: 1.2319 - val_accuracy: 0.6750\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.1544 - accuracy: 0.6587 - val_loss: 1.1539 - val_accuracy: 0.7100\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 1.0880 - accuracy: 0.6750 - val_loss: 1.0879 - val_accuracy: 0.7150\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.0398 - accuracy: 0.7100 - val_loss: 1.0311 - val_accuracy: 0.7300\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.9947 - accuracy: 0.7038 - val_loss: 0.9800 - val_accuracy: 0.7400\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.9296 - accuracy: 0.7387 - val_loss: 0.9379 - val_accuracy: 0.7500\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.8693 - accuracy: 0.7588 - val_loss: 0.9035 - val_accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.8191 - accuracy: 0.7675 - val_loss: 0.8751 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.7990 - accuracy: 0.7713 - val_loss: 0.8463 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.7646 - accuracy: 0.7688 - val_loss: 0.8235 - val_accuracy: 0.7550\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.7457 - accuracy: 0.7788 - val_loss: 0.8012 - val_accuracy: 0.7600\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6997 - accuracy: 0.8012 - val_loss: 0.7816 - val_accuracy: 0.7600\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.6635 - accuracy: 0.8200 - val_loss: 0.7638 - val_accuracy: 0.7750\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6681 - accuracy: 0.8188 - val_loss: 0.7485 - val_accuracy: 0.7750\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6395 - accuracy: 0.8163 - val_loss: 0.7328 - val_accuracy: 0.7800\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6322 - accuracy: 0.8163 - val_loss: 0.7181 - val_accuracy: 0.7850\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.6075 - accuracy: 0.8150 - val_loss: 0.7066 - val_accuracy: 0.7900\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.5908 - accuracy: 0.8388 - val_loss: 0.6970 - val_accuracy: 0.7900\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.5766 - accuracy: 0.8288 - val_loss: 0.6876 - val_accuracy: 0.7900\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5635 - accuracy: 0.8300 - val_loss: 0.6768 - val_accuracy: 0.7850\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5390 - accuracy: 0.8600 - val_loss: 0.6694 - val_accuracy: 0.7850\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5301 - accuracy: 0.8400 - val_loss: 0.6604 - val_accuracy: 0.7900\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5013 - accuracy: 0.8650 - val_loss: 0.6504 - val_accuracy: 0.7900\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5033 - accuracy: 0.8712 - val_loss: 0.6449 - val_accuracy: 0.7900\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.5140 - accuracy: 0.8562 - val_loss: 0.6363 - val_accuracy: 0.8000\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5042 - accuracy: 0.8687 - val_loss: 0.6311 - val_accuracy: 0.8050\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4702 - accuracy: 0.8687 - val_loss: 0.6270 - val_accuracy: 0.8050\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4579 - accuracy: 0.8612 - val_loss: 0.6197 - val_accuracy: 0.8050\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4507 - accuracy: 0.8662 - val_loss: 0.6149 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4333 - accuracy: 0.8775 - val_loss: 0.6084 - val_accuracy: 0.8000\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4384 - accuracy: 0.8800 - val_loss: 0.6064 - val_accuracy: 0.8050\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4239 - accuracy: 0.8888 - val_loss: 0.6011 - val_accuracy: 0.8050\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4162 - accuracy: 0.8888 - val_loss: 0.5975 - val_accuracy: 0.8050\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4093 - accuracy: 0.8925 - val_loss: 0.5937 - val_accuracy: 0.8050\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.4131 - accuracy: 0.8750 - val_loss: 0.5889 - val_accuracy: 0.8150\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3716 - accuracy: 0.9050 - val_loss: 0.5866 - val_accuracy: 0.8050\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3885 - accuracy: 0.8938 - val_loss: 0.5831 - val_accuracy: 0.8150\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3741 - accuracy: 0.9025 - val_loss: 0.5794 - val_accuracy: 0.8150\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3741 - accuracy: 0.8975 - val_loss: 0.5760 - val_accuracy: 0.8200\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3711 - accuracy: 0.9000 - val_loss: 0.5718 - val_accuracy: 0.8150\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3461 - accuracy: 0.9100 - val_loss: 0.5684 - val_accuracy: 0.8100\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 260ms/step - loss: 0.3468 - accuracy: 0.9087 - val_loss: 0.5669 - val_accuracy: 0.8150\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3531 - accuracy: 0.8963 - val_loss: 0.5657 - val_accuracy: 0.8100\n",
            "13/13 [==============================] - 2s 180ms/step - loss: 0.5657 - accuracy: 0.8100\n",
            "Fine-tuned model:\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_1 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 17s 340ms/step - loss: 0.2624 - accuracy: 0.9075 - val_loss: 0.5822 - val_accuracy: 0.8250\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.2084 - accuracy: 0.9325 - val_loss: 0.5906 - val_accuracy: 0.8350\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.1788 - accuracy: 0.9400 - val_loss: 0.6142 - val_accuracy: 0.8450\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.1589 - accuracy: 0.9463 - val_loss: 0.6097 - val_accuracy: 0.8450\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.1286 - accuracy: 0.9500 - val_loss: 0.5820 - val_accuracy: 0.8500\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1090 - accuracy: 0.9613 - val_loss: 0.6088 - val_accuracy: 0.8300\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0859 - accuracy: 0.9688 - val_loss: 0.6098 - val_accuracy: 0.8350\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0783 - accuracy: 0.9787 - val_loss: 0.6255 - val_accuracy: 0.8300\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0706 - accuracy: 0.9775 - val_loss: 0.6670 - val_accuracy: 0.8400\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 0.0731 - accuracy: 0.9762 - val_loss: 0.6726 - val_accuracy: 0.8150\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.6847 - val_accuracy: 0.8450\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0370 - accuracy: 0.9837 - val_loss: 0.7295 - val_accuracy: 0.8300\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0461 - accuracy: 0.9800 - val_loss: 0.7758 - val_accuracy: 0.8400\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.8336 - val_accuracy: 0.8250\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0403 - accuracy: 0.9800 - val_loss: 0.7870 - val_accuracy: 0.8200\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 0.7499 - val_accuracy: 0.8350\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0287 - accuracy: 0.9875 - val_loss: 0.8688 - val_accuracy: 0.8200\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.8131 - val_accuracy: 0.8300\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.8277 - val_accuracy: 0.8350\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.8332 - val_accuracy: 0.8450\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0122 - accuracy: 0.9987 - val_loss: 0.8376 - val_accuracy: 0.8400\n",
            "fold 3\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 182ms/step - loss: 2.6140 - accuracy: 0.1500\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.5714 - accuracy: 0.1175 - val_loss: 2.2328 - val_accuracy: 0.2100\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 2.2244 - accuracy: 0.2013 - val_loss: 1.9738 - val_accuracy: 0.3150\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.9856 - accuracy: 0.3075 - val_loss: 1.7598 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.7601 - accuracy: 0.4062 - val_loss: 1.5883 - val_accuracy: 0.4650\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.5862 - accuracy: 0.4663 - val_loss: 1.4499 - val_accuracy: 0.5350\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.4167 - accuracy: 0.5487 - val_loss: 1.3360 - val_accuracy: 0.5700\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.3034 - accuracy: 0.5688 - val_loss: 1.2391 - val_accuracy: 0.5950\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.2334 - accuracy: 0.6075 - val_loss: 1.1632 - val_accuracy: 0.6350\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 1.1427 - accuracy: 0.6650 - val_loss: 1.0978 - val_accuracy: 0.6750\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.0412 - accuracy: 0.7075 - val_loss: 1.0429 - val_accuracy: 0.6800\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.9785 - accuracy: 0.7212 - val_loss: 1.0013 - val_accuracy: 0.6950\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.9448 - accuracy: 0.7250 - val_loss: 0.9592 - val_accuracy: 0.7050\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.8872 - accuracy: 0.7475 - val_loss: 0.9248 - val_accuracy: 0.7100\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.8608 - accuracy: 0.7487 - val_loss: 0.8953 - val_accuracy: 0.7300\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.8188 - accuracy: 0.7525 - val_loss: 0.8643 - val_accuracy: 0.7350\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.7788 - accuracy: 0.7862 - val_loss: 0.8429 - val_accuracy: 0.7400\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.7082 - accuracy: 0.8150 - val_loss: 0.8240 - val_accuracy: 0.7400\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.7019 - accuracy: 0.7987 - val_loss: 0.8027 - val_accuracy: 0.7450\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6997 - accuracy: 0.8112 - val_loss: 0.7877 - val_accuracy: 0.7550\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.6559 - accuracy: 0.8238 - val_loss: 0.7726 - val_accuracy: 0.7550\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6273 - accuracy: 0.8188 - val_loss: 0.7618 - val_accuracy: 0.7550\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6177 - accuracy: 0.8400 - val_loss: 0.7477 - val_accuracy: 0.7550\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6116 - accuracy: 0.8275 - val_loss: 0.7388 - val_accuracy: 0.7650\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5662 - accuracy: 0.8612 - val_loss: 0.7303 - val_accuracy: 0.7600\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5558 - accuracy: 0.8425 - val_loss: 0.7204 - val_accuracy: 0.7600\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5451 - accuracy: 0.8612 - val_loss: 0.7158 - val_accuracy: 0.7600\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5322 - accuracy: 0.8550 - val_loss: 0.7067 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5377 - accuracy: 0.8487 - val_loss: 0.6966 - val_accuracy: 0.7650\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.5203 - accuracy: 0.8512 - val_loss: 0.6903 - val_accuracy: 0.7650\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4772 - accuracy: 0.8687 - val_loss: 0.6838 - val_accuracy: 0.7600\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4624 - accuracy: 0.8750 - val_loss: 0.6789 - val_accuracy: 0.7800\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4635 - accuracy: 0.8775 - val_loss: 0.6718 - val_accuracy: 0.7750\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4581 - accuracy: 0.8725 - val_loss: 0.6679 - val_accuracy: 0.7800\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4627 - accuracy: 0.8625 - val_loss: 0.6662 - val_accuracy: 0.7650\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4359 - accuracy: 0.8850 - val_loss: 0.6617 - val_accuracy: 0.7700\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4467 - accuracy: 0.8700 - val_loss: 0.6565 - val_accuracy: 0.7850\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4163 - accuracy: 0.8850 - val_loss: 0.6520 - val_accuracy: 0.7750\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4115 - accuracy: 0.8888 - val_loss: 0.6487 - val_accuracy: 0.7800\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4059 - accuracy: 0.8900 - val_loss: 0.6465 - val_accuracy: 0.7800\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3912 - accuracy: 0.9100 - val_loss: 0.6433 - val_accuracy: 0.7800\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3936 - accuracy: 0.8863 - val_loss: 0.6401 - val_accuracy: 0.7850\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3719 - accuracy: 0.8963 - val_loss: 0.6371 - val_accuracy: 0.7900\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3837 - accuracy: 0.9200 - val_loss: 0.6358 - val_accuracy: 0.7850\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3757 - accuracy: 0.8950 - val_loss: 0.6321 - val_accuracy: 0.7850\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3712 - accuracy: 0.9162 - val_loss: 0.6331 - val_accuracy: 0.7850\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3605 - accuracy: 0.8963 - val_loss: 0.6307 - val_accuracy: 0.7850\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3505 - accuracy: 0.9087 - val_loss: 0.6313 - val_accuracy: 0.7800\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3196 - accuracy: 0.9212 - val_loss: 0.6296 - val_accuracy: 0.7850\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3564 - accuracy: 0.9187 - val_loss: 0.6253 - val_accuracy: 0.7950\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3403 - accuracy: 0.9125 - val_loss: 0.6279 - val_accuracy: 0.7800\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 0.6279 - accuracy: 0.7800\n",
            "Fine-tuned model:\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_2 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 17s 342ms/step - loss: 0.2752 - accuracy: 0.9112 - val_loss: 0.6727 - val_accuracy: 0.7800\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.2229 - accuracy: 0.9200 - val_loss: 0.6525 - val_accuracy: 0.7850\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.2009 - accuracy: 0.9312 - val_loss: 0.6611 - val_accuracy: 0.7950\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.1730 - accuracy: 0.9463 - val_loss: 0.6713 - val_accuracy: 0.8100\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1188 - accuracy: 0.9613 - val_loss: 0.7069 - val_accuracy: 0.8150\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1038 - accuracy: 0.9737 - val_loss: 0.7462 - val_accuracy: 0.8050\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0927 - accuracy: 0.9737 - val_loss: 0.7294 - val_accuracy: 0.8250\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.7525 - val_accuracy: 0.8100\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0572 - accuracy: 0.9800 - val_loss: 0.7698 - val_accuracy: 0.8000\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0474 - accuracy: 0.9850 - val_loss: 0.8177 - val_accuracy: 0.8100\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.8558 - val_accuracy: 0.8100\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0495 - accuracy: 0.9862 - val_loss: 0.8440 - val_accuracy: 0.8050\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0356 - accuracy: 0.9925 - val_loss: 0.8635 - val_accuracy: 0.8100\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0212 - accuracy: 0.9962 - val_loss: 0.9594 - val_accuracy: 0.7900\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 1.0195 - val_accuracy: 0.7800\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.9592 - val_accuracy: 0.8050\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.9678 - val_accuracy: 0.8100\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 1.0023 - val_accuracy: 0.8100\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0134 - accuracy: 0.9950 - val_loss: 1.1313 - val_accuracy: 0.7600\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0211 - accuracy: 0.9962 - val_loss: 1.0661 - val_accuracy: 0.8050\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 16s 320ms/step - loss: 0.0175 - accuracy: 0.9925 - val_loss: 1.0666 - val_accuracy: 0.8050\n",
            "fold 4\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 180ms/step - loss: 2.7562 - accuracy: 0.1050\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 2.6302 - accuracy: 0.1213 - val_loss: 2.3613 - val_accuracy: 0.1300\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 2.2574 - accuracy: 0.1963 - val_loss: 2.0901 - val_accuracy: 0.2350\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.9930 - accuracy: 0.2988 - val_loss: 1.8735 - val_accuracy: 0.3650\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.8133 - accuracy: 0.3812 - val_loss: 1.6933 - val_accuracy: 0.4450\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.5713 - accuracy: 0.4975 - val_loss: 1.5388 - val_accuracy: 0.5050\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.4890 - accuracy: 0.5225 - val_loss: 1.4158 - val_accuracy: 0.5500\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.3426 - accuracy: 0.5850 - val_loss: 1.3127 - val_accuracy: 0.5750\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.2636 - accuracy: 0.6137 - val_loss: 1.2292 - val_accuracy: 0.6150\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.1371 - accuracy: 0.6625 - val_loss: 1.1541 - val_accuracy: 0.6550\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.0766 - accuracy: 0.6900 - val_loss: 1.0919 - val_accuracy: 0.6650\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.0355 - accuracy: 0.6875 - val_loss: 1.0375 - val_accuracy: 0.7050\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.9509 - accuracy: 0.7200 - val_loss: 0.9907 - val_accuracy: 0.7200\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.9097 - accuracy: 0.7250 - val_loss: 0.9497 - val_accuracy: 0.7300\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.8346 - accuracy: 0.7688 - val_loss: 0.9172 - val_accuracy: 0.7350\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.8483 - accuracy: 0.7500 - val_loss: 0.8851 - val_accuracy: 0.7400\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.7930 - accuracy: 0.7825 - val_loss: 0.8653 - val_accuracy: 0.7450\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.7503 - accuracy: 0.7912 - val_loss: 0.8385 - val_accuracy: 0.7550\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.7417 - accuracy: 0.7825 - val_loss: 0.8174 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.7163 - accuracy: 0.7812 - val_loss: 0.7948 - val_accuracy: 0.7700\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6581 - accuracy: 0.8213 - val_loss: 0.7777 - val_accuracy: 0.7800\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6548 - accuracy: 0.8150 - val_loss: 0.7617 - val_accuracy: 0.7750\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6441 - accuracy: 0.8163 - val_loss: 0.7465 - val_accuracy: 0.7850\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.6195 - accuracy: 0.8338 - val_loss: 0.7322 - val_accuracy: 0.7750\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5883 - accuracy: 0.8413 - val_loss: 0.7164 - val_accuracy: 0.7900\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5854 - accuracy: 0.8238 - val_loss: 0.7031 - val_accuracy: 0.7950\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5831 - accuracy: 0.8250 - val_loss: 0.6947 - val_accuracy: 0.7950\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5658 - accuracy: 0.8450 - val_loss: 0.6821 - val_accuracy: 0.8100\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5403 - accuracy: 0.8525 - val_loss: 0.6747 - val_accuracy: 0.8050\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5292 - accuracy: 0.8525 - val_loss: 0.6656 - val_accuracy: 0.8100\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5386 - accuracy: 0.8512 - val_loss: 0.6559 - val_accuracy: 0.8050\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4986 - accuracy: 0.8625 - val_loss: 0.6508 - val_accuracy: 0.8150\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.5079 - accuracy: 0.8550 - val_loss: 0.6395 - val_accuracy: 0.8100\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4854 - accuracy: 0.8662 - val_loss: 0.6338 - val_accuracy: 0.8200\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4857 - accuracy: 0.8788 - val_loss: 0.6284 - val_accuracy: 0.8150\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4507 - accuracy: 0.8650 - val_loss: 0.6253 - val_accuracy: 0.8250\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4469 - accuracy: 0.8650 - val_loss: 0.6156 - val_accuracy: 0.8300\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.4506 - accuracy: 0.8650 - val_loss: 0.6108 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4279 - accuracy: 0.8913 - val_loss: 0.6068 - val_accuracy: 0.8350\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4044 - accuracy: 0.8938 - val_loss: 0.6030 - val_accuracy: 0.8350\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4332 - accuracy: 0.8750 - val_loss: 0.5986 - val_accuracy: 0.8400\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.3972 - accuracy: 0.8925 - val_loss: 0.5930 - val_accuracy: 0.8300\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4096 - accuracy: 0.8763 - val_loss: 0.5902 - val_accuracy: 0.8250\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3966 - accuracy: 0.9013 - val_loss: 0.5859 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.3784 - accuracy: 0.8975 - val_loss: 0.5805 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 261ms/step - loss: 0.3717 - accuracy: 0.9025 - val_loss: 0.5777 - val_accuracy: 0.8400\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3771 - accuracy: 0.8900 - val_loss: 0.5733 - val_accuracy: 0.8350\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3621 - accuracy: 0.9112 - val_loss: 0.5672 - val_accuracy: 0.8350\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3817 - accuracy: 0.8975 - val_loss: 0.5634 - val_accuracy: 0.8350\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.3306 - accuracy: 0.9250 - val_loss: 0.5583 - val_accuracy: 0.8450\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3531 - accuracy: 0.9050 - val_loss: 0.5567 - val_accuracy: 0.8350\n",
            "13/13 [==============================] - 2s 180ms/step - loss: 0.5567 - accuracy: 0.8350\n",
            "Fine-tuned model:\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_3 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_3 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.2839 - accuracy: 0.9000 - val_loss: 0.5528 - val_accuracy: 0.8350\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.2151 - accuracy: 0.9237 - val_loss: 0.5880 - val_accuracy: 0.8450\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1736 - accuracy: 0.9388 - val_loss: 0.5473 - val_accuracy: 0.8550\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.1322 - accuracy: 0.9575 - val_loss: 0.6024 - val_accuracy: 0.8500\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1561 - accuracy: 0.9525 - val_loss: 0.5691 - val_accuracy: 0.8400\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.1048 - accuracy: 0.9613 - val_loss: 0.5832 - val_accuracy: 0.8350\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0645 - accuracy: 0.9825 - val_loss: 0.6254 - val_accuracy: 0.8400\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0735 - accuracy: 0.9800 - val_loss: 0.6514 - val_accuracy: 0.8350\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0557 - accuracy: 0.9837 - val_loss: 0.6718 - val_accuracy: 0.8550\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0546 - accuracy: 0.9887 - val_loss: 0.6685 - val_accuracy: 0.8550\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0467 - accuracy: 0.9850 - val_loss: 0.6925 - val_accuracy: 0.8550\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.7184 - val_accuracy: 0.8650\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.7525 - val_accuracy: 0.8200\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.7038 - val_accuracy: 0.8650\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.7699 - val_accuracy: 0.8450\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.7519 - val_accuracy: 0.8300\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.8287 - val_accuracy: 0.7950\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.8269 - val_accuracy: 0.8400\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.8189 - val_accuracy: 0.8550\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.8316 - val_accuracy: 0.8700\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.8581 - val_accuracy: 0.8500\n",
            "fold 5\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "13/13 [==============================] - 2s 182ms/step - loss: 2.7095 - accuracy: 0.0750\n",
            "Epoch 1/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 2.6868 - accuracy: 0.1063 - val_loss: 2.3639 - val_accuracy: 0.1450\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 2.3401 - accuracy: 0.1688 - val_loss: 2.0930 - val_accuracy: 0.2250\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 2.1302 - accuracy: 0.2387 - val_loss: 1.8668 - val_accuracy: 0.3200\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.8600 - accuracy: 0.3438 - val_loss: 1.6731 - val_accuracy: 0.4350\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.7085 - accuracy: 0.4013 - val_loss: 1.5148 - val_accuracy: 0.5100\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.5445 - accuracy: 0.4938 - val_loss: 1.3859 - val_accuracy: 0.5650\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.4114 - accuracy: 0.5500 - val_loss: 1.2719 - val_accuracy: 0.6500\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.3376 - accuracy: 0.5713 - val_loss: 1.1805 - val_accuracy: 0.6600\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.1994 - accuracy: 0.6375 - val_loss: 1.1021 - val_accuracy: 0.6850\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 1.1242 - accuracy: 0.6637 - val_loss: 1.0323 - val_accuracy: 0.7150\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 13s 265ms/step - loss: 1.0748 - accuracy: 0.6725 - val_loss: 0.9785 - val_accuracy: 0.7300\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 1.0199 - accuracy: 0.6725 - val_loss: 0.9308 - val_accuracy: 0.7400\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.9574 - accuracy: 0.7150 - val_loss: 0.8851 - val_accuracy: 0.7550\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.8952 - accuracy: 0.7325 - val_loss: 0.8486 - val_accuracy: 0.7700\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.8507 - accuracy: 0.7650 - val_loss: 0.8158 - val_accuracy: 0.7800\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.8292 - accuracy: 0.7575 - val_loss: 0.7851 - val_accuracy: 0.7800\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.7976 - accuracy: 0.7575 - val_loss: 0.7592 - val_accuracy: 0.7900\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.7476 - accuracy: 0.7837 - val_loss: 0.7375 - val_accuracy: 0.7950\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.7461 - accuracy: 0.7812 - val_loss: 0.7141 - val_accuracy: 0.7950\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.7134 - accuracy: 0.7775 - val_loss: 0.6940 - val_accuracy: 0.7950\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.6954 - accuracy: 0.7900 - val_loss: 0.6808 - val_accuracy: 0.7950\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.6591 - accuracy: 0.8175 - val_loss: 0.6652 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.6287 - accuracy: 0.8138 - val_loss: 0.6492 - val_accuracy: 0.8000\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.6060 - accuracy: 0.8325 - val_loss: 0.6379 - val_accuracy: 0.8050\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.6006 - accuracy: 0.8338 - val_loss: 0.6257 - val_accuracy: 0.7950\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5838 - accuracy: 0.8363 - val_loss: 0.6135 - val_accuracy: 0.8100\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.5763 - accuracy: 0.8313 - val_loss: 0.6048 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.5601 - accuracy: 0.8525 - val_loss: 0.5951 - val_accuracy: 0.8000\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5462 - accuracy: 0.8475 - val_loss: 0.5831 - val_accuracy: 0.8200\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5407 - accuracy: 0.8375 - val_loss: 0.5779 - val_accuracy: 0.8200\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5285 - accuracy: 0.8438 - val_loss: 0.5697 - val_accuracy: 0.8200\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4984 - accuracy: 0.8662 - val_loss: 0.5648 - val_accuracy: 0.8200\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.5022 - accuracy: 0.8550 - val_loss: 0.5558 - val_accuracy: 0.8150\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.4849 - accuracy: 0.8587 - val_loss: 0.5503 - val_accuracy: 0.8300\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.4511 - accuracy: 0.8788 - val_loss: 0.5474 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4847 - accuracy: 0.8675 - val_loss: 0.5397 - val_accuracy: 0.8250\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4399 - accuracy: 0.8813 - val_loss: 0.5296 - val_accuracy: 0.8300\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.4521 - accuracy: 0.8838 - val_loss: 0.5273 - val_accuracy: 0.8300\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 13s 265ms/step - loss: 0.4217 - accuracy: 0.8975 - val_loss: 0.5223 - val_accuracy: 0.8300\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.4334 - accuracy: 0.8775 - val_loss: 0.5185 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4219 - accuracy: 0.8900 - val_loss: 0.5113 - val_accuracy: 0.8350\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.3949 - accuracy: 0.9000 - val_loss: 0.5091 - val_accuracy: 0.8400\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4010 - accuracy: 0.8900 - val_loss: 0.5061 - val_accuracy: 0.8400\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.3983 - accuracy: 0.8913 - val_loss: 0.5005 - val_accuracy: 0.8350\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.4067 - accuracy: 0.8938 - val_loss: 0.4969 - val_accuracy: 0.8350\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.3823 - accuracy: 0.8988 - val_loss: 0.4942 - val_accuracy: 0.8400\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.3736 - accuracy: 0.8888 - val_loss: 0.4896 - val_accuracy: 0.8400\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 13s 262ms/step - loss: 0.3708 - accuracy: 0.9150 - val_loss: 0.4877 - val_accuracy: 0.8450\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 13s 264ms/step - loss: 0.3677 - accuracy: 0.8963 - val_loss: 0.4827 - val_accuracy: 0.8300\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 13s 263ms/step - loss: 0.3577 - accuracy: 0.9137 - val_loss: 0.4828 - val_accuracy: 0.8400\n",
            "13/13 [==============================] - 2s 179ms/step - loss: 0.4828 - accuracy: 0.8400\n",
            "Fine-tuned model:\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 299, 299, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv_4 (Tenso [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub_4 (TensorFlo [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 12,103,690\n",
            "Non-trainable params: 11,481,600\n",
            "_________________________________________________________________\n",
            "Epoch 50/70\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.2811 - accuracy: 0.9025 - val_loss: 0.4259 - val_accuracy: 0.8450\n",
            "Epoch 51/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.2414 - accuracy: 0.9175 - val_loss: 0.4167 - val_accuracy: 0.8450\n",
            "Epoch 52/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.2093 - accuracy: 0.9300 - val_loss: 0.4150 - val_accuracy: 0.8500\n",
            "Epoch 53/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.1590 - accuracy: 0.9563 - val_loss: 0.4370 - val_accuracy: 0.8450\n",
            "Epoch 54/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.1389 - accuracy: 0.9500 - val_loss: 0.4431 - val_accuracy: 0.8450\n",
            "Epoch 55/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.1029 - accuracy: 0.9600 - val_loss: 0.4756 - val_accuracy: 0.8450\n",
            "Epoch 56/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.0953 - accuracy: 0.9663 - val_loss: 0.4681 - val_accuracy: 0.8550\n",
            "Epoch 57/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0917 - accuracy: 0.9712 - val_loss: 0.4889 - val_accuracy: 0.8250\n",
            "Epoch 58/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0692 - accuracy: 0.9775 - val_loss: 0.4863 - val_accuracy: 0.8350\n",
            "Epoch 59/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0524 - accuracy: 0.9837 - val_loss: 0.5053 - val_accuracy: 0.8450\n",
            "Epoch 60/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.0580 - accuracy: 0.9787 - val_loss: 0.4950 - val_accuracy: 0.8500\n",
            "Epoch 61/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.5684 - val_accuracy: 0.8300\n",
            "Epoch 62/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.5535 - val_accuracy: 0.8150\n",
            "Epoch 63/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0482 - accuracy: 0.9875 - val_loss: 0.5288 - val_accuracy: 0.8400\n",
            "Epoch 64/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.5766 - val_accuracy: 0.8350\n",
            "Epoch 65/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.6121 - val_accuracy: 0.8450\n",
            "Epoch 66/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.5515 - val_accuracy: 0.8350\n",
            "Epoch 67/70\n",
            "50/50 [==============================] - 16s 323ms/step - loss: 0.0330 - accuracy: 0.9937 - val_loss: 0.6162 - val_accuracy: 0.8450\n",
            "Epoch 68/70\n",
            "50/50 [==============================] - 16s 321ms/step - loss: 0.0314 - accuracy: 0.9875 - val_loss: 0.6216 - val_accuracy: 0.8300\n",
            "Epoch 69/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0199 - accuracy: 0.9912 - val_loss: 0.6361 - val_accuracy: 0.8450\n",
            "Epoch 70/70\n",
            "50/50 [==============================] - 16s 322ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.6768 - val_accuracy: 0.8250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2E72C3O30fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1476d504-2e67-4bec-9389-d8e00ce6ad6e"
      },
      "source": [
        "# cross-validated accuracy for pre-trained model before training\n",
        "print(\"Base model accuracy:\", np.mean(base_model_acc_list))\n",
        "# cross-validated accuracy before fine-tuning\n",
        "print(\"Accuracy before fine-tuning:\", np.mean(pre_trained_acc_list))\n",
        "# cross-validated accuracy after fine-tuning\n",
        "print(\"Final accuracy:\", np.mean(final_acc_list))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model accuracy: 0.10300000011920929\n",
            "Accuracy before fine-tuning: 0.8139999866485595\n",
            "Final accuracy: 0.8480000019073486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn-03T_ZaRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b7b5d840-985f-42f1-d28c-09f2b7a57f02"
      },
      "source": [
        "# plot graph of cross-validated accuracies\n",
        "acc = np.mean(history_map['accuracy'], axis=0)\n",
        "val_acc = np.mean(history_map['val_accuracy'], axis=0)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU5dn48e+dfSULSViSkARk3yGAgAruoCi1ahWXiguotXWrvi+1taUur7b6a9XW2tIqrhUXqgXFDdlUUAj7DiELhISQfd8m8/z+OJMwhCQEyDBJ5v5c11yZOXOWeybJuc95nufcR4wxKKWU8lxe7g5AKaWUe2kiUEopD6eJQCmlPJwmAqWU8nCaCJRSysNpIlBKKQ+niUAdR0Q+E5Hb2ntedxKRDBG5xAXrXSUidzme3ywiX7Zl3tPYTh8RKRcR79ONVanWaCLoAhw7iYaHXUSqnF7ffCrrMsZMN8a80d7zdkQiMk9E1jQzPUpEakVkWFvXZYx5xxhzWTvFdVziMsYcNMaEGGPq22P9zWxPRCRNRHa5Yv2q49NE0AU4dhIhxpgQ4CBwldO0dxrmExEf90XZIb0NTBKRpCbTbwS2G2N2uCEmd7gAiAH6isi4s7lh/ZvsGDQRdGEiMlVEskTkf0XkCLBQRCJE5BMRyRORIsfzOKdlnJs7ZovItyLyvGPedBGZfprzJonIGhEpE5HlIvKyiLzdQtxtifFJEfnOsb4vRSTK6f1bRSRTRApE5NctfT/GmCxgBXBrk7d+Crx5sjiaxDxbRL51en2piOwRkRIR+SsgTu/1E5EVjvjyReQdEQl3vPcW0AdY6jij+x8RSRQR07DTFJHeIrJERApFJFVE5jite76IvC8ibzq+m50iktzSd+BwG/BfYJnjufPnGioiXzm2lSsijzmme4vIYyJywLGdjSIS3zRWx7xN/06+E5E/i0gBML+178OxTLyI/MfxeygQkb+KiJ8jpuFO88WISKWIRJ/k86omNBF0fT2BSCABmIv1O1/oeN0HqAL+2sryE4C9QBTwR+BVEZHTmPffwHqgOzCfE3e+ztoS403A7VhHsn7AIwAiMgR4xbH+3o7tNbvzdnjDORYRGQiMcsR7qt9VwzqigP8Av8H6Lg4Ak51nAZ5xxDcYiMf6TjDG3MrxZ3V/bGYTi4Asx/LXAf8nIhc5vX+1Y55wYElrMYtIkGMd7zgeN4qIn+O9UGA58LljW+cAXzsWfRiYBVwBdAPuACpb/WKOmQCkAT2Ap1v7PsTqF/kEyAQSgVhgkTGm1vEZb3Fa7yzga2NMXhvjUA2MMfroQg8gA7jE8XwqUAsEtDL/KKDI6fUq4C7H89lAqtN7QYABep7KvFg7URsQ5PT+28DbbfxMzcX4G6fXPwM+dzz/LdaOouG9YMd3cEkL6w4CSoFJjtdPA/89ze/qW8fznwLfO80nWDvuu1pY74+Azc39Dh2vEx3fpQ/WTrIeCHV6/xngdcfz+cByp/eGAFWtfLe3AHmOdQcAJcA1jvdmOcfVZLm9wMxmpjfG2sr3dPAkv+/G7wOY2BBfM/NNwEqa4nidAvzEnf9/nfWhZwRdX54xprrhhYgEicg/HE0npcAaIFxaHpFypOGJMabhiC/kFOftDRQ6TQM41FLAbYzxiNPzSqeYejuv2xhTARS0tC1HTB8AP3WcvdwMvHkKcTSnaQzG+bWI9BCRRSJy2LHet7HOHNqi4bssc5qWiXWk3KDpdxMgLbfF3wa8b4yxOf5OFnOseSge62ymOa29dzLH/e5P8n3EA5nGGFvTlRhjfsD6fFNFZBDWGcuS04zJo2ki6Pqalpf9JTAQmGCM6YbVUQhObdgukANEOpohGsS3Mv+ZxJjjvG7HNrufZJk3gJ8AlwKhwNIzjKNpDMLxn/f/sH4vwx3rvaXJOlsrCZyN9V2GOk3rAxw+SUwncPR3XATcIiJHxOpHug64wtG8dQjo28Lih4B+zUyvcPx0/l33bDJP08/X2vdxCOjTSiJ7wzH/rcCHzgc9qu00EXieUKy27mIRiQR+5+oNGmMysU7b5zs6+SYCV7koxg+BGSJynqOt+wlO/nf+DVAMLOBY+/OZxPEpMFREfuzYgd3P8TvDUKAcKBGRWODRJsvn0sIO2BhzCFgLPCMiASIyArgT6yj6VN0K7MNKdqMcjwFYzVizsNrme4nIgyLiLyKhIjLBsey/gCdFpL9YRohId2O1zx/GSi7eInIHzScMZ619H+uxEuuzIhLs+MzO/S1vA9dgJYM3T+M7UGgi8EQvAIFAPvA9Vkfg2XAzVntvAfAU8B5Q08K8px2jMWYncB9WZ28OUIS1Y2ttGYO1E0ng+J3JacVhjMkHrgeexfq8/YHvnGb5PTAGqz3+U6yOZWfPAL8RkWIReaSZTczCaovPBj4CfmeMWd6W2Jq4DfibMeaI8wP4O3Cbo/npUqykfQTYD1zoWPZPwPvAl1h9LK9ifVcAc7B25gXAUKzE1ZoWvw9jXTtxFVazz0Gs3+UNTu8fAjZhnVF8c+pfgYJjnSxKnVUi8h6wxxjj8jMS1bWJyGtAtjHmN+6OpbPSRKDOCrEuVCoE0oHLgI+BicaYzW4NTHVqIpIIbAFGG2PS3RtN5+WypiEReU1EjopIs1dnOtoVXxLrgphtIjLGVbGoDqEn1jDCcuAl4F5NAupMiMiTwA7gOU0CZ8ZlZwQicgHWP/2bxpgTaraIyBXAL7AuSJkAvGiMmdB0PqWUUq7lsjMCY8warKaAlszEShLGGPM91vjsXq6KRymlVPPcWfApluMvLMlyTMtpOqOIzMUqj0BwcPDYQYMGnZUAlVItyyjNACCxW6Jb4+js7MZgN2AMeAmIgCAYDLU2O7U2OzU2O7X1dsIDfQn2P73d9saNG/ONMc3WYeoUlf+MMQuwxniTnJxsUlJS3ByRUur2z28HYOG0hW6OxLWMMWQVVbE1q5jtWSUUV9Yxqk84yQkR9IsOwcvLuvat3m7ILq4iLb+Ckqo67HaDzW6w2w2VtTZySqo5XFxFTkk1R0qqKa2uo6LGhr0NrfMC9Ar249dXDObasa2VzmplHSKZLb3nzkRwmOOvtozjNK6OVEqp01FVW09pdR2+3l74egt+Pl4YAwfyytmTU8aeI6XsOVLG9sPWzh/Az9uLIH9v3kuxGjPCAn0ZFtuNgvJa0vIrqLXZW9yen48XvcIC6B0WyISkSLoF+hLi70Owvw8h/t54eQm1Njt19dZZgJeX0CcyiITIYPp0DyIs0Ndl34U7E8ES4Ocisgirs7jEGHNCs5BSSp2OWpud7OIqsoqqOFRUyaHCSg4VVXGosJKsoiryy1u6ntHi7+PFgB6hXD6kJyPiwxgRG86AniH4eXuRnl/BxswiNmYWsSunlNjwQC4YEE3fqGD6RocQGeyHt5fgLYK3txDg40VksB8tF+51L5clAhF5F6v6ZZSIZGFdnu8LYIz5O1bt8yuAVKzCUbe7KhalVNd3pKSalMxCUjKO7aDrndpdfLyE3uGBxEcGcvGgGOIjA4kI9sNW72iLr7djjCExKphBPbuR2D0IH+/mx9P0jQ6hb3QI1ye3VjKr83BZIjDGzDrJ+warFIBSSp2Skqo6th4qZvvhksafOSVWvbkAXy9GxYdz9wV9SYoKJj4yiPjIIHqE+re4Y/d0naKzWCmlAA4VVvKPNQd4PyWrsT2+b1Qw45MiGRFndeAO6d0NX93hnxJNBEqpDm/vkTJeWZXK0m05eItw7dhYrhrRm2FxYXQLcF0nqqfQRKCU6pDq6u0s35XL2z9k8l1qAUF+3twxOZE7z+tLz7AAd4fXpWgiUEq5Xb3dUFxZS1FlLYUVdXy7P49FGw5xtKyG2PBAHrlsADdPSCAi2M/doXZJmgiUUm6TerSce9/eSGpeOc5lz0Rg6oBonjk3gakDY/D26pjDLrsKTQRKKbfYeqiY2QvX4+3lxS8u6k/3YD/Cg3yJDPajX3QIvcMDT74S1S40ESilzrrvUvOZ+2YKkSF+vH3nBBK6B7s7JI+miUApdVZ9tj2HBxZtoW90MG/eMZ6Ybtrx626aCJRSZ0VFjY2/rEhlwZoDjO4TwWu3jSMsSId+dgSaCJRSLmWMYdn2Izz16S5ySqq5fmwcT8wcRqCft7tDUw6aCJRSLpOeX8HjH+/g29R8hvTqxl9vGsPYhAh3h6Wa0ESglHKJzQeLmL1wA3ZjeGLmUG6ekKDDQDsoTQRKqTax2w0G2rQz/y41nzlvphAd6s/bd04gPjLI9QGq06aJQCnVLLvdsOdIGevSClh3IJ8f0gux1RuGxXZjRFw4+dU1hPj7YLebxrt0AXy+4wj3v7tZRwV1IpoIlFIAVNfVs/1wiaOefyEbM4soctyZK7F7EDNG9MLfx5vth0t454dMpFc5ACOf+JLhsWGMiAsnyM+bF5bvY1R8OAtnj9dRQZ2EJgKlOrHCilpeWL4PAW6dmMg5MSEnzJORX8HKvUdJjApmQlIkQX7H/u1rbPWs2H2UxZsOs2ZfHrX1x0o7XzK4BxP6dmdiv+7ENrnK11Zv5+ZP36W8xsaoXr3ZfriEV79No67ecH7/KP5x69jjtqM6Nv1NKdVJfb4jh998vIOSqjpEhDfWZTJlQDS3T05kdJ8Ilm3PYfHGLFIyixqX8fP2YkxCOOedE0VuaQ1Lt2VTXFlHTKg/t05M4Ny+3RmbEEHkSYq7+Xh7EeTnTZCfN09PGw5YSeVQYVWrd/ZSHZMmAqXcoLzGxpp9eWzKLGJobDcu6B9N9xD/Ni1bUF7D75bs5JNtOQyL7cbbd00gOsSff/9wkDe/z2T2wg2IgDFwTkwI/zttEFcM70lmQSXfpebzzf58nv9yH/4+Xlw2tCfXjonlvHOiznjn7e/j3ewZier4NBEodZaUVNaxZFs2y3flsu5AAbX1dry9hHq7QQSGx4ZxQf9oAv28Sc+vILOggoyCSgoravH1Fny9vfD38aKiph6b3c6jlw9k7gV9G+/G9YuL+3P3lH58uj2bfbnlTBvakxFxYY03TE/oHswFA6L5FVaTkp+PFyH+ugtQmgiUOiu+2HmEX3+0g/zyGhK6B/HTiQlcOqQHo/tEsOdIKWv25bF6Xx6vrD5Avd3Qo5s/Cd2DuXBgNNGh/tYN1uvt1NrsiMCt5yYysGfoCdvx8/HimtFxJ43nZE0/yrNoIlDKhYoqavndkp0s2ZrNkF7dePW25OOO0gFGxIUzIi6cn1/Un/IaG16CdrSqs0r/2pQ6BTW2etamFvD5jiPkldcwqGcow2LDGNq7G30ig6isrSe3tJrc0hoO5JXzwvJ9lFTV8fClA7h3ar+T3lRdm2qUO+hfnVInUVlrY+WePD7feYSVe45SXmMjxN+H2PBA1uzLw2a3bq3l6y3U1Zvjlh3auxtv3TmBwb26uSN0pdpEE4FSzWjY+S/bnsOKPUepqqsnMtiPGSN6cfmwnkzq1x1/H2+q6+rZn1vOzuwS0vMrCA/yo0c3f3p2CyCmWwBJUcFaX0d1eJoIlMc4kFfO0q3ZfLkzl3q7ISLYl4ggPyKC/RCgoLyW/PIa8stryC6pptZmJyrEj2vHxnLF8F6MT4w8YYhlgK83w+PCGB4X5p4PpVQ70ESguixjDGn5FXy5M5elW7PZlVOKCIxLjCQ80Jfiyjr2Hy2nuLKWershKsSfqBB/hseFc9nQAC4cGMP4pEg9olddniYC1WmVVNbx6nfp2O2G3uGB9AoPoHdYILml1azYc5SVe4+SWVAJwOg+4fx2xhCuHNGLHloETanjaCJQndLXu3P51X+2k19eg4h1UZYzfx8vJvXrzl3nJXHhoBjiIrQMslIt0USgOpXiylqeWLqL/2w+zKCeobw2exyDeoZytKyGnJIqDhdXE+LvzcS+UXorRNW52e3gdXZqNmkiUB1WeY2NQ4WVjaUWMgsqWL77KEUVtdx/cX9+fuE5+PlY/yi9wwPpHR7I2AQ3B61cr+QwbHoTEs+DpPNPbx0FB2Ddy1CUAUOuhiEzIbCD3ELTbocvHoPNb8PkB2DifeDn2jNaTQTqrKqx1fPNvnyWbM1mW1Yxwf4+hAX60i3Al2B/H4oqa8kuruJwcRVl1bbjlu0e7MfgXt2YN30Qw2J1lE6nV10KOVsgZysUH4SyHCg7Yj38gmHA5TDwCogbB17ekLsL1r4E2z8Auw3WeMGFj8F5v2z7kXPWRlj7IuxaAt6+0C0Wlj4Ayx6F/pfBiBtgwDTwcVMJDlst/Pdn1mfsOQJWPgUbF8LFv4Ph17vsDEETgXK5gvIaNh8s5qtduXy2I4fSahvhQb5M7NudWpudkqo60vLLKa+2ER7kR1xEEOOTIukdHkhseCBJUcH06R5EtwC9yUmnZQwUpkHGN5C5Fg5vgoL9x973D4NuvSC0p3WkX5ZjHbF/9yIERUFUfzi4DnyDYNxdMOY2+Ob/wYqn4OAP8OMFEBRprevoHtj+PqR+DfV1x7ZRXwMFqda2znsIJtwNIT2sZLTtfdj+Iez5BIJjYMytMHY2hPc5tnxNmZW0bNXQ90IrOTWVtw9WPm19joseB/8m1ViNgfX/hFXPQOxYmHw/JJ4PIlBbAe//FFKXwyXzYfKD1nf1xWPw0Vz44RWY/hzEj2unX8oxYow5+VwdSHJysklJSXF3GKoVdfV23k85xA9phWw5VMzBQmvkToi/D5cN7cFVI3tz3jlRJy23oDq22z+/HYCF0xY2P0NVEez/Cg6sgPQ1UHrYmh7SA2KToffoY4/g7icuX11i7RT3LIPcnTDsWhh357EdvjGw4V/w+a+sHe+Yn8LupXBkG4gXJEyGgCZnjgmTrPn8TyzYR73NijXlNdj/hTWt/2UQEA7ZmyF/H+DYX0b2hUm/gJGzwDcQKgpg9bOw4VXwCYC6SgiPh6v/Cn2nWMuU58F/77PW3WeilZQq8qzPf+7PrARxOAVm/NlKQg3sdiuxLf89TP+D1ZR1GkRkozEmudn3NBGo9nSkpJr7/r2JjZlF9OwWwOg+4YzuE86o+AhGxIUR4KsduF1Fs4mgMA32fg57l1lHs6YegrpbR71JF1iP7udYR8DtJWsjfHAblByC3mNgxE9g6I8htMfpr7P4EGx6w2qnN3ZrvQ1Jq7Yc1v4FsjdBcDQMmgE7/mNNT74dpv7K2sl//DMoPADJd0C/i+CTh63kdtmTMH6udWax9V1rXYVp4O0H1/7L6q9oTl2VlWRO87vTRKDOiu9S87n/3c1U1dXz7LUjuHpkb3eH5Jns9dZOqab82M+6CmuH5szbD/xCrOYLv1CrqaM812qWKc1xarN3arv3DbR2hrFjuD13OXj7sTB+JqR/Yx31lxy01h09GAZdAQOvtOZ39eiX2kqoKoSwk5fgbhfGQMa3Vp/F/i+tM4dLn4SYQcfHtPJpq4kLAzFDrB19j6HHr8teD/u+sM6U4sa6LGRNBMoljDHU2OxU19Xz1rpM/rR8H/2iQ/j7LWM4J6aZU29PU5ZrHb0FRZ18R1hXZY1kKUi1OkL9Qqzmi4Y25rLcYzvk8iNWR2vjzr7sxJ1+ewkIh1BH231oT2u72ZuhLJvbe8YAsPDIUWu+pPMh8QLof4nVdOIp6qqsBNmSQ+ut/o3xc1ufz8VaSwQu7SwWkWnAi4A38C9jzLNN3u8DvAGEO+aZZ4xZ5sqY1Jk5VFjJLz/YyvasEqpt9TgfR8wc1Zv/u2Y4wZ5YSrki39pBZm+2OkKzN1s7bAAvHwhx7EgDI44/ta+vtZoFig/R2P58MoGREBh+LFmE9ITuIU7JI9TpSL/hEXxi56at5vgzh/o6qzmlYccf0rPlYYulObD8HqsDduZi6DHsrI1573BOtnOPH289OjCX/ceKiDfwMnApkAVsEJElxphdTrP9BnjfGPOKiAwBlgGJropJnZkvdh7h0Q+2YoAbx8cT6u9DgJ83gb7e9IkM4qJBMcfdcKVTstVC7g5r5xwYAd16WzvFgHDrSL0891hzSf7+Yzv/kkOOFQhEDYC+U6H3KCsJlGYfW6Yy//jtibc1PHLUzVbbeVR/qx3Y+Ujf2J12zj3cN7TRWbdexzpte41wbyzqjLny0G08kGqMSQMQkUXATMA5ERigoVB7GJDtwnjUaaq12fnD53t49dt0hseG8fJNY+jTvZOWbKitsEagVORbwwEbdrbFmdYOPXendZTelLe/Y3qTo/aIJGtHPn6u1RbeayQE6L0HVOfiykQQCxxyep0FTGgyz3zgSxH5BRAMXNLcikRkLjAXoE+fPs3NolxkQ0YhT326m62HirltYgKPXTkYf58OOPKnvg4Ob7TGqZcfPb4TFAM526wdfd7uEztNAfy7WUfw595r7dCjBkJ18fEdpr7BjrHujqPzsPhjR8VKdWLubsydBbxujPl/IjIReEtEhhlz/H+qMWYBsACszmI3xOlRjDGs2pvH31alsiGjiMhgP16+aQxXjuh19oKoKbcuOLLXH2sS8XZcUGarhaJ0q2kmb481TPHg98c6SQPCrCN/u9OVyUHdrSGAg2dAr1HWDt0v1KkdPbh9hzQq1Ym4MhEcBuKdXsc5pjm7E5gGYIxZJyIBQBRw1IVxqSYqa22k5VWQll/BgaPlfLkrl905pfQOC+B3Vw3hxnF92qeAW1WxdRVnQ4dqcaZ1pWhDJ6dvoNXWnp8KZU1bCQWCo6z5S7Ks8ekNogfB6JutseqJ51lH6cYc6wy110NIjO7olWqBKxPBBqC/iCRhJYAbgZuazHMQuBh4XUQGAwFAngtjUg71dsOy7Tn8bdUBdueUNk4XgYE9QnnuuhHMHBXbWNStzSoLrQttcrZZV5I6j0MvdToOiEiyOkdt1dbVlUXp1rjrbr2si46i+lsPb39r9E3ZEavTtbbcqrkSNQCizrHW0fTq0YYP4htgPZRSrXJZIjDG2ETk58AXWENDXzPG7BSRJ4AUY8wS4JfAP0XkIaxeuNmms13Y0MnU2w2fbs/hL1/vZ//RcvrHhPDwpQPoFx1Cv5hgErsHN3/1b32ddRSfvsZqh68pdQxTdDSv2Kohe4t1lN8gMOJYe3r0IGtseewYq2lG29aV6jBc2kfguCZgWZNpv3V6vguY7MoY1DGr9h7lqU93k+pIAH+9aTRXDOuFV0u3YizJgr2fwb7PIXPdsTb4HsOt8eY15VCZaY2+ES+rkzX5DsfOfmTzR+pKqQ7H3Z3F6izIKqrkyU928cXOXJKigltOADVlVpNOxjew51OreBdAZD8YdZN15WjCec0XCFNKdVqaCLqwGls9//omnb+ssMr9Pnr5QO46P8ka/mkM5O21dvpZKY6hlXuxWujEuhLykt9b9eCjB7j1cyilXEsTQReUU1LFv384yOIfUgmqzOKOfkHcMS6aKN9dsHm1Ndwy4xvrKlmw6q/HjrEqNvYebdVJ16N+pTyGJoIuZPPBIv69ajNm35dcLBu5z2cbAf7V1qV8WU4zhvS0RuYknm8190Qk6dBKpTyYJoKuwBi2rvqQipUv8KzXTrx9DLbgnvgMvunYzTkarrQNCLdK9eqOXynloImgM7PVwo7FVK36MyOL95Lv0x3buQ/hPXQGPr3OQg14pVSXoImgMyrLhc1vQspCKD3MYeL5wP8B5vzsUfzD9D4ASqlTo4mgszDG6uBNec26L6vdRnX8+cyruI11XmNYfM9kosI6aUVQpZRbaSLoDDLXwhePWUM8A8Jhwj0UDr6Za97LpdhexwdzzyUuQpOAUur0aCLoyArT4Kvfwe4l0C0Wrv4LDL+eavy485/fk1tazb/nnMuAHtocpJQ6fZoIOiJ7Pax4Ctb+xbrB+IW/gYn3gV8QdrvhkUWb2XywmL/fMoYxfSLcHa1SqpPTRNDR1Nvg43th+/sw8ia45HdW0TaHF5bv45NtOcybPohpw87i/QGUUl2WJoKOpL4OFt8Ju/4LF/8Wzv/lcW8v3pjFSytSuSE5nrsv6OumIJVSXY0mgo7CVgMfzIa9y+Dy/7Oaghzq6u18tuMI8/6zjYl9u/Pkj4Z1/pvEK6U6DE0EHUFNuZUEUr+CK56H8XMA2JldwuKNh/nvlsMUVNQyoEcIf79l7KnfLEYppVqhicCdjLGuCfh8nnX3rategrG3UVhRy5w3U9iYWYSftxcXD47h2jFxTBkYja+3JgGlVPvSROAuRRmw7FHY/yX0GAbXLYQ+EyiprOPWV38g9Wg5868awo9GxxIe5OfuaJVSXZgmAnfYugiWPgDiDZc9DRPuAW8fymts3LZwPftzy1nw07FMHRjj7kiVUh5AE8HZVpoDnzxs1f2/9l9WJVCgstbGHQs3sONwCX+7eYwmAaXUWaMNzmfb10+AvQ5mvtyYBKrr6pn75kZSMgt54cZRXDa050lWopRS7UcTwdl0eCNs/Tecey9079c4+Y+f7+Xb1Hyeu24kM0b0dmOASilPpIngbDEGPv+VdVvI8x9pnPxDWgEL16bz04kJXDs2zo0BKqU8lfYRnC07FsOhH6zCcQHdAKiosfHoh9uIjwjif6cNcnOASilPpYngbKitgK9+C71GwqibGyc/+9keDhVV8t7ciQT7669CKeUeuvc5G757CUoPW6OEvLytSan5vPV9Jneel8T4pEg3B6iU8mTaR+BqBQfguxdh6DWQMAmAsuo6/ufDbfSNCubRywe6OUCllKfTMwJXstdbJaV9/KxCcg5/+mofOSVVfHjvJAJ8vd0YoFJKaSJwrXUvWx3E1yyAbtaw0Lp6Ox9tPsyMEb31pjJKqQ5Bm4Zc5ege6y5jg2bAiJ80Tv42NZ/iyjquHqnXCyilOgZNBK7QcJcxv2CY8WdwunfAJ1tzCA3w4fwBUW4MUCmljtGmIVf47gXI3mRVFA05VjOoxlbPl7uOcPnQnvj7aN+AUqpj0DOC9nZ0D6x61holNOzHx721Zl8+ZdU2ZozQew0rpToOTQTt7Ye/g5ePdaexJj7Zlk1EkC+Tz9FmIaVUx6GJoD3VVlqlJIb+CIKP39lX1dazfFcu04b11LuMKaU6FN0jtafdS6CmFEbfcsJbK/cepaK2XquLKqU6HJcmAhGZJiJ7RSRVROa1MM9PRGSXiOwUkX+7Mh6X2/w2RCRBwuQT3tLubwsAACAASURBVPpkWzZRIX5M0HISSqkOxmWjhkTEG3gZuBTIAjaIyBJjzC6nefoDvwImG2OKRKTz3parMA0yvoGLfnPccFGwqoyu2HOU68fG46PNQkqpDsaVe6XxQKoxJs0YUwssAmY2mWcO8LIxpgjAGHPUhfG41pZ/g3jByJtOeGv57lyq6+w6Wkgp1SGdNBGIyFUicjoJIxY45PQ6yzHN2QBggIh8JyLfi8i0FmKYKyIpIpKSl5d3GqG4mL3eSgT9Loawph8RPtmWQ49u/oxL1GYhpVTH05Yd/A3AfhH5o4i0991TfID+wFRgFvBPEQlvOpMxZoExJtkYkxwdHd3OIbSDtJVWmelmOol3HC5h9d48rhjeCy8vaWZhpZRyr5MmAmPMLcBo4ADwuoiscxyhh55k0cNAvNPrOMc0Z1nAEmNMnTEmHdiHlRg6l01vQWAkDJx+3OS8shrmvJlCVIgfP5t6jpuCU0qp1rWpyccYUwp8iNXO3wu4BtgkIr9oZbENQH8RSRIRP+BGYEmTeT7GOhtARKKwmorSTuUDuF1FAez5FEbcAD7+jZNrbPXc/VYKRZW1LPhpMtGh/q2sRCml3KctfQRXi8hHwCrAFxhvjJkOjAR+2dJyxhgb8HPgC2A38L4xZqeIPCEiVztm+wIoEJFdwErgUWNMwZl8oLNu+wdgrzuuWcgYw68/2sGmg8X8v+tHMSw2zI0BKqVU69oyfPRa4M/GmDXOE40xlSJyZ2sLGmOWAcuaTPut03MDPOx4dE7b37fuRdxzWOOkV79N58ONWdx/cX+u1JFCSqkOri1NQ/OB9Q0vRCRQRBIBjDFfuySqzqI0Gw5vhCHHRsWmZBTyf8t2M31YTx68uPN1dyilPE9bEsEHgN3pdb1jmtrrONkZeGXjpL+sSCUy2J/nrx+po4SUUp1CWxKBj+OCMAAcz/1cF1InsmcZRPaDaOsG9HuPlLF6Xx63T04k2F9v9aCU6hzakgjynDp3EZGZQL7rQuokqkshfQ0MuqKxpMQ/v0kj0Nebmyf0cXNwSinVdm05bL0HeEdE/goI1tXCP3VpVJ1B6lfWaCFHs1BuaTX/3XKYm8b3ITxIT5iUUp3HSROBMeYAcK6IhDhel7s8qs5gzzIIioL48QC8sTaDervhjvOS3ByYUkqdmjY1ZIvIlcBQIEAczSDGmCdcGFfHZquF/V/CkKvBy5uKGhtvf5/JtGE9Sege7O7olFLqlLTlgrK/Y9Ub+gVW09D1QIKL4+rYMr+1bkAzaAYA76ccorTaxpzz+7o5MKWUOnVt6SyeZIz5KVBkjPk9MBGrFITn2vMp+AZB36nY6u28+m064xIjGN0nwt2RKaXUKWtLIqh2/KwUkd5AHVa9Ic9kjNU/0O8i8A3ki525ZBVVcZeeDSilOqm2JIKljtLQzwGbgAygc99S8kxkb4aybBhkjRZ654dMEroHccngHm4OTCmlTk+rncWOG9J8bYwpBhaLyCdAgDGm5KxE1xHtXWbdiWzANMqq61ifXshd5/fFW68iVkp1Uq2eERhj7Fj3HW54XePRSQCs/oE+kyAoku9SC7DZDVMHdsCb5SilVBu1pWnoaxG5VkT0kLf4EBzd1XgDmtX7jhLq78PYBO0kVkp1Xm1JBHdjFZmrEZFSESkTkVIXx9Uxpa+2fva7CGMMq/bmMfmcKHy9T+eWzkop1TG05VaVocYYL2OMnzGmm+N1t7MRXIeTthqCoyFmMPuPlpNTUs0UbRZSSnVyJ72yWEQuaG560xvVdHnGWGcESReACKv2HgXQ/gGlVKfXlhITjzo9DwDGAxuBi1wSUUeVvw/KcyFpCgCr9uYxsEcovcIC3RyYUkqdmbYUnbvK+bWIxAMvuCyijirN0T/QdwrlNTY2ZBRyx2QtMKeU6vxOp5czCxjc3oF0eOmrIbwPRCSyNjWfunqj/QNKqS6hLX0EfwGM46UXMArrCmPPYa+HjG9gsHV/nlX78gj28yY5IdLNgSml1JlrSx9BitNzG/CuMeY7F8XTMeVsgeoS6DsVYwyr9+Yx6Zwo/Hx02KhSqvNrSyL4EKg2xtQDiIi3iAQZYypdG1oHku4YIJV0AQfyyjlcXMXPLuzn3piUUqqdtOnKYsB5aEwgsNw14XRQaashejCExLBqbx4AUwZo/4BSqmtoSyIIcL49peN5kOtC6mBsNXDwe+h7bNjoOTEhxEV4zleglOra2pIIKkRkTMMLERkLVLkupA7m0HqwVUHSFCprbaxPL2Sqng0opbqQtvQRPAh8ICLZWLeq7Il160rPkL7GKjudMImUjCJq6+2cr4lAKdWFtOWCsg0iMggY6Ji01xhT59qwOpD01dB7NASGs/bAHny8hHGJWm1UKdV1tOXm9fcBwcaYHcaYHUCIiPzM9aF1ADVlcHhjY1mJdQfyGd0nnCC/tpxIKaVU59CWPoI5jjuUAWCMKQLmuC6kDiRzLdht0HcKpdV1bD9cwsR+Ue6OSiml2lVbEoG3801pRMQb8HNdSB1Ixrfg5QvxE1ifVojdwKR+3d0dlVJKtau2tHF8DrwnIv9wvL4b+Mx1IXUgmWshdiz4BrL2QDr+Pl6M7hPu7qiUUqpdteWM4H+BFcA9jsd2jr/ArGuqKbdKSyRMAmDtgXySEyPw9/F2c2BKKdW+2nKHMjvwA5CBdS+Ci4Ddrg2rA8jaYPUPJEymoLyGPUfKmKT9A0qpLqjFpiERGQDMcjzygfcAjDEXnp3Q3CxzrXX9QPx4vt9XCMBE7R9QSnVBrfUR7AG+AWYYY1IBROShsxJVR3BwHfQcAQHdWHsgkxB/H0bEhrk7KqWUanetNQ39GMgBVorIP0XkYqwri9tMRKaJyF4RSRWRea3Md62IGBFJPpX1u4ytxmoaSpgMwLoDBYxPisTHW8tOK6W6nhb3bMaYj40xNwKDgJVYpSZiROQVEbnsZCt2DDN9GZgODAFmiciQZuYLBR7A6ofoGLI3g60aEiZypKSatPwKHTaqlOqy2tJZXGGM+bfj3sVxwGaskUQnMx5INcakGWNqgUXAzGbmexL4A1Dd9rBdLNNx350+E1mXlg9o/4BSqus6pbYOY0yRMWaBMebiNsweCxxyep3lmNbIUdU03hjzaWsrEpG5IpIiIil5eXmnEvLpyVwL0YMgOIq1qQWEB/kyuGc3129XKaXcwG2N3iLiBfwJ+OXJ5nUkn2RjTHJ0tIsrf9rr4eAPkDAJYwxrDxRwblJ3vLxOqXtEKaU6DVcmgsNAvNPrOMe0BqHAMGCViGQA5wJL3N5hfGQ71JZBwmQOFVZxuLiKSedos5BSqutyZSLYAPQXkSQR8QNuBJY0vGmMKTHGRBljEo0xicD3wNXGmBQXxnRymWutn30m8n1aAQAT+2oiUEp1XS5LBMYYG/Bz4AusK5HfN8bsFJEnRORqV233jGV+BxGJEBbL9sMlhPr70C86xN1RKaWUy7i0sL4xZhmwrMm037Yw71RXxtImxlgXkvW/HIBdOaUM7tVN+weUUl2aXiHlLH8fVBZAwiTq7YbdOaUM6a2jhZRSXZsmAmcN1w8kTCKjoILK2npNBEqpLk8TgbPMtRDSEyL7siu7FIChmgiUUl2cJgJn2ZshLhlE2Jldiq+30D8m1N1RKaWUS2kiaFBXBYVp0GMoYHUU948Jxc9HvyKlVNeme7kG+fvA2CFmCMYYdmWXaP+AUsojaCJokLvL+hkzhLyyGvLLa7V/QCnlETQRNDi6C7z9IbIvOx0dxUN6aSJQSnV9mggaHN0N0QPA24ddOVYiGKxnBEopD6CJoMHRXRBj3TdnZ3YJfSKD6Bbg6+aglFLK9TQRAFQVQ+lhiBkMwK7sUu0fUEp5DE0EAHl7rJ8xQyirriOjoFL7B5RSHkMTAUDuTutnzBD2HCkDYGisJgKllGfQRABWR7FfKITFsfNwCQBDeoW5OSillDo7NBGAlQhiBoMIu3JK6R7sR49u/u6OSimlzgpNBMY4RgxZHcU7s63S0yJ6DwKllGfQRFCeC1WF0GMotTY7+3PLtbSEUsqjaCI42lBaYjCpR8uprbfriCGllEfRRHB0t/UzZkjjFcVDe2tHsVLKc2giyN0FwTEQHMXO7BICfb1Jigp2d1RKKXXWaCJw7ig+XMqgXqF4683qlVIexLMTgd1uXVUcM4Ram52tWcWMjo9wd1RKKXVWeXYiKM6EukqIGcyO7BJqbHbGJWoiUEp5Fs9OBA0jhnoMJSWjEICxmgiUUh5GEwFA9EBSMopI7B5ETGiAe2NSSqmzzMfdAbjV0d0Q3gfjF0JKZhEXDYpxd0RKtVldXR1ZWVlUV1e7Zft3xNwBwO7du92yfdW8gIAA4uLi8PVt+/1UPDsR5O6CmKGk5VdQWFFLcoI2C6nOIysri9DQUBITE91SEiW9JB2ApLCks75t1TxjDAUFBWRlZZGU1Pbfi+c2DdlqoWA/xAxu7B9ITox0c1BKtV11dTXdu3fXuliqkYjQvXv3Uz5L9NxEkLcb7DboMZQNGUVEBPnSL1ovJFOdiyYB1dTp/E14biI4tN76GTeOjZlFJCdG6j+VUsojeW4iyEqBkB7kefcgPb9C+weUOkVFhUVced6VjBo1ip49exIbG8uoUaMYNWoUtbW1rS6bkpLC/ffff9JtTJo0qb3CBeDBBx8kNjYWu93eruvt7Dy3szhrg3U2cLAI0P4BpU5VRGQEn377KUlhScyfP5+QkBAeeeSRxvdtNhs+Ps3vYpKTk0lOTj7pNtauXdtu8drtdj766CPi4+NZvXo1F154Ybut21lrn7uj6lzRtpeKAig8AGNuZUNGEf4+XgzTexSrTuz3S3eyK7u0Xdc5pHc3fnfV0FNaZvbs2QQEBLB582YmT57MjTfeyAMPPEB1dTWBgYEsXLiQgQMHsmrVKp5//nk++eQT5s+fz8GDB0lLS+PgwYM8+OCDjWcLISEhlJeXs2rVKubPn09UVBQ7duxg7NixvP3224gIy5Yt4+GHHyY4OJjJkyeTlpbGJ598ckJsq1atYujQodxwww28++67jYkgNzeXe+65h7S0NABeeeUVJk2axJtvvsnzzz+PiDBixAjeeustZs+ezYwZM7juuutOiO/xxx8nIiKCPXv2sG/fPn70ox9x6NAhqqureeCBB5g7dy4An3/+OY899hj19fVERUXx1VdfMXDgQNauXUt0dDR2u50BAwawbt06oqOjT/v3dyo8MxEcTrF+xo0jZUshI+PD8ffxdm9MSnURWVlZrF27Fm9vb0pLS/nmm2/w8fFh+fLlPPbYYyxevPiEZfbs2cPKlSspKytj4MCB3HvvvSeMg9+8eTM7d+6kd+/eTJ48me+++47k5GTuvvtu1qxZQ1JSErNmzWoxrnfffZdZs2Yxc+ZMHnvsMerq6vD19eX+++9nypQpfPTRR9TX11NeXs7OnTt56qmnWLt2LVFRURQWFp70c2/atIkdO3Y0Dtt87bXXiIyMpKqqinHjxnHttddit9uZM2dOY7yFhYV4eXlxyy238M477/Dggw+yfPlyRo4cedaSAHhqIsjaAOJNZdRwdmZ/x9wL+ro7IqXOyKkeubvS9ddfj7e3dWBVUlLCbbfdxv79+xER6urqml3myiuvxN/fH39/f2JiYsjNzSUuLu64ecaPH984bdSoUWRkZBASEkLfvn0bd76zZs1iwYIFJ6y/traWZcuW8ac//YnQ0FAmTJjAF198wYwZM1ixYgVvvvkmAN7e3oSFhfHmm29y/fXXExUVBUBk5MmbjsePH3/c2P2XXnqJjz76CIBDhw6xf/9+8vLyuOCCCxrna1jvHXfcwcyZM3nwwQd57bXXuP3220+6vfbk0s5iEZkmIntFJFVE5jXz/sMisktEtonI1yKS4Mp4Gh1aDz2GsiW3DpvdME77B5RqN8HBx4ZhP/7441x44YXs2LGDpUuXtji+3d/fv/G5t7c3NpvttOZpyRdffEFxcTHDhw8nMTGRb7/9lnfffbfNyzfw8fFp7Gi22+3HdYo7f+5Vq1axfPly1q1bx9atWxk9enSrY/vj4+Pp0aMHK1asYP369UyfPv2UYzsTLksEIuINvAxMB4YAs0RkSJPZNgPJxpgRwIfAH10VTyN7PRzeZDULZRQhAmP66IghpVyhpKSE2NhYAF5//fV2X//AgQNJS0sjIyMDgPfee6/Z+d59913+9a9/kZGRQUZGBunp6Xz11VdUVlZy8cUX88orrwBQX19PSUkJF110ER988AEFBQUAjU1DiYmJbNy4EYAlS5a0eIZTUlJCREQEQUFB7Nmzh++//x6Ac889lzVr1pCenn7cegHuuusubrnlluPOqM4WV54RjAdSjTFpxphaYBEw03kGY8xKY0yl4+X3QByulrcXassgfjwbMgoZ2COUsKC21+RQSrXd//zP//CrX/2K0aNHn9IRfFsFBgbyt7/9jWnTpjF27FhCQ0MJCzv+VrOVlZV8/vnnXHnllY3TgoODOe+881i6dCkvvvgiK1euZPjw4YwdO5Zdu3YxdOhQfv3rXzNlyhRGjhzJww8/DMCcOXNYvXo1I0eOZN26dcedBTibNm0aNpuNwYMHM2/ePM4991wAoqOjWbBgAT/+8Y8ZOXIkN9xwQ+MyV199NeXl5We9WQhAjDGuWbHIdcA0Y8xdjte3AhOMMT9vYf6/AkeMMU81895cYC5Anz59xmZmZp5+YBvfgKX3U3/fRkb+9QA/Gt2bp340/PTXp5Sb7N69m8GDB7tt+x2l1lB5eTkhISEYY7jvvvvo378/Dz30kFtjOh0pKSk89NBDfPPNN2e8rub+NkRkozGm2TG7HeKCMhG5BUgGnmvufWPMAmNMsjEm+Yx70rPWQ2Aku2uiKK+xkZyg/QNKdWb//Oc/GTVqFEOHDqWkpIS7777b3SGdsmeffZZrr72WZ555xi3bd+WoocNAvNPrOMe044jIJcCvgSnGmBoXxmPJSoG4cazPsC4kG5+kiUCpzuyhhx7qlGcAzubNm8e8eSeMpzlrXHlGsAHoLyJJIuIH3AgscZ5BREYD/wCuNsYcdWEslqpi6x7FceNYn15IfGQgvcMDXb5ZpZTqyFyWCIwxNuDnwBfAbuB9Y8xOEXlCRK52zPYcEAJ8ICJbRGRJC6trH4et3n4Tl8z6jELGJ3Z36eaUUqozcOkFZcaYZcCyJtN+6/T8Eldu/wRZKYCQ5j+QworNTNBmIaWU6hidxWdN1gaIGcz3h62xv9o/oJRSnpQIjHFUHE1mfXohMaH+JHQPcndUSnVaN824iTVfrzlu2gsvvMC9997b4jJTp04lJcWq9XXFFVdQXFx8wjzz58/n+eefb3XbH3/8Mbt27Wp8/dvf/pbly5efSvit8rRy1Z6TCApSoboYE5vMD2mFjE/SG9EodSauuu4qli5eety0RYsWtVr4zdmyZcsIDw8/rW03TQRPPPEEl1zSPi3NTctVu4orLrA7XZ5TdC5rAwBHuo3gSGm29g+oruWzeXBke/uus+dwmP5si29PnzmdPz31J2pra/Hz8yMjI4Ps7GzOP/987r33XjZs2EBVVRXXXXcdv//9709YPjExkZSUFKKionj66ad54403iImJIT4+nrFjxwLWNQILFiygtraWc845h7feeostW7awZMkSVq9ezVNPPcXixYt58sknG8tDf/311zzyyCPYbDbGjRvHK6+8gr+/P4mJidx2220sXbqUuro6PvjgAwYNGnRCXJ5Yrtpzzgi8/SBhMt+VWCOFxifpiCGlzkR4RDgjxo7gs88+A6yzgZ/85CeICE8//TQpKSls27aN1atXs23bthbXs3HjRhYtWsSWLVtYtmwZGzZsaHzvxz/+MRs2bGDr1q0MHjyYV199lUmTJnH11Vfz3HPPsWXLFvr169c4f3V1NbNnz+a9995j+/bt2Gy2xjpCAFFRUWzatIl77723xeanhnLV11xzDZ9++mljPaGGctVbt25l06ZNDB06tLFc9YoVK9i6dSsvvvjiSb+3TZs28eKLL7Jv3z7AKle9ceNGUlJSeOmllygoKCAvL485c+awePFitm7dygcffHBcuWqgXctVe84ZwfDrYPh1rP9wK+FBvvSPCXF3REq1n1aO3F3pqmuvYtGiRcycOZNFixbx6quvAvD++++zYMECbDYbOTk57Nq1ixEjRjS7jm+++YZrrrmGoCCrz+7qq69ufG/Hjh385je/obi4mPLyci6//PJW49m7dy9JSUkMGDAAgNtuu42XX36ZBx98ELASC8DYsWP5z3/+c8Lynlqu2nMSgcP69ELGJUbi5aX9A0qdqUuvuJRnfv0MmzZtorKykrFjx5Kens7zzz/Phg0biIiIYPbs2a2WYG7N7Nmz+fjjjxk5ciSvv/46q1atOqN4G0pZt1TG2rlcNVgF6wIDA5kxY8Ypbed0ylUHBQUxderUUypX3XB2cKY8p2kIyC2tJqOgUvsHlGonwSHBXHjhhdxxxx2NncSlpaUEBwcTFhZGbm5uY9NRSy644AI+/vhjqqqqKCsrY+nSYx3QZWVl9OrVi7q6uuN2eqGhoZSVlZ2wroEDB5KRkUFqaioAb731FlOmTGnz5/HUctUelQjWp1tfpl4/oFT7mTVrFlu3bm1MBCNHjmT06NEMGjSIm266icmTJ7e6/JgxY7jhhhsYOXIk06dPZ9y4cY3vPfnkk0yYMIHJkycf17F744038txzzzF69GgOHDjQOD0gIICFCxdy/fXXM3z4cLy8vLjnnnva9Dk8uVy1y8pQu0pycrJpGId8qh7/eAf/2ZTF1t9dho+3R+VA1QVpGWrP1JZy1adahtqj+gjWpxcyNjFSk4BSqlN69tlneeWVV9qtb6CBx+wRiypq2Ztbpv0DSqlOa968eWRmZnLeeee163o9JhFsyND+AaWUao7HJIKDhZUE+XkzIi7s5DMrpZQH8Zg+grvO78st5ybg79M+w62UUqqr8JgzAoAAX00CSinVlEclAqVU+3r5+ZcZOnQoI0aMYNSoUfzwww+AVY66srLylNf3+uuvk52d3ex7s2fPJikpiVGjRjFq1Cheeumldik/vX379sZ1RkZGNm7jdKqZtlRau6PzmKYhpVT72rR+Eyu+WMGmTZvw9/cnPz+/sZTCCy+8wC233NJYP6gt6uvref311xk2bBi9e/dudp7nnnuusaJnexk+fDhbtmwBOKFq6KlatmzZyWfqgDQRKNUF/GH9H9hTuKdd1zkochD/O/5/W3z/6JGjRERGNNbvaSi89tJLL5Gdnc2FF15IVFQUK1eubLEsdWJiIjfccANfffUVDz/8MCkpKdx8880EBgaybt06AgMDW43RecfdUpnpiooKfvGLX7Bjxw7q6uqYP38+M2fOPOnnnzp1Ks8//zzJycnk5+eTnJxMRkYGr7/+OkuWLKGyspIDBw5wzTXX8Mc//rHx86SkpFBeXs706dM577zzWLt2LbGxsfz3v/8lMDCQDRs2cOedd+Ll5cWll17KZ599xo4dO9r0O3EVbRpSSp2W8y86n5zDOQwYMICf/exnjTdxuf/+++nduzcrV65k5cqVAK2Wpe7evTubNm3illtuITk5mXfeeYctW7Y0mwQeffTRxmac7dtPvP9Cc2Wmn376aS666CLWr1/PypUrefTRR6moqDijz75ly5bGUtfvvfcehw4dOmGe/fv3c99997Fz507Cw8NZvHgxALfffjv/+Mc/2LJlS7vVCjpTekagVBfQ2pG7qwSHBLNk9RKytmWxcuVKbrjhBp599llmz559wrytlaV2rqNzMidrGmquzPSXX37JkiVLGhNDdXU1Bw8ePKPyHBdffDFhYdZQ9CFDhpCZmUl8fPxx8zT0NTTEk5GRQXFxMWVlZUycOBGAm266iU8++eS042gvmgiUUqfN29ubqVOnMnXqVIYPH84bb7xxQiI4WVnqlgqynY7mykwbY1i8eDEDBw48pXU5l5JuWhq6YTtNt9XaPFVVVae0/bNJm4aUUqclbX8a6QfSG19v2bKFhIQE4Pgy0adSlrql8tJn4vLLL+cvf/kLDQU2N2/e3KblnEtJf/jhh+0SS3h4OKGhoY2jqxYtWtQu6z1TekaglDottmobv37k11SWVuLj48M555zDggULAJg7dy7Tpk1r7CtoKEsdHx/falnq2bNnc88997S5s7gtHn/8cR588EFGjBiB3W4nKSmpTc0xjzzyCD/5yU9YsGDBcaWpz9Srr77KnDlz8PLyYsqUKY1NTO7kUWWolepK3F2GWp2e8vJyQkKsW+U+++yz5OTktOlex6dCy1ArpVQH9umnn/LMM89gs9lISEjg9ddfd3dImgiUUupsuuGGG05ppNTZoJ3FSnVina1pV7ne6fxNaCJQqpMKCAigoKBAk4FqZIyhoKCAgICAU1pOm4aU6qTi4uLIysoiLy/P3aGoDiQgIIC4uLhTWkYTgVKdlK+vL0lJeuN4dea0aUgppTycJgKllPJwmgiUUsrDdbori0UkD8g8zcWjgPx2DMfVOlO8nSlW6FzxdqZYoXPF25lihTOLN8EYE93cG50uEZwJEUlp6RLrjqgzxduZYoXOFW9nihU6V7ydKVZwXbzaNKSUUh5OE4FSSnk4T0sEC9wdwCnqTPF2plihc8XbmWKFzhVvZ4oVXBSvR/URKKWUOpGnnREopZRqQhOBUkp5OI9JBCIyTUT2ikiqiMxzdzxNichrInJURHY4TYsUka9EZL/jZ4Q7Y2wgIvEislJEdonIThF5wDG9w8UrIgEisl5Etjpi/b1jepKI/OD4e3hPRPzcHWsDEfEWkc0i8onjdUeONUNEtovIFhFJcUzrcH8HDUQkXEQ+FJE9IrJbRCZ2xHhFZKDjO214lIrIg66K1SMSgYh4Ay8D04EhwCwRGeLeqE7wOjCtybR5wNfGmP7A147XHYENDoDg+gAABPBJREFU+KUxZghwLnCf4/vsiPHWABcZY0YCo4BpInIu8Afgz8aYc4Ai4E43xtjUA8Bup9cdOVaAC40xo5zGt3fEv4MGLwKfG2MGASOxvucOF68xZq/jOx0FjAUqgY9wVazGmC7/ACYCXzi9/hXwK3fH1Uyc/7+9e3uxqozDOP59wgoPoR1MxInMiopA1AuDtJCkLiSkC6ODiUTQjTdeFdIJ+gM6XEQJRRiJhaUlXpUWgkEem8wUOwqOqBORlUFR+uvi/W3bjSNN4cx6Yz0fGGatd63ZPBvePb+93rX3+04F9nbtHwAm5/Zk4EDTGc+S+13g9trzAmOA3cBNlG9njhqsfzScsSdf4LcBGwHVmjXzHAQuG9BWZT8AxgPfkh+SqT1vV747gI+GM2srrgiAKcChrv2+bKvdpIg4kttHgUlNhhmMpKnATGAblebNoZZeoB94H/gaOB4Rf+QpNfWH54BHgFO5fyn1ZgUI4D1JuyQ9nG1V9gPgKuA74NUcentZ0ljqzdtxL7Amt4cla1sKwf9elLcAVX3WV9I44G1geUT81H2sprwRcTLKJXYPMBu4vuFIg5J0J9AfEbuazvIvzI2IWZRh12WSbu0+WFM/oKy/Mgt4MSJmAr8wYGilsrzk/aCFwNqBx85l1rYUgsPAFV37PdlWu2OSJgPk7/6G85wm6XxKEVgdEeuyudq8ABFxHPiQMrwyQVJnYaZa+sMcYKGkg8AblOGh56kzKwARcTh/91PGsGdTbz/oA/oiYlvuv0UpDLXmhVJgd0fEsdwflqxtKQQ7gGvz0xcXUC61NjScaSg2AEtzeyllLL5xkgS8AuyPiGe6DlWXV9JESRNyezTlXsZ+SkFYlKdVkTUiVkRET0RMpfTRDyJiMRVmBZA0VtJFnW3KWPZeKuwHABFxFDgk6bpsmg/so9K86T7+GhaC4cra9I2QEbzhsgD4gjI+/FjTeQbJtwY4AvxOeefyEGV8eDPwJbAJuKTpnJl1LuWSdA/Qmz8LaswLTAc+yax7gSezfRqwHfiKctl9YdNZB+SeB2ysOWvm+jR/Pu+8rmrsB12ZZwA7sz+8A1xca15gLPA9ML6rbViyeooJM7OWa8vQkJmZnYULgZlZy7kQmJm1nAuBmVnLuRCYmbWcC4HZCJI0rzOrqFktXAjMzFrOhcBsEJIeyHUMeiWtzInrTkh6Ntc12CxpYp47Q9LHkvZIWt+ZI17SNZI25VoIuyVdnQ8/rmtO/NX5TW2zxrgQmA0g6QbgHmBOlMnqTgKLKd/03BkRNwJbgKfyT14DHo2I6cBnXe2rgReirIVwM+Wb41Bma11OWRtjGmWOIbPGjPrnU8xaZz5lMZAd+WZ9NGVyr1PAm3nO68A6SeOBCRGxJdtXAWtzDp4pEbEeICJ+BcjH2x4RfbnfS1mHYuvwPy2zwbkQmJ1JwKqIWPG3RumJAef91/lZfuvaPolfh9YwDw2ZnWkzsEjS5XB6Dd4rKa+Xziyg9wNbI+JH4AdJt2T7EmBLRPwM9Em6Kx/jQkljRvRZmA2R34mYDRAR+yQ9Tll56zzKjLDLKAuZzM5j/ZT7CFCmA34p/9F/AzyY7UuAlZKezse4ewSfhtmQefZRsyGSdCIixjWdw+xc89CQmVnL+YrAzKzlfEVgZtZyLgRmZi3nQmBm1nIuBGZmLedCYGbWcn8Cn4J56hdB6x0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCYvBkKZmGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "84025ba2-8401-41d0-ce4f-2a6559274934"
      },
      "source": [
        "# plot graph of cross-validated losses\n",
        "loss = np.mean(history_map['loss'], axis=0)\n",
        "val_loss = np.mean(history_map['val_loss'], axis=0)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.plot([no_epochs-1,no_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}